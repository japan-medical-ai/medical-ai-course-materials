

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="ja" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="ja" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>2. 機械学習ライブラリの基礎 &mdash; メディカルAIコース オンライン講義資料&lt;Paste&gt;  ドキュメント</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="index" title="索引" href="../genindex.html" />
    <link rel="search" title="検索" href="../search.html" />
    <link rel="next" title="3. ニューラルネットワークの基礎" href="Introduction_to_Neural_Network.html" />
    <link rel="prev" title="1. 機械学習に必要な数学の基礎" href="Basic_Math_for_ML.html" /> 

  
  <script src="../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../index.html" class="icon icon-home"> メディカルAIコース オンライン講義資料<Paste>
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="Basic_Math_for_ML.html">1. 機械学習に必要な数学の基礎</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">2. 機械学習ライブラリの基礎</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#単回帰分析">2.1. 単回帰分析</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#問題設定">2.1.1. 問題設定</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Step1.-モデルを決める">2.1.2. Step1. モデルを決める</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Step2.-目的関数を決める">2.1.3. Step2. 目的関数を決める</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Step3.-最適なパラメータを求める">2.1.4. Step3. 最適なパラメータを求める</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#重回帰分析">2.2. 重回帰分析</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#問題設定">2.2.1. 問題設定</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Step1.-モデルを決める">2.2.2. Step1. モデルを決める</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Step2.-目的関数を決める">2.2.3. Step2. 目的関数を決める</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Step3.-パラメータを最適化する">2.2.4. Step3. パラメータを最適化する</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#Numpyによる実装">2.3. Numpyによる実装</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Scikit-learnによる本格的な実装">2.4. Scikit-learnによる本格的な実装</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#Scikit-learn基礎編">2.4.1. Scikit-learn基礎編</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Scikit-learn応用編">2.4.2. Scikit-learn応用編</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#よく使われる機械学習アルゴリズムの紹介">2.5. よく使われる機械学習アルゴリズムの紹介</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#Support-Vector-Machine-(SVM)">2.5.1. Support Vector Machine (SVM)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#Support-Vector-Regression-(SVR)">2.5.1.1. Support Vector Regression (SVR)</a></li>
<li class="toctree-l4"><a class="reference internal" href="#Support-Vector-Classification-(SVC)">2.5.1.2. Support Vector Classification (SVC)</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#Random-Forest">2.5.2. Random Forest</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#回帰-(Regression)">2.5.2.1. 回帰 (Regression)</a></li>
<li class="toctree-l4"><a class="reference internal" href="#分類-(Classification)">2.5.2.2. 分類 (Classification)</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#ロジスティック回帰">2.5.3. ロジスティック回帰</a></li>
<li class="toctree-l3"><a class="reference internal" href="#k-means">2.5.4. k-means</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="Introduction_to_Neural_Network.html">3. ニューラルネットワークの基礎</a></li>
<li class="toctree-l1"><a class="reference internal" href="Introduction_to_Chainer.html">4. Deep Learningフレームワークの基礎</a></li>
<li class="toctree-l1"><a class="reference internal" href="Image_Segmentation.html">5. 実践編: MRI画像のセグメンテーション</a></li>
<li class="toctree-l1"><a class="reference internal" href="Blood_Cell_Detection.html">6. 実践編: 血液の顕微鏡画像からの細胞検出</a></li>
<li class="toctree-l1"><a class="reference internal" href="DNA_Sequence_Data_Analysis.html">7. 実践編：ディープラーニングを使った配列解析</a></li>
<li class="toctree-l1"><a class="reference internal" href="Sequential_Data_Analysis_with_Deep_Learning.html">8. 実践編: ディープラーニングを使ったモニタリングデータの時系列解析</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">メディカルAIコース オンライン講義資料<Paste></a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
      <li>2. 機械学習ライブラリの基礎</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/notebooks/Introduction_to_ML_libs.ipynb.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput,
div.nbinput div.prompt,
div.nbinput div.input_area,
div.nbinput div[class*=highlight],
div.nbinput div[class*=highlight] pre,
div.nboutput,
div.nbinput div.prompt,
div.nbinput div.output_area,
div.nboutput div[class*=highlight],
div.nboutput div[class*=highlight] pre {
    background: none;
    border: none;
    padding: 0 0;
    margin: 0;
    box-shadow: none;
}

/* avoid gaps between output lines */
div.nboutput div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput,
div.nboutput {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput,
    div.nboutput {
        flex-direction: column;
    }
}

/* input container */
div.nbinput {
    padding-top: 5px;
}

/* last container */
div.nblast {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput div.prompt pre {
    color: #303F9F;
}

/* output prompt */
div.nboutput div.prompt pre {
    color: #D84315;
}

/* all prompts */
div.nbinput div.prompt,
div.nboutput div.prompt {
    min-width: 8ex;
    padding-top: 0.4em;
    padding-right: 0.4em;
    text-align: right;
    flex: 0;
}
@media (max-width: 540px) {
    div.nbinput div.prompt,
    div.nboutput div.prompt {
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput div.prompt.empty {
        padding: 0;
    }
}

/* disable scrollbars on prompts */
div.nbinput div.prompt pre,
div.nboutput div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput div.input_area,
div.nboutput div.output_area {
    padding: 0.4em;
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput div.input_area,
    div.nboutput div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput div.input_area {
    border: 1px solid #cfcfcf;
    border-radius: 2px;
    background: #f7f7f7;
}

/* override MathJax center alignment in output cells */
div.nboutput div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.pngmath center alignment in output cells */
div.nboutput div.math p {
    text-align: left;
}

/* standard error */
div.nboutput div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }

/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast,
.nboutput.nblast {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast + .nbinput {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}
</style>
<p><a class="reference external" href="https://colab.research.google.com/github/japan-medical-ai/medical-ai-course-materials/blob/master/notebooks/Introduction_to_ML_libs.ipynb"><img alt="colab-logo" src="https://colab.research.google.com/assets/colab-badge.svg" /></a></p>
<div class="section" id="機械学習ライブラリの基礎">
<h1>2. 機械学習ライブラリの基礎<a class="headerlink" href="#機械学習ライブラリの基礎" title="このヘッドラインへのパーマリンク">¶</a></h1>
<p>ここでは，代表的な機械学習アルゴリズムの紹介とチューニングのポイントをその数学的な背景と合わせて紹介します．
機械学習の考え方を身に着ける練習として，単回帰分析と重回帰分析のアルゴリズムを扱います．これらを学ぶことで線形代数，統計，微分についての理解が深まります．</p>
<div class="section" id="単回帰分析">
<h2>2.1. 単回帰分析<a class="headerlink" href="#単回帰分析" title="このヘッドラインへのパーマリンク">¶</a></h2>
<p>機械学習アルゴリズムの第一弾として，最も基本的な単回帰分析について紹介します．ここで微分を含む基礎的な数学とそれに対応する機械学習アルゴリズムを交互に学びながら，知識を深めていきます．</p>
<p>単回帰分析は教師あり学習の一種です．その中でも，数値（厳密には連続値）を予測する<strong>回帰</strong>を取り扱う手法です．単回帰分析は，ひとつの入力変数からひとつの出力変数を予測する機械学習アルゴリズムです．</p>
<div class="section" id="問題設定">
<h3>2.2.1. 問題設定<a class="headerlink" href="#問題設定" title="このヘッドラインへのパーマリンク">¶</a></h3>
<p>例として家賃の予測を考えます．この場合，家賃が出力変数 <span class="math notranslate nohighlight">\(y\)</span>
となります．</p>
<p>次に入力変数として何を採用するかを考えます．機械学習は，データをもとに学習しますが，一番最初にどのデータを使ってどの値を予測させるかは人間側で決めなければなりません．そのため，入力変数として何を採用するかといった問題は，人間側の経験に依存します．例えば，家賃の予測では，部屋の広さか，駅からの距離か，それとも犯罪発生率を入力変数として採用するかの自由度があります．例えばここでは部屋の広さを入力変数<span class="math notranslate nohighlight">\(x\)</span>として採用することとします．実際には，このように複数の候補があった際に，それらすべてを考慮できるようなモデル化を採用するのが一般的であり，それはこの次の重回帰分析以降で紹介していきます．</p>
<p>機械学習アルゴリズムは，どの手法も大きく分けて次の3つのステップで成り立っています．</p>
<ul class="simple">
<li>モデルを決める</li>
<li>目的関数を決める</li>
<li>最適なパラメータを求める</li>
</ul>
</div>
<div class="section" id="Step1.-モデルを決める">
<h3>2.2.2. Step1. モデルを決める<a class="headerlink" href="#Step1.-モデルを決める" title="このヘッドラインへのパーマリンク">¶</a></h3>
<p>まず<strong>Step1は</strong>では<strong>モデル</strong>を消えます．このモデルとは出力変数<span class="math notranslate nohighlight">\(y\)</span>と入力変数<span class="math notranslate nohighlight">\(x\)</span>の関係を定式化したものです．家賃の予測値を<span class="math notranslate nohighlight">\(y\)</span>とした際に，どのように定式化すればうまく予測することができるのか．このモデル設計は現在は人手で行うのが一般的であり，機械が自動的に決めてくれるわけではありません（一方で最近のAutoMLなど，モデルも自動決定する研究が進展しています）</p>
<div class="figure" id="id14">
<img alt="01.png" src="https://github.com/japan-medical-ai/medical-ai-course-materials/raw/master/notebooks/images/2/01.png" />
<p class="caption"><span class="caption-text">01.png</span></p>
</div>
<p>例えば，与えられたデータセットにおいて，家賃と部屋の広さの関係が次のようになっているとします．この場合，部屋の広さが広くなるほど，家賃が高くなっている関係がみられ，予測のために直線を書くのが妥当にみえます．</p>
<div class="figure" id="id15">
<img alt="02.png" src="https://github.com/japan-medical-ai/medical-ai-course-materials/raw/master/notebooks/images/2/02.png" />
<p class="caption"><span class="caption-text">02.png</span></p>
</div>
<p>直線の式は<span class="math notranslate nohighlight">\(y=ax+b\)</span> で表され，<span class="math notranslate nohighlight">\(a\)</span> を傾き，<span class="math notranslate nohighlight">\(b\)</span>
を切片とよばれるパラメータです．</p>
<p>今回，このデータセットに対して，直線を引くことが適切であると（人間側の経験で）判断したため，以下のようにモデルを決める．</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}  y = wx + b\\傾き :math:`a` の箇所が :math:`w`\end{aligned}\end{align} \]</div>
<p>となっているが，一般的に機械学習では，傾きの箇所を<strong>重み (weight)</strong>
<span class="math notranslate nohighlight">\(w\)</span>, 切片 <span class="math notranslate nohighlight">\(b\)</span> の箇所を<strong>バイアス (bias)</strong> <span class="math notranslate nohighlight">\(b\)</span>
で記述することが多いので覚えておいてほしい．</p>
<p>単回帰分析では，このようにモデルを直線 <span class="math notranslate nohighlight">\(y = wx + b\)</span>
と決めて，その重みとバイアスの値をデータにうまく合うように調整します．この調整される変数のことを<strong>パラメータ</strong>と呼びます．つまり，今回は
<span class="math notranslate nohighlight">\(w\)</span> と <span class="math notranslate nohighlight">\(b\)</span>
がパラメータです．多くの機械学習ではこのようなパラメータで特徴付けられたモデルを使い，データにあうように最適なパラメータを求めることが目標となります．先程の例ではデータとは，部屋の広さ
<span class="math notranslate nohighlight">\(x\)</span> と教師データとなる家賃 <span class="math notranslate nohighlight">\(t\)</span>
のことであり，<span class="math notranslate nohighlight">\(\mathcal{D} = \{x_i, t_i\}_{i=1}^{N}\)</span>
として表す．ここで，添え字 <span class="math notranslate nohighlight">\(i\)</span>
(<span class="math notranslate nohighlight">\(i=1,2,\ldots,N\)</span>)は<span class="math notranslate nohighlight">\(i\)</span>番目の物件という意味であり，<span class="math notranslate nohighlight">\(N\)</span>は全体の物件数のことである．この<span class="math notranslate nohighlight">\(N\)</span>を<strong>サンプル数</strong>という．</p>
<p>ここで，この後の計算を楽に進めるために，<strong>データの中心化</strong>というテクニックを使う．これはデータの重心（全部のデータの平均）を0とした中央に配置するように変換の処理を施す．この中心化は前処理として行うことが一般的である（分散/標準偏差も1とする正規化もよく使われる．</p>
<div class="figure" id="id16">
<img alt="03.png" src="https://github.com/japan-medical-ai/medical-ai-course-materials/raw/master/notebooks/images/2/03.png" />
<p class="caption"><span class="caption-text">03.png</span></p>
</div>
<p>中心化によって，求める直線のバイアス <span class="math notranslate nohighlight">\(b\)</span>
が0となり，<span class="math notranslate nohighlight">\(y_{c} = wx_{c}\)</span>
とすることができ，調整すべきパラメータを2つから1つに減らすことができる，ただし<span class="math notranslate nohighlight">\(x_c, y_c\)</span>は中心化を適用した後の値である．</p>
<div class="figure" id="id17">
<img alt="04.png" src="https://github.com/japan-medical-ai/medical-ai-course-materials/raw/master/notebooks/images/2/04.png" />
<p class="caption"><span class="caption-text">04.png</span></p>
</div>
<p>データの中心化は入出力の平均をデータの全体から引くことで実現されます．つまり，</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\begin{split}  \begin{aligned}
  x_{c} &amp;= x - \bar{x} \\
  t_{c} &amp;= t - \bar{t}
  \end{aligned}\end{split}\\を行います．\end{aligned}\end{align} \]</div>
<p>例えば，具体的な数値で見ると，下図のようになります．</p>
<div class="figure" id="id18">
<img alt="05.png" src="https://github.com/japan-medical-ai/medical-ai-course-materials/raw/master/notebooks/images/2/05.png" />
<p class="caption"><span class="caption-text">05.png</span></p>
</div>
<p>中心化後を示す添え字の <span class="math notranslate nohighlight">\(c\)</span>
に関しては表現が冗長となるため，今後はこの添え字を省略し，データの中心化を事前に行っていることを前提とします．この時，モデルは</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}  y = wx\\となり，単回帰分析の目標は，データセット\end{aligned}\end{align} \]</div>
<p><span class="math notranslate nohighlight">\(\mathcal{D} = \{x_n, t_n\}_{n=1}^{N}\)</span>
に基づいて，パラメータ<span class="math notranslate nohighlight">\(w\)</span> を適切に調整することになります．</p>
</div>
<div class="section" id="Step2.-目的関数を決める">
<h3>2.2.3. Step2. 目的関数を決める<a class="headerlink" href="#Step2.-目的関数を決める" title="このヘッドラインへのパーマリンク">¶</a></h3>
<p>どれだけ目標を達成しているかを表す関数を<strong>目的関数</strong>とよびます．分野によっては評価関数ともよばれます．</p>
<p>今回は教師データと予測値が一致することが目標であり，それを表す目的関数として教師データと予測値の二乗誤差を使います．二乗誤差が0であるとき，またその時のみt
= y となり，完璧な予測を達成しているといえます，<span class="math notranslate nohighlight">\(n\)</span>
番目の物件に対する教師データ<span class="math notranslate nohighlight">\(t_{n}\)</span>
と予測値<span class="math notranslate nohighlight">\(y_{n}\)</span>の二乗誤差は</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}  (t{_n} - y_{n})^{2}\\となります．これを全物件で考慮する必要があるため，最終的な目的関数は\end{aligned}\end{align} \]</div>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\begin{split}  \begin{aligned}
  \mathcal{L}&amp;=\left( t_{1}-y_{1}\right)^{2}+\left( t_{2}-y_{2}\right)^{2}+\ldots + (t_{N}-y_{N})^{2} \\
  &amp;=\sum^{N}_{n=1}\left( t_{n}-y_{n}\right)^{2}\\
  \end{aligned}\end{split}\\となります．また，Step1で決めたモデルより，\end{aligned}\end{align} \]</div>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}  y_{n} = wx_{n}\\となるため，目的関数は\end{aligned}\end{align} \]</div>
<div class="math notranslate nohighlight">
\[\mathcal{L}=\sum^{N}_{n=1}\left( t_{n}-wx_{n}\right)^{2}\]</div>
<p>とパラメータを含んだ形式で表現することができます．機械学習ではこのような望ましい時に値が<span class="math notranslate nohighlight">\(0\)</span>であり，望ましくない時に大きな正の値となるような関数を目的関数とします．このような関数を<strong>損失関数</strong>と呼び，その値を<strong>損失</strong>とよびます．多くの場合複数の教師データからなる学習問題では各教師データに対する損失関数の和を目的関数とし，それを最小化することで望ましい状態を達成することを目指します．$</p>
</div>
<div class="section" id="Step3.-最適なパラメータを求める">
<h3>2.1.4. Step3. 最適なパラメータを求める<a class="headerlink" href="#Step3.-最適なパラメータを求める" title="このヘッドラインへのパーマリンク">¶</a></h3>
<p>最後は目的関数を最小化するようなパラメータを求めます．ここで，ある関数を最小化する点を求める方法としては微分が使えることをすでに学んでいます．今回のような差の二乗の場合微分して「傾き0」となる点が損失が<span class="math notranslate nohighlight">\(0\)</span>となる点です．目的関数の微分求めると，次のようになります．</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
\dfrac{\partial }{\partial w} \mathcal{L}  &amp;= \dfrac{\partial}{\partial w} { \sum^{N}_{n=1} ( t_{n}-wx_{n})^{2} }\\
\end{aligned}\end{split}\]</div>
<p>ここで，微分が線形性の性質を持つことを使う，特に和の微分は微分の和であることを利用し次を得ます</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}  \dfrac{\partial}{\partial w} \mathcal{L}=\sum^{N}_{n=1}\dfrac {\partial }{\partial w}\left( t_{n}-wx_{n}\right)^{2}\\ここでは微分と総和 :math:`\sum`\end{aligned}\end{align} \]</div>
<p>の記号が交換しています．なお微分と積分<span class="math notranslate nohighlight">\(\int\)</span>は常に交換できるとは限りません．次に和の各項をみると</p>
<div class="math notranslate nohighlight">
\[\dfrac {\partial }{\partial w}\left( t_{n}-wx_{n}\right)^{2}\]</div>
<p>の部分は合成関数になっていることがわかります．<span class="math notranslate nohighlight">\(u_{n} = t_{n} - wx_{n}\)</span>
とおくと，</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\begin{split}  \begin{aligned}
  \dfrac {\partial }{\partial w}\left( t_{n}-wx_{n}\right)^{2} &amp;=  \dfrac {\partial }{\partial w} f(u_{n}) \\ \because f(u_{n}) &amp;= u_{n}^{2}\\
  \Rightarrow \dfrac {\partial }{\partial w} f(u_{n}) &amp;= \dfrac {\partial u_{n}}{\partial w} \dfrac{\partial f(u_{n})}{\partial w} \\
  &amp;=-x_{n} \times 2 \left( t_{n}-wx_{n}\right)  \\
  &amp;= -2x_{n}( t_{n}-wx_{n} )
  \end{aligned}\end{split}\\が得られます．これより，\end{aligned}\end{align} \]</div>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\begin{split}  \begin{aligned}
  \dfrac{\partial }{\partial w} \mathcal{L}
  &amp;=\sum^{N}_{n=1}\dfrac {\partial }{\partial w}\left( t_{n}-wx_{n}\right)^{2}
  \\&amp;=-\sum^{N}_{n=1}2x_{n}\left( t_{n}-wx_{n}\right)
  \end{aligned}\end{split}\\となります．この微分の値が0となるように\ :math:`w`\ を決めていくと，\end{aligned}\end{align} \]</div>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\begin{split}  \begin{aligned}
  \dfrac {\partial }{\partial w} \mathcal{L} &amp;=0\\
  -2\sum^{N}_{n=1}x_{n}\left( t_{n}-wx_{n}\right) &amp;=0\\
  -2 \sum^{N}_{n=1}x_{n}t_{n} + 2\sum^{n}_{n=1}wx^{2}_{n}&amp;=0\\
  -2\sum^{N}_{n=1}x_{n}t_{n}+2w\sum^{N}_{n=1}x^{2}_{n}&amp;=0\\
  w\sum^{N}_{n=1}x^{2}_{n}&amp;=\sum^{n}_{n=1}x_{n}t_{n}\\
  \Rightarrow w&amp;=\dfrac {\displaystyle  \sum^{N}_{n=1}x_{n}t_{n}}{\displaystyle  \sum^{N}_{n=1}x^{2}_{n}}
  \end{aligned}\end{split}\\となります．この求まったパラメータはデータセット\end{aligned}\end{align} \]</div>
<p><span class="math notranslate nohighlight">\(\mathcal{D} = \{x_n, t_n\}_{n=1}^{N}\)</span>
のみから決定されていることが確認できます．</p>
<p>次に例題にあげていた数値例でパラメータ <span class="math notranslate nohighlight">\(w\)</span>
を求めてみます．まずは，データの中心化を行います．最初に平均を求めます．</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\begin{split}  \begin{aligned}
  \bar{x} &amp;= \dfrac{1}{3} (1 + 2 + 3) = 2 \\
  \bar{t} &amp;= \dfrac{1}{3}(2 + 3.9 + 6.1) = 4
  \end{aligned}\end{split}\\そして，各変数に対して前処理として，平均を引く中心化の処理を施します．\end{aligned}\end{align} \]</div>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
x_{1} &amp;= 1 - 2 = -1 \\
x_{2} &amp;= 2 -2 = 0 \\
x_{3} &amp;= 3- 2 = 1\\
t_{1} &amp;= 2 - 4 = -2\\
t_{2} &amp;= 3.9 - 4 = -0.1\\
t_{3} &amp;= 6.1 - 4 = 2.1
\end{aligned}\end{split}\]</div>
<p>そして，中心化後の値を用いて，最適なパラメータ<span class="math notranslate nohighlight">\(w\)</span>を導出します．</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
w &amp;= \dfrac{\displaystyle \sum_{n=1}^{N}x_{n}t_{n}}{\displaystyle  \sum_{n=1}^{N}x_{n}^{2}} \\
&amp;= \dfrac{x_{1}t_{1} + x_{2}t_{2} + x_{3}t_{3}}{x_{1}^{2} + x_{2}^{2} + x_{3}^{2}} \\
&amp;= \dfrac{-1 \times (-2) + 0 \times 0.1 + 1 \times 2.1}{(-1)^{2} + 0^2 + 1^2} \\
&amp;= 2.05
\end{aligned}\end{split}\]</div>
<p>これで単回帰分析の学習の手順が完了しました．．この求まったパラメータを使用したモデルが学習済みモデルとよばれます．</p>
<p>このモデルを使って新しいサンプルに対する予測をしてみましょう．例えば，新しいサンプル<span class="math notranslate nohighlight">\(x_{q}=1.5\)</span>
に対する予測値は次のように求まります．</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
y_{q} - \bar{t} &amp;= w(x_{q}-\bar{x}) \\
\Rightarrow y_{q} &amp;= w(x_{q}-\bar{x}) + \bar{t} \\
&amp;= 2.05 \times (1.5 - 2) + 4 \\
&amp;= 2.975
\end{aligned}\end{split}\]</div>
<p>単回帰解析は単純ですがこれで機械学習の一通りを学ぶことができます．</p>
</div>
</div>
<div class="section" id="重回帰分析">
<h2>2.2. 重回帰分析<a class="headerlink" href="#重回帰分析" title="このヘッドラインへのパーマリンク">¶</a></h2>
<p>次に，多変数の入力変数を扱う重回帰分析を扱います．この重回帰分析を学ぶことで線形代数に関する知識が深まります．</p>
<p>重回帰分析は単回帰分析と同様に教師あり学習の一種であり，回帰を取り扱う手法です．問題設定は，ほとんど単回帰分析と同じですが，重回帰分析では入力変数の数が複数となります．つまり，複数の入力変数から出力変数を予測できるような機械学習アルゴリズムです．</p>
<div class="section" id="問題設定">
<span id="id5"></span><h3>2.2.1. 問題設定<a class="headerlink" href="#問題設定" title="このヘッドラインへのパーマリンク">¶</a></h3>
<p>ここでは単回帰分析の場合と同様，家賃の予測を考え，家賃を出力変数<span class="math notranslate nohighlight">\(y\)</span>とします．そして，入力変数としては，前回の単回帰分析で考慮できなかった駅からの距離や犯罪発生率なども考慮していきます．例えば，部屋の広さ<span class="math notranslate nohighlight">\(x_{1}\)</span>,
駅からの距離<span class="math notranslate nohighlight">\(x_{2}\)</span>, …, 犯罪発生率<span class="math notranslate nohighlight">\(x_{M}\)</span> のように
<span class="math notranslate nohighlight">\(M\)</span> 個の入力変数があるとします．</p>
<p>単回帰分析と同様，以下の3つのステップで学習してきます．</p>
<ul class="simple">
<li>モデルを決める</li>
<li>目的関数を決める</li>
<li>最適なパラメータを求める</li>
</ul>
</div>
<div class="section" id="Step1.-モデルを決める">
<span id="step1-1"></span><h3>2.2.2. Step1. モデルを決める<a class="headerlink" href="#Step1.-モデルを決める" title="このヘッドラインへのパーマリンク">¶</a></h3>
<p>単回帰分析のモデルは，</p>
<div class="math notranslate nohighlight">
\[y = wx + b\]</div>
<p>であり，<span class="math notranslate nohighlight">\(w\)</span>を重み（weight），<span class="math notranslate nohighlight">\(b\)</span>をバイアス(bias)と呼びました．重回帰分析では，この式を複数の入力変数に拡張し，</p>
<div class="math notranslate nohighlight">
\[y=w_{1}x_{1}+w_{2}x_{2}+\ldots +w_{M}x_{M}+b\]</div>
<p>のような線形結合の形で表します．この場合，各変数は独立に出力変数を影響を与えるというようなモデル化であり，かなり単純なモデル化といえます．実際は問題にあわせて様々なモデルを考えそれらを選択する必要があります．それらについては今後説明していきます．</p>
<p>重回帰分析のモデルは，和の記号を使って次のように書くことができます．</p>
<div class="math notranslate nohighlight">
\[y = \sum_{m=1}^{M} w_{m} x_{m} + b\]</div>
<p>これをベクトルを使って表してみる．単回帰分析では，データの中心化によって，バイアス<span class="math notranslate nohighlight">\(b\)</span>を無視できように式変形を行ったが，前回はそれによって，求めるべきパラメータが<span class="math notranslate nohighlight">\(w\)</span>の１つだけになり，手計算の量が減るというメリットがあった．重回帰分析では，<span class="math notranslate nohighlight">\(b\)</span>が省略できたところで，パラメータの数が<span class="math notranslate nohighlight">\(M+1\)</span>個から<span class="math notranslate nohighlight">\(M\)</span>個に減るだけでほとんどメリットがない．そこで，入力変数で値が常に<span class="math notranslate nohighlight">\(1\)</span>であるような仮想変数<span class="math notranslate nohighlight">\(x_0 = 1\)</span>を加え，<span class="math notranslate nohighlight">\(w_0\)</span>をバイアスに対応させるようにする．</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
y&amp;=w_{1}x_{1}+w_{2}x_{2}+\ldots +w_{M}x_{M}+b\\
&amp;=w_{1}x_{1}+w_{2}x_{2}+\ldots +w_{M}x_{M}+w_{0} x_{0}\\
&amp;=w_{0}x_{0}+w_{1}x_{1}+\ldots +w_{M}x_{M}\\
\end{aligned}\end{split}\]</div>
<p>このようにバイアス<span class="math notranslate nohighlight">\(b\)</span>を重みに包含して書く記法は多くの登場する．そして，この式を整理していくと，</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
y&amp;=w_{0}x_{0}+w_{1}x_{1}+\ldots +w_{M}x_{M}\\
&amp;=\begin{bmatrix}
w_{0} &amp; w_{1} &amp; \ldots  &amp; w_{n}
\end{bmatrix}\begin{bmatrix}
x_{0} \\
x_{1} \\
\vdots  \\
x_{M}
\end{bmatrix}\\
&amp;=w^{T}x
\end{aligned}\end{split}\]</div>
<p>のように，ベクトルの内積で表現することができます．また，今後取り扱う際には，<span class="math notranslate nohighlight">\(x\)</span>が前に来ているほうが何かと便利なことからこれと等価な，</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\begin{split}  \begin{aligned}
  y&amp;=w_{0}x_{0}+w_{1}x_{1}+\ldots +w_{M}x_{M}\\
  &amp;=\begin{bmatrix}
  x_{0} &amp; x_{1} &amp; \ldots  &amp; x_{n}
  \end{bmatrix}\begin{bmatrix}
  w_{0} \\
  w_{1} \\
  \vdots  \\
  w_{M}
  \end{bmatrix}\\
  &amp;=x^{T}w
  \end{aligned}\end{split}\\として表すこともできます．今後はこちらを採用していきます．\end{aligned}\end{align} \]</div>
</div>
<div class="section" id="Step2.-目的関数を決める">
<span id="step2-1"></span><h3>2.2.3. Step2. 目的関数を決める<a class="headerlink" href="#Step2.-目的関数を決める" title="このヘッドラインへのパーマリンク">¶</a></h3>
<p>単回帰分析では，教師データ<span class="math notranslate nohighlight">\(t\)</span>と予測値<span class="math notranslate nohighlight">\(y\)</span>の二乗誤差が小さいほど，良い予測であるとし，この総和を目的関数として定めました．重回帰分析でも，予測値<span class="math notranslate nohighlight">\(y\)</span>を求めるということは同じであるため，次のような同じ目的関数を使います．</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}  \begin{aligned}
  L&amp;=\left( t_{1}-y_{1}\right)^{2}+\left( t_{2}-y_{2}\right)^{2}+\ldots + \left( t_{N}-y_{N}\right)^{2}
  \end{aligned}\\単回帰分析では，これを\end{aligned}\end{align} \]</div>
<div class="math notranslate nohighlight">
\[\mathcal{L}=\sum^{N}_{n=1} ( t_{n} - y_{n})^{2}\]</div>
<p>のように，総和の記号を使ってまとめていましたが，ここでも線形代数で学んだテクニックを活かして，</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
L&amp;=\left( t_{1}-y_{1}\right)^{2}+\left( t_{2}-y_{2}\right)^{2}+\ldots + \left( t_{N}-y_{N}\right)^{2}\\
&amp;=\begin{bmatrix} t_{1} - y_{1} &amp; t_{2}-y_{2} &amp; \ldots &amp; t_{N}-y_{N} \end{bmatrix} \begin{bmatrix}
t_{1}-y_{1} \\
t_{2}-y_{2} \\
\vdots \\
t_{N}-y_{N}
\end{bmatrix}\\
&amp;=\left( t-y\right)^{T}\left( t-y\right)
\end{aligned}\end{split}\]</div>
<p>のようにベクトルの内積で表現できます．また，<span class="math notranslate nohighlight">\(y\)</span>に関して，Step3に入る前に式を整理しておくと，</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\begin{split}  \begin{aligned}
  y=\begin{bmatrix}
  y_{1} \\
  y_{2} \\
  \vdots \\
  y_{N}
  \end{bmatrix}=\begin{bmatrix}
  x_{1}^{T}w \\
  x_{2}^{T}w \\
  \vdots  \\
  x_{N}^{T}w
  \end{bmatrix}
  =\begin{bmatrix}
  x_{1}^{T} \\
  x_{2}^{T} \\
  \vdots  \\
  x_{N}^{T}
  \end{bmatrix}
  w
  \end{aligned}\end{split}\\のように，書くことができます．整理すると\end{aligned}\end{align} \]</div>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
y&amp;=
\begin{bmatrix}
x_{10} &amp; x_{11} &amp; x_{12} &amp; \ldots  &amp; x_{1M} \\
x_{20} &amp; x_{21} &amp; x_{22} &amp; \ldots  &amp; x_{2M} \\
\vdots  &amp; \vdots  &amp; \ddots  &amp; \vdots  \\
x_{N0} &amp; x_{N1} &amp; x_{N{2}} &amp; \ldots  &amp; x_{NM}
\end{bmatrix}\begin{bmatrix}
w_{1} \\
w_{2} \\
\vdots  \\
w_{M}
\end{bmatrix}\\
\Rightarrow y&amp;=Xw
\end{aligned}\end{split}\]</div>
<p>と表記できます．ここでは<span class="math notranslate nohighlight">\(X\)</span>の行（横）方向が各サンプルを表しており，例えば各物件に相当します．列（縦）方向が入力変数を表しており，例えば，部屋の広さや駅からの距離などの各サンプルの値が入っています．例えば，部屋の広さ50m<span class="math notranslate nohighlight">\(^{2}\)</span>で駅からの距離600m,
犯罪発生率2%のような物件の場合，</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}  x^{T} = \begin{bmatrix}
  1 &amp; 50 &amp; 600 &amp; \cdots &amp; 0.02
  \end{bmatrix}\\のようにデータ表現されています．先頭の :math:`1`\end{aligned}\end{align} \]</div>
<p>はバイアスを包含する際に使用している<span class="math notranslate nohighlight">\(x_{0}\)</span>であることに注意してください．</p>
</div>
<div class="section" id="Step3.-パラメータを最適化する">
<h3>2.2.4. Step3. パラメータを最適化する<a class="headerlink" href="#Step3.-パラメータを最適化する" title="このヘッドラインへのパーマリンク">¶</a></h3>
<p>それでは，Step1で定めたモデルのパラメータを，Step2で定めた目的関数を最小化するように決めていきます．</p>
<p>まずは目的関数に関して，パラメータ<span class="math notranslate nohighlight">\(w\)</span>で表現できるように式変形を行うと，</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\begin{split}  \begin{aligned}
  \mathcal{L}&amp;=\left( t-y\right)^{T}\left( t-y\right) \\
  &amp;=\left( t-Xw\right)^{T}\left( t-Xw\right) \\
  &amp;= \left\{ t^{T}-(Xw)^{T}\right\}\left( t-Xw\right) \\
  &amp;=\left( t^{T}-w^{T}X^{T}\right)\left( t-Xw\right)
  \end{aligned}\end{split}\\となります．ここでは，転置の公式 :math:`(AB)^{T} = B^{T}A^{T}`\end{aligned}\end{align} \]</div>
<p>を使っています．さらに分配法則を使って展開を進めていくと，</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
\mathcal{L}&amp;=t^{T}t-t^{T}Xw-w^{T}X^{T}t + w^{T}X^{T}Xw\\
\end{aligned}\end{split}\]</div>
<p>となります．この目的関数に対しパラメータの<span class="math notranslate nohighlight">\(w\)</span>について偏微分をとりたいが，その前にこの式はもう少し整理することができます．はじめに，</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}  (1)^T = 1\\というように，スカラーは転置しても同じです．上式の中で出てくる\end{aligned}\end{align} \]</div>
<p><span class="math notranslate nohighlight">\(t^{T}Xw\)</span> はスカラーなので，</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}  (t^{T}Xw)^{T} = t^{T}Xw\\が成り立ちます．さらに，転置の公式 :math:`(ABC)^T = C^TB^TA^T` より，\end{aligned}\end{align} \]</div>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}  (t^{T}Xw)^T = w^{T} X^{T} t\\も成り立ちます．これより，\end{aligned}\end{align} \]</div>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}  (t^{T}Xw)^{T} = t^{T}Xw = w^{T} X^{T} t\\を導くことができます．これを使って目的関数を\end{aligned}\end{align} \]</div>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
\mathcal{L}=t^{T}t-2t^{T}Xw + w^{T}X^{T}Xw\\
\end{aligned}\end{split}\]</div>
<p>とまとめることができます．次に<span class="math notranslate nohighlight">\(w\)</span>に関する偏微分をとるにあたって</p>
<p><span class="math notranslate nohighlight">\(w\)</span>に以外の定数項をまとめると，</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
L&amp;=t^{T}t-2t^{T}Xw+w^{T}X^{T}Xw\\
&amp;=t^{T}t-2\left( X^{T}t\right)^{T} w+w^{T}X^{T}Xw \\
&amp;=c+b^{T}w+w^{T}Aw
\end{aligned}\end{split}\]</div>
<p>が得られます．これは，線形代数で学んだ<span class="math notranslate nohighlight">\(w\)</span>に関する二次関数となっており，<span class="math notranslate nohighlight">\(A= X^{T}X, \ b =-2 X^{T}t, \ c=t^{T}t\)</span>
と表せます．ここで，<span class="math notranslate nohighlight">\(b\)</span>
を転置の形式にした理由は，線形代数で学んだベクトルで微分の公式の形式に合わせるためである．</p>
<p>それでは，目的関数を最小化することができるパラメータ<span class="math notranslate nohighlight">\(w\)</span>の求め方を考える．先述の通り，目的関数はパラメータ<span class="math notranslate nohighlight">\(w\)</span>に関して二次関数である．例えば，</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\begin{split}  \begin{aligned}
  w = \begin{bmatrix}
  w_{1} \\ w_{2}
  \end{bmatrix},
  A=\begin{bmatrix}
  1 &amp; 2 \\
  3 &amp; 4
  \end{bmatrix},b=\begin{bmatrix}
  1 \\
  2
  \end{bmatrix},C=1
  \end{aligned}\end{split}\\のように具体的な数値例で考えてみると，\end{aligned}\end{align} \]</div>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\begin{split}  \begin{aligned}
  \mathcal{L} &amp;=
  w^{T}Aw+b^{T}w+c\\
  &amp;=
  \begin{bmatrix}
  w_{1} &amp; w_{2}
  \end{bmatrix}\begin{bmatrix}
  1 &amp; 2 \\
  3 &amp; 4
  \end{bmatrix}\begin{bmatrix}
  w_{1} \\
  w_{2}
  \end{bmatrix}
  +\begin{bmatrix}
  1 &amp; 2
  \end{bmatrix}\begin{bmatrix}
  w_{1} \\
  w_{2}
  \end{bmatrix}+1\\
  &amp;=
  \begin{bmatrix}
  w_{1} &amp; w_{2}
  \end{bmatrix}
  \begin{bmatrix}
  w_{1}+2w_{2} \\
  3w_{1}+4w_{2}
  \end{bmatrix}+w_{1}+2w_{2}+1\\
  &amp;=w_{1}\left( w_{1}+2w_{2}\right) +w_{1}\left( 3w_{1}+4w_{2}\right) +w _{1}+2w_{2}+1\\
  &amp;=w^{2}_{1}+5w_{1}w_{2}+4w^{2}_{2}+w_{1}+2w_{2}+1 \\
  \end{aligned}\end{split}\\となり，\ :math:`w_{1}, w_{2}`\ に関してそれぞれまとめると，\end{aligned}\end{align} \]</div>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\begin{split}  \begin{aligned}
  \mathcal{L}
  &amp;=w^{2}_{1}+\left( 5w_{2}+1\right) w_{1} +
  \left( 4w^{2}_{2}+2w_{2}+1\right) \\
  &amp;=w^{2}_{2}+\left( 5w_{1}+2\right) w_{2}+\left( w^{2}_{1}+w_{1}+1\right) \end{aligned}\end{split}\\のようにそれぞれの二次関数であることがわかります．\end{aligned}\end{align} \]</div>
<p>二次関数は一般に次のようなお椀型の形をとります．</p>
<div class="figure" id="id19">
<img alt="06.png" src="https://github.com/japan-medical-ai/medical-ai-course-materials/raw/master/notebooks/images/2/06.png" />
<p class="caption"><span class="caption-text">06.png</span></p>
</div>
<p>これを3次元でイメージすると，下図のようになります．</p>
<div class="figure" id="id20">
<img alt="08.png" src="https://github.com/japan-medical-ai/medical-ai-course-materials/raw/master/notebooks/images/2/08.png" />
<p class="caption"><span class="caption-text">08.png</span></p>
</div>
<p>そして，目的関数である二乗誤差の総和が最小となる点では各変数で微分した時の傾きが0となります．</p>
<div class="figure" id="id21">
<img alt="07.png" src="https://github.com/japan-medical-ai/medical-ai-course-materials/raw/master/notebooks/images/2/07.png" />
<p class="caption"><span class="caption-text">07.png</span></p>
</div>
<p>この例では，<span class="math notranslate nohighlight">\(w_{1}\)</span> と <span class="math notranslate nohighlight">\(w_{2}\)</span>
の２つのパラメータの場合で考えたが，これは <span class="math notranslate nohighlight">\(w_{1}\)</span>, <span class="math notranslate nohighlight">\(w_{2}\)</span>,
<span class="math notranslate nohighlight">\(\ldots\)</span>, <span class="math notranslate nohighlight">\(w_{M}\)</span>
の場合でも同様に考えることができ，目的関数が最小となる点は</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\begin{split}  \begin{cases}
  \dfrac {\partial }{\partial w_{0}}\mathcal{L}=0\\
  \dfrac {\partial }{\partial w_{1}}\mathcal{L}=0\\
  \ \ \ \ \ \vdots \\
  \dfrac {\partial }{\partial w_{M}}\mathcal{L}=0\\
  \end{cases}\end{split}\\となる点です．これをまとめると，\end{aligned}\end{align} \]</div>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
\begin{bmatrix}
\dfrac {\partial}{\partial w_{0}} \mathcal{L} \\
\dfrac {\partial}{\partial w_{1}} \mathcal{L} \\
\vdots  \\
\dfrac {\partial}{\partial w_{M}} \mathcal{L} \\
\end{bmatrix}&amp;=\begin{bmatrix}
0 \\
0 \\
\vdots  \\
0 \\
\end{bmatrix} \\
\Rightarrow \dfrac {\partial}{\partial w} \mathcal{L} &amp;= 0 \\
\end{aligned}\end{split}\]</div>
<p>のように表されます．あとは，上式を満たすように<span class="math notranslate nohighlight">\(w\)</span>を決めていけばいきます．下記の計算にはベクトルの微分をはじめとして，線形代数で学んだ内容を利用しています．必要に応じて線形代数の章を確認してください．</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
\dfrac {\partial }{\partial w}\mathcal{L}
&amp;= \dfrac {\partial }{aw}\left( c+b^{T}w+w^{T}Aw\right) \\
&amp;\Rightarrow \dfrac {\partial }{\partial u}\left( c\right) +\dfrac {\partial }{\partial w}\left( b^{T}w\right) +\dfrac {\partial }{\partial w}\left( w^{T}Aw\right)
= 0\\
&amp;\Rightarrow 0+b+\left( A+A^{T}\right) w =0\\
&amp;\Rightarrow -2X^{T}t+\left\{ X^{T}X^{T}\left( X^{T}X\right)^{T}\right\} w
=0\\
&amp;\Rightarrow -2X^{T}t+2X^{T}Xw=0\\
&amp;\Rightarrow X^{T}Xw=X^{T}t\\
&amp;\Rightarrow \left( X^{T}X\right)^{-1}X^{T}X w =\left( X^{T}X\right)^{-1}X^{T}t \\
Iw&amp;=\left( X^{T}X\right)^{-1}X^{T}t \\
w&amp;=\left( X^{T}X\right)^{-1}X^{T}t
\end{aligned}\end{split}\]</div>
<p>ここで，<span class="math notranslate nohighlight">\(I\)</span>は単位行列です．このように，最適なパラメータは与えられているデータセット
<span class="math notranslate nohighlight">\(X, t\)</span> から求まります．また，式変形の際には</p>
<div class="math notranslate nohighlight">
\[w = \dfrac{X^{T}t}{X^{T}X}\]</div>
<p>のような分数が表れないように注意してください．これは行列の計算には割り算がないためです．そのため，逆行列を使って行列積のみで計算しています．</p>
<p>また，もうひとつよくある間違いとして，</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
X^{T}Xw&amp;=X^{T}t\\
\Rightarrow \left( X^{T}\right) ^{-1}X^{T}Xw&amp;=\left( X^{T}\right) ^{-1}X^{T}t\\
\Rightarrow Xw&amp;=t\\
\Rightarrow X^{-1}Xw&amp;=X^{-1}t\\
\Rightarrow w&amp;=X^{-1}t
\end{aligned}\end{split}\]</div>
<p>のような式変形をする場合もみられます．しかし，これは一般的には成立しません．なぜなら，線形代数の章で説明した逆行列を持つための条件として，行列は正方行列であるという条件を満たしていないためです．一般的に，サンプル数<span class="math notranslate nohighlight">\(N\)</span>と入力変数の数<span class="math notranslate nohighlight">\(M\)</span>は等しくないため<span class="math notranslate nohighlight">\(X\)</span>は正方行列ではなく，逆行列をもちません．それに対し，<span class="math notranslate nohighlight">\(X \in \mathcal{R}^{N \times M}\)</span>
の場合，<span class="math notranslate nohighlight">\(X^{T}X \in \mathcal{R}^{M\times M}\)</span>
となり，サンプル数に依存することなく，常に正方行列となります．</p>
<p>また</p>
<p>また<span class="math notranslate nohighlight">\(X^T X\)</span>が正方行列だからといって必ず逆行列を持つとは限らない，または逆行列を持ったとしても数値計算が不安定になるという問題がある．これについて，今回は解説しないが，疑似逆行列とよばれる手法を使うことが多い．</p>
<p>推論の際は学習で得られたパラメータ<span class="math notranslate nohighlight">\(w\)</span>を用いて，</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}  y = w^{T}x\\のように計算すれば良い．\end{aligned}\end{align} \]</div>
</div>
</div>
<div class="section" id="Numpyによる実装">
<h2>2.3. Numpyによる実装<a class="headerlink" href="#Numpyによる実装" title="このヘッドラインへのパーマリンク">¶</a></h2>
<p>それでは，重回帰分析の実装を行います．PythonにはNumpyと呼ばれる線形代数を簡単に扱えるライブラリが広く使われている．次の章で紹介するChainerの中でもNumpyは多用されている．</p>
<p>Pythonの文法に関しては把握していることを前提に進めてきます．具体的には，変数（数値・文字列，リスト，タプル，辞書），制御構文（for，if），関数，クラスを理解している必要があります</p>
<p>重回帰分析では，最終的に最適なパラメータ <span class="math notranslate nohighlight">\(w\)</span> が</p>
<div class="math notranslate nohighlight">
\[w=\left( X^{T}X\right)^{-1}X^{T}t\]</div>
<p>で求まります．この最適なパラメータを求めるため次の5つを扱います．</p>
<ul class="simple">
<li>ベクトルの定義</li>
<li>行列の定義</li>
<li>転置</li>
<li>行列積</li>
<li>逆行列</li>
</ul>
<p>具体的に，以下のようなデータセットが与えられているケースを想定してみましょう．</p>
<div class="math notranslate nohighlight">
\[\begin{split}X =
\begin{bmatrix}
1 &amp; 2 &amp; 3 \\
1 &amp; 2 &amp; 5 \\
1 &amp; 3 &amp; 4 \\
1 &amp; 5 &amp; 9
\end{bmatrix}, \
t =
\begin{bmatrix}
1 \\ 5 \\ 6 \\ 8
\end{bmatrix}\end{split}\]</div>
<p>それぞれの実装について，見ていきましょう．まずは，Numpyの読み込みから始めます．numpyはnpと省略するのが一般的です．</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>import numpy as np
</pre></div>
</div>
</div>
<p>ベクトルの定義は以下のように行います．</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>t = np.array([[1], [5], [6], [8]])
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [3]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>print(t.shape)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
(4, 1)
</pre></div></div>
</div>
<p>つぎに，行列の定義も行いましょう．</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>X = np.array([
    [1, 2, 3],
    [1, 2, 5],
    [1, 3, 4],
    [1, 5, 9]
])
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [5]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>print(X)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[[1 2 3]
 [1 2 5]
 [1 3 4]
 [1 5 9]]
</pre></div></div>
</div>
<p>次は行列の転地を行う．Numpyの<code class="docutils literal notranslate"><span class="pre">array</span></code>で定義されている場合，<code class="docutils literal notranslate"><span class="pre">.T</span></code>をつけるだけで転置ができる．</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [6]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>print(X.T)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[[1 1 1 1]
 [2 2 3 5]
 [3 5 4 9]]
</pre></div></div>
</div>
<p>次に，行列積は <code class="docutils literal notranslate"><span class="pre">np.dot</span></code>
によって実現できる．行列積の際には最初の行列の列数と二番目の行列の行数が同じであることに注意する．</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>XX = np.dot(X.T, X)
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [8]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>print(XX)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[[  4  12  21]
 [ 12  42  73]
 [ 21  73 131]]
</pre></div></div>
</div>
<p>つぎに，この逆行列を求めるには，<code class="docutils literal notranslate"><span class="pre">np.linalg.inv</span></code> を用いる．</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>XX_inv = np.linalg.inv(XX)
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [10]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>print(XX_inv)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[[ 1.76530612 -0.39795918 -0.06122449]
 [-0.39795918  0.84693878 -0.40816327]
 [-0.06122449 -0.40816327  0.24489796]]
</pre></div></div>
</div>
<p>これで重回帰分析のために必要な演算がそろった．最適なパラメータを求めると，</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>Xt = np.dot(X.T, t)
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [12]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>print(Xt)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[[ 20]
 [ 70]
 [124]]
</pre></div></div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>w = np.dot(XX_inv, Xt)
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [14]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>print(w)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[[-0.14285714]
 [ 0.71428571]
 [ 0.57142857]]
</pre></div></div>
</div>
<p>このように求まります．Numpyを使うことで，数式をそのままプログラミング上で書くことができます．</p>
</div>
<div class="section" id="Scikit-learnによる本格的な実装">
<h2>2.4. Scikit-learnによる本格的な実装<a class="headerlink" href="#Scikit-learnによる本格的な実装" title="このヘッドラインへのパーマリンク">¶</a></h2>
<p>重回帰分析であればNumpyで簡単に実装することができましたが，本格的に使用していくアルゴリズムは初学者が一から書くには難しく，またその必要はない．PythonではScikit-learnと呼ばれる機械学習用のフレームワークが公開されており，初学者でも簡単に扱うことができます．</p>
<p>まずは重回帰分析をScikit-learnによって実装してみましょう．</p>
<div class="section" id="Scikit-learn基礎編">
<h3>2.4.1. Scikit-learn基礎編<a class="headerlink" href="#Scikit-learn基礎編" title="このヘッドラインへのパーマリンク">¶</a></h3>
<p>Scikit-learnは<code class="docutils literal notranslate"><span class="pre">sklearn</span></code>という名前で呼び出すことができます．</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>import sklearn
</pre></div>
</div>
</div>
<p>たとえば，重回帰分析を使用する場合は以下のように呼び出す．</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>from sklearn.linear_model import LinearRegression
</pre></div>
</div>
</div>
<p>なお，numpyの時もそうだが，使い方を調べる際，<a class="reference external" href="http://scikit-learn.org/">公式のリファレンス</a>に加えて，「重回帰分析
Scikit-learn」というように検索して，実例のソースコードを見るほうが早い場合も多くあります．</p>
<p>はじめにアルゴリズムのインスタンス化を行います．</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>model = LinearRegression()
</pre></div>
</div>
</div>
<p>これで重回帰分析を使用するための準備がおわりました．次にパラメータの学習も以下のように行います．</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [18]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>model.fit(X, t)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>Out[18]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)
</pre></div>
</div>
</div>
<p>最後にどのような結果が得られたかの検証は次のように行なえます．</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [19]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>model.score(X, t)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>Out[19]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>0.6923076923076923
</pre></div>
</div>
</div>
<p>回帰では<strong>決定係数</strong>と呼ばれる指標が，分類の場合は<strong>精度</strong>が自動的に計算されるようになっている．どちらも1に近ければうまくモデルがデータを説明できていることになります．
このように，簡単なインターフェースで機械学習のモデルを構築し，学習できるようになっています．Scikit-learnの良い点は最初にアルゴリズムを決めてしまえば，どのアルゴリズムでも，<code class="docutils literal notranslate"><span class="pre">.fit</span></code>で学習，<code class="docutils literal notranslate"><span class="pre">.score</span></code>で検証が行える点です．</p>
<p>また，アルゴリズムによって内容は多少異なるが，パラメータもインスタンス変数として格納されているため，学習後に確認することができます．</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [20]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># パラメータw
model.coef_
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>Out[20]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>array([[0.        , 0.71428571, 0.57142857]])
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [21]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># バイアスb
model.intercept_
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>Out[21]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>array([-0.14285714])
</pre></div>
</div>
</div>
<p>この例からわかるように，Scikit-learnでは，パラメータとバイアスがそれぞれ準備されているため，入力変数<span class="math notranslate nohighlight">\(X\)</span>の左端の列に1を格納した変数を入れる必要はありません．</p>
</div>
<div class="section" id="Scikit-learn応用編">
<h3>2.4.2. Scikit-learn応用編<a class="headerlink" href="#Scikit-learn応用編" title="このヘッドラインへのパーマリンク">¶</a></h3>
<p>Scikit-learnは機械学習の実装を支援する多くの機能を兼ね備えています．</p>
<p>まず最初にサンプルのデータセットの取り扱いを紹介します．Scikit-learnには学び始めでテストするために，データセットがいくつか提供されています．今回は，この提供されているデータセットの中で<code class="docutils literal notranslate"><span class="pre">load_boston</span></code>というボストン近郊の家賃に関するデータセットを使って説明してきます．</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>from sklearn.datasets import load_boston
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>boston = load_boston()
</pre></div>
</div>
</div>
<p>変数の<code class="docutils literal notranslate"><span class="pre">boston</span></code>には辞書と同じ形式で格納されており，変数の中身を見ながら入力変数と教師データに対応するものを見つけていきます．</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>X = boston[&#39;data&#39;]
t = boston[&#39;target&#39;]
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [25]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>print(X)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[[6.3200e-03 1.8000e+01 2.3100e+00 ... 1.5300e+01 3.9690e+02 4.9800e+00]
 [2.7310e-02 0.0000e+00 7.0700e+00 ... 1.7800e+01 3.9690e+02 9.1400e+00]
 [2.7290e-02 0.0000e+00 7.0700e+00 ... 1.7800e+01 3.9283e+02 4.0300e+00]
 ...
 [6.0760e-02 0.0000e+00 1.1930e+01 ... 2.1000e+01 3.9690e+02 5.6400e+00]
 [1.0959e-01 0.0000e+00 1.1930e+01 ... 2.1000e+01 3.9345e+02 6.4800e+00]
 [4.7410e-02 0.0000e+00 1.1930e+01 ... 2.1000e+01 3.9690e+02 7.8800e+00]]
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [26]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>print(t)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[24.  21.6 34.7 33.4 36.2 28.7 22.9 27.1 16.5 18.9 15.  18.9 21.7 20.4
 18.2 19.9 23.1 17.5 20.2 18.2 13.6 19.6 15.2 14.5 15.6 13.9 16.6 14.8
 18.4 21.  12.7 14.5 13.2 13.1 13.5 18.9 20.  21.  24.7 30.8 34.9 26.6
 25.3 24.7 21.2 19.3 20.  16.6 14.4 19.4 19.7 20.5 25.  23.4 18.9 35.4
 24.7 31.6 23.3 19.6 18.7 16.  22.2 25.  33.  23.5 19.4 22.  17.4 20.9
 24.2 21.7 22.8 23.4 24.1 21.4 20.  20.8 21.2 20.3 28.  23.9 24.8 22.9
 23.9 26.6 22.5 22.2 23.6 28.7 22.6 22.  22.9 25.  20.6 28.4 21.4 38.7
 43.8 33.2 27.5 26.5 18.6 19.3 20.1 19.5 19.5 20.4 19.8 19.4 21.7 22.8
 18.8 18.7 18.5 18.3 21.2 19.2 20.4 19.3 22.  20.3 20.5 17.3 18.8 21.4
 15.7 16.2 18.  14.3 19.2 19.6 23.  18.4 15.6 18.1 17.4 17.1 13.3 17.8
 14.  14.4 13.4 15.6 11.8 13.8 15.6 14.6 17.8 15.4 21.5 19.6 15.3 19.4
 17.  15.6 13.1 41.3 24.3 23.3 27.  50.  50.  50.  22.7 25.  50.  23.8
 23.8 22.3 17.4 19.1 23.1 23.6 22.6 29.4 23.2 24.6 29.9 37.2 39.8 36.2
 37.9 32.5 26.4 29.6 50.  32.  29.8 34.9 37.  30.5 36.4 31.1 29.1 50.
 33.3 30.3 34.6 34.9 32.9 24.1 42.3 48.5 50.  22.6 24.4 22.5 24.4 20.
 21.7 19.3 22.4 28.1 23.7 25.  23.3 28.7 21.5 23.  26.7 21.7 27.5 30.1
 44.8 50.  37.6 31.6 46.7 31.5 24.3 31.7 41.7 48.3 29.  24.  25.1 31.5
 23.7 23.3 22.  20.1 22.2 23.7 17.6 18.5 24.3 20.5 24.5 26.2 24.4 24.8
 29.6 42.8 21.9 20.9 44.  50.  36.  30.1 33.8 43.1 48.8 31.  36.5 22.8
 30.7 50.  43.5 20.7 21.1 25.2 24.4 35.2 32.4 32.  33.2 33.1 29.1 35.1
 45.4 35.4 46.  50.  32.2 22.  20.1 23.2 22.3 24.8 28.5 37.3 27.9 23.9
 21.7 28.6 27.1 20.3 22.5 29.  24.8 22.  26.4 33.1 36.1 28.4 33.4 28.2
 22.8 20.3 16.1 22.1 19.4 21.6 23.8 16.2 17.8 19.8 23.1 21.  23.8 23.1
 20.4 18.5 25.  24.6 23.  22.2 19.3 22.6 19.8 17.1 19.4 22.2 20.7 21.1
 19.5 18.5 20.6 19.  18.7 32.7 16.5 23.9 31.2 17.5 17.2 23.1 24.5 26.6
 22.9 24.1 18.6 30.1 18.2 20.6 17.8 21.7 22.7 22.6 25.  19.9 20.8 16.8
 21.9 27.5 21.9 23.1 50.  50.  50.  50.  50.  13.8 13.8 15.  13.9 13.3
 13.1 10.2 10.4 10.9 11.3 12.3  8.8  7.2 10.5  7.4 10.2 11.5 15.1 23.2
  9.7 13.8 12.7 13.1 12.5  8.5  5.   6.3  5.6  7.2 12.1  8.3  8.5  5.
 11.9 27.9 17.2 27.5 15.  17.2 17.9 16.3  7.   7.2  7.5 10.4  8.8  8.4
 16.7 14.2 20.8 13.4 11.7  8.3 10.2 10.9 11.   9.5 14.5 14.1 16.1 14.3
 11.7 13.4  9.6  8.7  8.4 12.8 10.5 17.1 18.4 15.4 10.8 11.8 14.9 12.6
 14.1 13.  13.4 15.2 16.1 17.8 14.9 14.1 12.7 13.5 14.9 20.  16.4 17.7
 19.5 20.2 21.4 19.9 19.  19.1 19.1 20.1 19.9 19.6 23.2 29.8 13.8 13.3
 16.7 12.  14.6 21.4 23.  23.7 25.  21.8 20.6 21.2 19.1 20.6 15.2  7.
  8.1 13.6 20.1 21.8 24.5 23.1 19.7 18.3 21.2 17.5 16.8 22.4 20.6 23.9
 22.  11.9]
</pre></div></div>
</div>
<p>Numpyの形式で入力変数と教師データが格納されており，<code class="docutils literal notranslate"><span class="pre">.shape</span></code>を使うことで行と列の数を確認できる．</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [27]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>X.shape
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>Out[27]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>(506, 13)
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [28]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>t.shape
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>Out[28]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>(506,)
</pre></div>
</div>
</div>
<p>つぎに，訓練データと検証データの分割です．学習の時と同じデータを使って性能を検証した場合，モデルが学習データだけをうまくモデル化し，同じような分布からとられた未知のデータはうまくいかない場合があります．これを過学習とよびます．機械学習ではこれを防ぐために学習データと別に性能を評価する検証データを分けて評価します．このように分割して検証することを<strong>ホールドアウト法</strong>とよびます．</p>
<p>Scikit-learnではこの訓練用と検証用を分割する機能が準備されています．</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>from sklearn.model_selection import train_test_split
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>X_train, X_test, t_train, t_test = train_test_split(X, t, test_size=0.3, random_state=0)
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [31]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>X_train.shape
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>Out[31]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>(354, 13)
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [32]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>X_test.shape
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>Out[32]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>(152, 13)
</pre></div>
</div>
</div>
<p>引数の<code class="docutils literal notranslate"><span class="pre">test_size</span></code>は検証用に使うデータの比率であり，0.3と指定すると全体の30%が検証データとなります．また，<code class="docutils literal notranslate"><span class="pre">random_state</span></code>は乱数のシードであり，再現性を確保するためのものです．なぜ乱数が登場するかというと，前から70%を訓練用，残りを検証用とするのではなく，全体からランダムに選択した70%を訓練用，残り30%を検証用と選択しているためです．</p>
<p>そして，訓練データを使って学習します．</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>model = LinearRegression()
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [34]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>model.fit(X_train, t_train)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>Out[34]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)
</pre></div>
</div>
</div>
<p>検証を行う場合は，訓練データと検証データの両方に対してチェックしておくと良いでしょう．</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [35]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># 訓練データ
model.score(X_train, t_train)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>Out[35]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>0.7644563391821222
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [36]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># 検証データ
model.score(X_test, t_test)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>Out[36]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>0.6735280865347263
</pre></div>
</div>
</div>
<p>検証データだけでなく，訓練データでも検証することで学習に失敗している場合の問題を切り分けることができます．</p>
<table border="1" class="docutils">
<colgroup>
<col width="22%" />
<col width="22%" />
<col width="56%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">訓練データ</th>
<th class="head">検証データ</th>
<th class="head">結果</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>×</td>
<td>×</td>
<td>未学習 アンダーフィッティング</td>
</tr>
<tr class="row-odd"><td>〇</td>
<td>×</td>
<td>過学習 オーバーフィッティング</td>
</tr>
<tr class="row-even"><td>〇</td>
<td>〇</td>
<td>ＯＫ</td>
</tr>
</tbody>
</table>
<p><strong>アンダーフィッティング</strong>の場合は，現状の機械学習アルゴリズムでうまくデータを扱えていない場合であり，アルゴリズムを変更したり，入力となるデータの特徴を表せるような変換を考えます．逆に<strong>オーバーフィッティング</strong>の時は，そのアルゴリズムでデータをモデル化できていることはわかっている．この場合，モデルを過学習させないようにする．代表的な方法として，<strong>ハイパーパラメータ</strong>と呼ばれる各アルゴリズムのパラメータの学習に使われるパラメータの値を調整していくことで解決できることがある．このハイパーパラメータの調整は後述する．</p>
<p>また，Scikit-learnでは，スケーリングも行うことができます．例えば，平均0，標準偏差1に変換するデータの正規化を行う場合は以下のようになります．</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>from sklearn.preprocessing import StandardScaler
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># インスタンス化
scaler = StandardScaler()
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [39]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># 平均の分散（標準偏差）を学習
scaler.fit(X_train)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>Out[39]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>StandardScaler(copy=True, with_mean=True, with_std=True)
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># 変換
X_train_s = scaler.transform(X_train)
X_test_s  = scaler.transform(X_test)
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [41]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>print(X_train_s)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[[-0.20416267 -0.49997924  1.54801583 ...  1.2272573   0.42454294
   3.10807269]
 [-0.38584317  0.34677427 -0.58974728 ...  0.05696346  0.40185312
  -0.66643035]
 [-0.33266283 -0.49997924  1.54801583 ...  1.2272573   0.39846135
   0.63936662]
 ...
 [-0.38147768 -0.49997924 -0.15303077 ... -0.30312696  0.39659002
  -0.30284441]
 [-0.3720831  -0.49997924 -0.59690657 ... -0.25811566  0.37588849
   0.89967717]
 [-0.38289844 -0.49997924 -1.00641779 ... -0.84326258  0.42454294
   0.31822262]]
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [42]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>print(X_test_s)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[[-0.39152624 -0.49997924 -1.12239824 ... -0.70822867  0.17086147
  -0.72160487]
 [ 0.70825498 -0.49997924  1.00534187 ...  0.77714428  0.0648977
  -0.41177872]
 [-0.38588517 -0.49997924  0.4025299  ... -0.93328518  0.38758427
  -0.27454978]
 ...
 [ 1.6177735  -0.49997924  1.00534187 ...  0.77714428  0.42454294
   2.59876943]
 [-0.34043865 -0.49997924 -0.1687812  ... -0.03305915  0.42454294
  -1.11772962]
 [-0.39601293 -0.49997924 -1.27417512 ...  0.10197476  0.39202867
  -1.02294263]]
</pre></div></div>
</div>
</div>
</div>
<div class="section" id="よく使われる機械学習アルゴリズムの紹介">
<h2>2.5. よく使われる機械学習アルゴリズムの紹介<a class="headerlink" href="#よく使われる機械学習アルゴリズムの紹介" title="このヘッドラインへのパーマリンク">¶</a></h2>
<p>ここからはよく用いられる機械学習アルゴリズムについて特徴とともに紹介していきます．ここでは概要だけ紹介するので気になった場合は参考図書を見て学びを深めてほしい．</p>
<p>Scikit-learnを使うことで実装は手軽に行うことができるが，内部挙動を理解していないがゆえに，うまくいかないときの対処法がわからないという問題もでてきます．ここでは．この問題につまずかないように，ハイパーパラメータのチューニングもあわせて紹介していきます．</p>
<div class="section" id="Support-Vector-Machine-(SVM)">
<h3>2.5.1. Support Vector Machine (SVM)<a class="headerlink" href="#Support-Vector-Machine-(SVM)" title="このヘッドラインへのパーマリンク">¶</a></h3>
<p>SVMはよく使われる手法の一つであり，入出力間の非線形性を捉えることができます．ただし，非線形なモデルの場合，<span class="math notranslate nohighlight">\(y=wx^2\)</span>や，<span class="math notranslate nohighlight">\(y=w\sin(x)\)</span>やその重ね合わせといったように組み合わせの候補が無限に存在するためモデルの設計は難しうなります．物理現象に基づいて入出力間の関係性が把握できていれば定式化のアイディアも存在しますが，そのような事前知識がある場合は多くはありません．そこで，SVMでは<strong>カーネルトリック</strong>と呼ばれるテクニックを利用し，データ間の類似度（カーネル）から入出力間の非線形性の定式化を行います．</p>
<p>SVMには連続値を予測する<strong>回帰 (Regression)</strong>
とカテゴリを予測する<strong>分類 (Classification)</strong>
の両方に対応した手法があります．それぞれ，Support Vector Regression
(SVR) と Support Vector Classification (SVC)
と呼びます．まずは回帰の問題設定で紹介し，前回のボストン近郊の家賃の予測の例題を取扱います．</p>
<div class="section" id="Support-Vector-Regression-(SVR)">
<h4>2.5.1.1. Support Vector Regression (SVR)<a class="headerlink" href="#Support-Vector-Regression-(SVR)" title="このヘッドラインへのパーマリンク">¶</a></h4>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># データの準備
from sklearn.datasets import load_boston

boston = load_boston()
X = boston[&#39;data&#39;]
t = boston[&#39;target&#39;]
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># 訓練と検証データの分割
from sklearn.model_selection import train_test_split

X_train, X_test, t_train, t_test = train_test_split(X, t, test_size=0.3, random_state=0)
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [45]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># モデルのインスタンス化，学習
from sklearn.svm import SVR

model = SVR()
model.fit(X_train, t_train)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>Out[45]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma=&#39;auto&#39;,
  kernel=&#39;rbf&#39;, max_iter=-1, shrinking=True, tol=0.001, verbose=False)
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [46]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># 検証（訓練データ）
model.score(X_train, t_train)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>Out[46]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>0.14680479454958428
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [47]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># 検証（検証データ）
model.score(X_test, t_test)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>Out[47]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>0.01018093344367077
</pre></div>
</div>
</div>
<p>このようにSVRも，重回帰分析のケースとほとんど同じように実装できます．</p>
<p>しかし結果は重回帰分析に比べて良くなっているとはいえません．
ハイパーパラメータの調整が必要そうだが，その前に，スケーリングを行うことで改善ができる場合が多くあります．</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
scaler.fit(X_train)

X_train_s = scaler.transform(X_train)
X_test_s = scaler.transform(X_test)
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [49]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># スケーリング後のデータを使って学習
model.fit(X_train_s, t_train)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>Out[49]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma=&#39;auto&#39;,
  kernel=&#39;rbf&#39;, max_iter=-1, shrinking=True, tol=0.001, verbose=False)
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [50]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># 検証（訓練データ）
model.score(X_train_s, t_train)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>Out[50]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>0.697669153907031
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [51]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># 検証（検証データ）
model.score(X_test_s, t_test)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>Out[51]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>0.5540391127752358
</pre></div>
</div>
</div>
<p>このように，大幅に結果を改善することができますスケーリングの影響を大きく受けるアルゴリズムと受けないアルゴリズムがあり，SVRを含むSVMはその影響を受けるアルゴリズムです．</p>
<p>最後に，さらに精度を上げるためにハイパーパラメータの調整を行います．ハイパーパラメータの調整を行うときに注意すべき点があります．それは訓練データ（train）はパラメータの調整に用いるが，検証データ（test）を見ながらハイパーパラーメータの調整を行なってはいけないということです．．検証データはあくまで未知のデータに対する性能検証を行うために用意したものであり，ハイパーパラメータの調整に検証データを使用してしまうと検証データの情報が学習にリークし正しい検証ができなくなります．</p>
<p>そこで，ハイパーパラメータの調整用にバリデーションデータ
（val）を追加することが一般的です．</p>
<div class="figure" id="id22">
<img alt="09.png" src="https://github.com/japan-medical-ai/medical-ai-course-materials/raw/master/notebooks/images/2/09.png" />
<p class="caption"><span class="caption-text">09.png</span></p>
</div>
<p>また，<strong>交差検証法（クロスバリデーション）</strong>という手法もあります．これは下図に示すようデータを複数パターン分割し，それらの性能の平均を評価する手法です．</p>
<div class="figure" id="id23">
<img alt="10.png" src="https://github.com/japan-medical-ai/medical-ai-course-materials/raw/master/notebooks/images/2/10.png" />
<p class="caption"><span class="caption-text">10.png</span></p>
</div>
<p>この分割数 <span class="math notranslate nohighlight">\(K\)</span> として，K-fold Cross Validation
(CV)と呼ばれることも多くあります．例えば上記の例だと
<span class="math notranslate nohighlight">\(K=3\)</span>-CVとなります．</p>
<p>それでは，SVRのハイパーパラメータ調整を交差検証法を使って行いましょう．Scikit-learnではハイパーパラメータ調整のための機能も<code class="docutils literal notranslate"><span class="pre">GridSearchCV</span></code>という名前で準備されています．グリッドサーチとは各組合せをすべて試す探索方法である．それ以外の方法として，ランダムサーチとベイズ最適化による探索もありますが，ここは余裕がでてきた段階でさらに深める内容のひとつとしてください．</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>from sklearn.model_selection import GridSearchCV
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># 調整を行うハイパーパラメータの値の候補
param_grid = [
    {&#39;C&#39;: [1, 10, 100], &#39;gamma&#39;: [0.01, 0.1, 1, 10]}
]
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [54]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># 交差検証法を使用したハイパーパラメータの各組合せでの学習
model_cv = GridSearchCV(SVR(), param_grid, cv=3, scoring=&#39;neg_mean_squared_error&#39;)
model_cv.fit(X_train_s, t_train)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>Out[54]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>GridSearchCV(cv=3, error_score=&#39;raise&#39;,
       estimator=SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma=&#39;auto&#39;,
  kernel=&#39;rbf&#39;, max_iter=-1, shrinking=True, tol=0.001, verbose=False),
       fit_params=None, iid=True, n_jobs=1,
       param_grid=[{&#39;C&#39;: [1, 10, 100], &#39;gamma&#39;: [0.01, 0.1, 1, 10]}],
       pre_dispatch=&#39;2*n_jobs&#39;, refit=True, return_train_score=&#39;warn&#39;,
       scoring=&#39;neg_mean_squared_error&#39;, verbose=0)
</pre></div>
</div>
</div>
<p>交差検証法とハイパーパラメータのグリッドサーチもこれで完了です．各ハイパーパラメータでの結果ももちろん確認することができ，最も結果の良かったハイパーパラメータの値を引き継いだモデルの選択もできます．</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [55]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># 結果の確認 (valの対する結果)
model_cv.grid_scores_
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="stderr output_area docutils container">
<div class="highlight"><pre>
/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:762: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20
  DeprecationWarning)
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>Out[55]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>[mean: -40.88957, std: 12.03388, params: {&#39;C&#39;: 1, &#39;gamma&#39;: 0.01},
 mean: -34.94548, std: 12.18057, params: {&#39;C&#39;: 1, &#39;gamma&#39;: 0.1},
 mean: -72.62060, std: 15.99632, params: {&#39;C&#39;: 1, &#39;gamma&#39;: 1},
 mean: -86.25200, std: 16.38372, params: {&#39;C&#39;: 1, &#39;gamma&#39;: 10},
 mean: -17.67763, std: 6.48783, params: {&#39;C&#39;: 10, &#39;gamma&#39;: 0.01},
 mean: -16.46703, std: 7.03969, params: {&#39;C&#39;: 10, &#39;gamma&#39;: 0.1},
 mean: -43.71719, std: 13.22953, params: {&#39;C&#39;: 10, &#39;gamma&#39;: 1},
 mean: -81.13324, std: 15.21847, params: {&#39;C&#39;: 10, &#39;gamma&#39;: 10},
 mean: -13.83363, std: 3.54540, params: {&#39;C&#39;: 100, &#39;gamma&#39;: 0.01},
 mean: -14.61609, std: 7.20850, params: {&#39;C&#39;: 100, &#39;gamma&#39;: 0.1},
 mean: -37.47299, std: 9.87515, params: {&#39;C&#39;: 100, &#39;gamma&#39;: 1},
 mean: -77.95797, std: 12.36436, params: {&#39;C&#39;: 100, &#39;gamma&#39;: 10}]
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [56]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># 最も結果が良かったハイパーパラメータ
model_cv.best_params_
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>Out[56]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>{&#39;C&#39;: 100, &#39;gamma&#39;: 0.01}
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># 最も結果が良かったハイパーパラメータの値を設定したモデル
model = model_cv.best_estimator_
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [58]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># 検証（検証データ）
model.score(X_test_s, t_test)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>Out[58]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>0.7685336670918768
</pre></div>
</div>
</div>
<p>ここまでがアルゴリズムの調整である．実際には特徴量の選択や外れ値除去など前処理も込みで行うため，ここまでシンプルに完了できるものではないが，まずはこの流れを覚えていただきたい．</p>
<ol class="arabic simple">
<li>スケーリング無　score:0.010</li>
<li>スケーリング有　score:0.554</li>
<li>スケーリング＋ハイパーパラメータの調整有　0.7685</li>
</ol>
</div>
<div class="section" id="Support-Vector-Classification-(SVC)">
<h4>2.5.1.2. Support Vector Classification (SVC)<a class="headerlink" href="#Support-Vector-Classification-(SVC)" title="このヘッドラインへのパーマリンク">¶</a></h4>
<p>次に，SVMの分類であるSVCも同様にスケーリングからハイパーパラメータの調整まで行う．分類の例題では，乳がんの患者か否かといったこれもScikit-learn側で準備されているデータセットを使用する．</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># データセットの準備
from sklearn.datasets import load_breast_cancer

breast_cancer = load_breast_cancer()
X = breast_cancer[&#39;data&#39;]
t = breast_cancer[&#39;target&#39;]
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [60]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>X.shape
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>Out[60]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>(569, 30)
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [61]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>print(X)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[[1.799e+01 1.038e+01 1.228e+02 ... 2.654e-01 4.601e-01 1.189e-01]
 [2.057e+01 1.777e+01 1.329e+02 ... 1.860e-01 2.750e-01 8.902e-02]
 [1.969e+01 2.125e+01 1.300e+02 ... 2.430e-01 3.613e-01 8.758e-02]
 ...
 [1.660e+01 2.808e+01 1.083e+02 ... 1.418e-01 2.218e-01 7.820e-02]
 [2.060e+01 2.933e+01 1.401e+02 ... 2.650e-01 4.087e-01 1.240e-01]
 [7.760e+00 2.454e+01 4.792e+01 ... 0.000e+00 2.871e-01 7.039e-02]]
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [62]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>print(t)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 0 0 0 0 0 0 0 0 1 0 1 1 1 1 1 0 0 1 0 0 1 1 1 1 0 1 0 0 1 1 1 1 0 1 0 0
 1 0 1 0 0 1 1 1 0 0 1 0 0 0 1 1 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 0 1 1 0 1 1
 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 0 0 1 0 1 0 0 1 0 0 1 1 0 1 1 0 1 1 1 1 0 1
 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 0 1 1 0 0 1 1 0 0 1 1 1 1 0 1 1 0 0 0 1 0
 1 0 1 1 1 0 1 1 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 1 1 0 1 0 0 0 0 1 1 0 0 1 1
 1 0 1 1 1 1 1 0 0 1 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 1 1 1 1 1 1 0 1 0 1 1 0 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1
 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1 1 1 0 0 0 1 1
 1 1 0 1 0 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0
 0 1 0 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1
 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 0 1 1 1 1 1 0 1 1
 0 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1
 1 1 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 0 0 1 0 1 0 1 1 1 1 1 0 1 1 0 1 0 1 0 0
 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 0 0 0 0 0 0 1]
</pre></div></div>
</div>
<p>上記からわかるように，入力変数のスケールは統一されていないことがわかる．</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># 訓練データと検証データに分割
from sklearn.model_selection import train_test_split

X_train, X_test, t_train, t_test = train_test_split(X, t, test_size=0.3, random_state=0)
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [64]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># スケーリング無で学習
from sklearn.svm import SVC

model = SVC()
model.fit(X_train, t_train)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>Out[64]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,
  decision_function_shape=&#39;ovr&#39;, degree=3, gamma=&#39;auto&#39;, kernel=&#39;rbf&#39;,
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [65]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># 検証（訓練データ）
model.score(X_train, t_train)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>Out[65]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>1.0
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [66]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># 検証（訓練データ）
model.score(X_test, t_test)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>Out[66]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>0.631578947368421
</pre></div>
</div>
</div>
<p>分類では精度 (Accuracy)
と呼ばれる指標の結果が得られる．例えば，100問中3問間違えると，Accuracyは0.97となる．</p>
<p>次にスケーリングを行った後に学習させる．</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># スケーリング
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
scaler.fit(X_train)

X_train_s = scaler.transform(X_train)
X_test_s  = scaler.transform(X_test)
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [68]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># スケーリングしたデータを用いて学習
model.fit(X_train_s, t_train)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>Out[68]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,
  decision_function_shape=&#39;ovr&#39;, degree=3, gamma=&#39;auto&#39;, kernel=&#39;rbf&#39;,
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [69]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># 検証（訓練データ）
model.score(X_train_s, t_train)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>Out[69]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>0.9824120603015075
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [70]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># 検証（検証データ）
model.score(X_test_s, t_test)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>Out[70]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>0.9766081871345029
</pre></div>
</div>
</div>
<p>このように精度が大幅に高まったことがわかる．最後にハイパーパラメータのチューニングを行う．</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>from sklearn.model_selection import GridSearchCV
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># 調整を行うハイパーパラメータの値の候補
param_grid = [
    {&#39;C&#39;: [1, 10, 100], &#39;gamma&#39;: [0.01, 0.1, 1, 10]}
]
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [73]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># 交差検証法を使用したハイパーパラメータの各組合せでの学習
model_cv = GridSearchCV(SVC(), param_grid, cv=3)
model_cv.fit(X_train_s, t_train)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>Out[73]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>GridSearchCV(cv=3, error_score=&#39;raise&#39;,
       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,
  decision_function_shape=&#39;ovr&#39;, degree=3, gamma=&#39;auto&#39;, kernel=&#39;rbf&#39;,
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False),
       fit_params=None, iid=True, n_jobs=1,
       param_grid=[{&#39;C&#39;: [1, 10, 100], &#39;gamma&#39;: [0.01, 0.1, 1, 10]}],
       pre_dispatch=&#39;2*n_jobs&#39;, refit=True, return_train_score=&#39;warn&#39;,
       scoring=None, verbose=0)
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [74]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># 結果の確認 (valの対する結果)
model_cv.grid_scores_
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="stderr output_area docutils container">
<div class="highlight"><pre>
/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:762: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20
  DeprecationWarning)
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>Out[74]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>[mean: 0.96482, std: 0.01272, params: {&#39;C&#39;: 1, &#39;gamma&#39;: 0.01},
 mean: 0.95226, std: 0.01543, params: {&#39;C&#39;: 1, &#39;gamma&#39;: 0.1},
 mean: 0.62814, std: 0.00310, params: {&#39;C&#39;: 1, &#39;gamma&#39;: 1},
 mean: 0.62563, std: 0.00223, params: {&#39;C&#39;: 1, &#39;gamma&#39;: 10},
 mean: 0.97487, std: 0.01972, params: {&#39;C&#39;: 10, &#39;gamma&#39;: 0.01},
 mean: 0.94472, std: 0.02474, params: {&#39;C&#39;: 10, &#39;gamma&#39;: 0.1},
 mean: 0.63065, std: 0.00132, params: {&#39;C&#39;: 10, &#39;gamma&#39;: 1},
 mean: 0.62563, std: 0.00223, params: {&#39;C&#39;: 10, &#39;gamma&#39;: 10},
 mean: 0.94975, std: 0.01981, params: {&#39;C&#39;: 100, &#39;gamma&#39;: 0.01},
 mean: 0.94472, std: 0.02474, params: {&#39;C&#39;: 100, &#39;gamma&#39;: 0.1},
 mean: 0.63065, std: 0.00132, params: {&#39;C&#39;: 100, &#39;gamma&#39;: 1},
 mean: 0.62563, std: 0.00223, params: {&#39;C&#39;: 100, &#39;gamma&#39;: 10}]
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [75]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># 最も結果が良かったハイパーパラメータ
model_cv.best_params_
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>Out[75]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>{&#39;C&#39;: 10, &#39;gamma&#39;: 0.01}
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># 最も結果が良かったハイパーパラメータの値を設定したモデル
model = model_cv.best_estimator_
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [77]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># 検証（検証データ）
model.score(X_test_s, t_test)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>Out[77]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>0.9883040935672515
</pre></div>
</div>
</div>
<p>ハイパーパラメータの調整により，多少であるが改善することができた．</p>
</div>
</div>
<div class="section" id="Random-Forest">
<h3>2.5.2. Random Forest<a class="headerlink" href="#Random-Forest" title="このヘッドラインへのパーマリンク">¶</a></h3>
<p>つぎに，決定木 (Dicision Tree)
のアンサンブル学習であるランダムフォレストを紹介する．こちらも実用上良く使われる手法である．ランダムフォレスト含めた決定木系の手法では入力変数のスケールの違いによる影響はほとんど受けない．また，<strong>カテゴリカル変数</strong>と呼ばれる定量評価を行うことが難しい変数（例えば，男性
or
女性）も定量化を気にすることなく扱うことができるメリットがある．回帰と分類と両方準備されているため，それぞれについて紹介する．</p>
<div class="section" id="回帰-(Regression)">
<h4>2.5.2.1. 回帰 (Regression)<a class="headerlink" href="#回帰-(Regression)" title="このヘッドラインへのパーマリンク">¶</a></h4>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># データの準備
from sklearn.datasets import load_boston

boston = load_boston()
X = boston[&#39;data&#39;]
t = boston[&#39;target&#39;]
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># 訓練と検証データの分割
from sklearn.model_selection import train_test_split

X_train, X_test, t_train, t_test = train_test_split(X, t, test_size=0.3, random_state=0)
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [80]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># モデルのインスタンス化，学習
from sklearn.ensemble import RandomForestRegressor

model = RandomForestRegressor()
model.fit(X_train, t_train)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>Out[80]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>RandomForestRegressor(bootstrap=True, criterion=&#39;mse&#39;, max_depth=None,
           max_features=&#39;auto&#39;, max_leaf_nodes=None,
           min_impurity_decrease=0.0, min_impurity_split=None,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [81]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># 検証（訓練データ）
model.score(X_train, t_train)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>Out[81]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>0.9827106387591679
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [82]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># 検証（検証データ）
model.score(X_test, t_test)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>Out[82]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>0.8253491402788222
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
scaler.fit(X_train)

X_train_s = scaler.transform(X_train)
X_test_s = scaler.transform(X_test)
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [84]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># スケーリング後のデータを使って学習
model.fit(X_train_s, t_train)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>Out[84]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>RandomForestRegressor(bootstrap=True, criterion=&#39;mse&#39;, max_depth=None,
           max_features=&#39;auto&#39;, max_leaf_nodes=None,
           min_impurity_decrease=0.0, min_impurity_split=None,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [85]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># 検証（訓練データ）
model.score(X_train_s, t_train)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>Out[85]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>0.9721252941946761
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [86]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># 検証（検証データ）
model.score(X_test_s, t_test)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>Out[86]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>0.8070758556594833
</pre></div>
</div>
</div>
<p>このように，スケーリングによる影響はほとんどないことが経験的にもわかる．
また，Random
Forest含めた決定木系の手法では，まずは条件分岐させる数である
<code class="docutils literal notranslate"><span class="pre">max_depth</span></code> をハイパーパラメータとして調整することが多い．</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>from sklearn.model_selection import GridSearchCV
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># 調整を行うハイパーパラメータの値の候補
param_grid = [
    {&#39;max_depth&#39;: [1, 2, 3, 4, 5, 6]}
]
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [89]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># 交差検証法を使用したハイパーパラメータの各組合せでの学習
model_cv = GridSearchCV(RandomForestRegressor(), param_grid, cv=3, scoring=&#39;neg_mean_squared_error&#39;)
model_cv.fit(X_train_s, t_train)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>Out[89]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>GridSearchCV(cv=3, error_score=&#39;raise&#39;,
       estimator=RandomForestRegressor(bootstrap=True, criterion=&#39;mse&#39;, max_depth=None,
           max_features=&#39;auto&#39;, max_leaf_nodes=None,
           min_impurity_decrease=0.0, min_impurity_split=None,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,
           oob_score=False, random_state=None, verbose=0, warm_start=False),
       fit_params=None, iid=True, n_jobs=1,
       param_grid=[{&#39;max_depth&#39;: [1, 2, 3, 4, 5, 6]}],
       pre_dispatch=&#39;2*n_jobs&#39;, refit=True, return_train_score=&#39;warn&#39;,
       scoring=&#39;neg_mean_squared_error&#39;, verbose=0)
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [90]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># 結果の確認 (valの対する結果)
model_cv.grid_scores_
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="stderr output_area docutils container">
<div class="highlight"><pre>
/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:762: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20
  DeprecationWarning)
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>Out[90]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>[mean: -45.39943, std: 13.11535, params: {&#39;max_depth&#39;: 1},
 mean: -24.64284, std: 7.10625, params: {&#39;max_depth&#39;: 2},
 mean: -23.00834, std: 7.99062, params: {&#39;max_depth&#39;: 3},
 mean: -19.58811, std: 5.74226, params: {&#39;max_depth&#39;: 4},
 mean: -19.36648, std: 6.03968, params: {&#39;max_depth&#39;: 5},
 mean: -16.72697, std: 6.46439, params: {&#39;max_depth&#39;: 6}]
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [91]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># 最も結果が良かったハイパーパラメータ
model_cv.best_params_
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>Out[91]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>{&#39;max_depth&#39;: 6}
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># 最も結果が良かったハイパーパラメータの値を設定したモデル
model = model_cv.best_estimator_
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [93]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># 検証（検証データ）
model.score(X_test_s, t_test)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>Out[93]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>0.8210485221230714
</pre></div>
</div>
</div>
<p>今回はもともとオーバーフィッティングしていなかったため，ハイパーパラメータの調整によって改善することはなかったが，もちろんオーバーフィッティングしているケースには有効な施策である．</p>
<p>またランダムフォレストを含めた決定木系の手法の大きなメリットとして，各入力変数がどの程度重要であるかを定量評価した値が得られる．</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [94]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># 各入力変数の重要度
model.feature_importances_
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>Out[94]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>array([0.05015888, 0.00077746, 0.00376263, 0.00479107, 0.01185907,
       0.47868764, 0.00844228, 0.03243677, 0.00319549, 0.0143976 ,
       0.01143796, 0.00552612, 0.37452702])
</pre></div>
</div>
</div>
<p>重要度の総和が1になっており，この値を使って考察したり説明できるため，実務でよく見るポイントの一つである．</p>
</div>
<div class="section" id="分類-(Classification)">
<h4>2.5.2.2. 分類 (Classification)<a class="headerlink" href="#分類-(Classification)" title="このヘッドラインへのパーマリンク">¶</a></h4>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># データの準備
from sklearn.datasets import load_boston

breast_cancer = load_breast_cancer()
X = breast_cancer[&#39;data&#39;]
t = breast_cancer[&#39;target&#39;]
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># 訓練と検証データの分割
from sklearn.model_selection import train_test_split

X_train, X_test, t_train, t_test = train_test_split(X, t, test_size=0.3, random_state=0)
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [97]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># モデルのインスタンス化，学習
from sklearn.ensemble import RandomForestClassifier

model = RandomForestClassifier()
model.fit(X_train, t_train)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>Out[97]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;,
            max_depth=None, max_features=&#39;auto&#39;, max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [98]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># 検証（訓練データ）
model.score(X_train, t_train)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>Out[98]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>1.0
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [99]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># 検証（検証データ）
model.score(X_test, t_test)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>Out[99]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>0.9649122807017544
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
scaler.fit(X_train)

X_train_s = scaler.transform(X_train)
X_test_s = scaler.transform(X_test)
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [101]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># スケーリング後のデータを使って学習
model.fit(X_train_s, t_train)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>Out[101]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;,
            max_depth=None, max_features=&#39;auto&#39;, max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [102]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># 検証（訓練データ）
model.score(X_train_s, t_train)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>Out[102]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>0.9974874371859297
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [103]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># 検証（検証データ）
model.score(X_test_s, t_test)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>Out[103]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>0.9473684210526315
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>from sklearn.model_selection import GridSearchCV
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># 調整を行うハイパーパラメータの値の候補
param_grid = [
    {&#39;max_depth&#39;: [1, 2, 3, 4, 5, 6]}
]
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [106]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># 交差検証法を使用したハイパーパラメータの各組合せでの学習
model_cv = GridSearchCV(RandomForestClassifier(), param_grid, cv=3)
model_cv.fit(X_train_s, t_train)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>Out[106]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>GridSearchCV(cv=3, error_score=&#39;raise&#39;,
       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;,
            max_depth=None, max_features=&#39;auto&#39;, max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False),
       fit_params=None, iid=True, n_jobs=1,
       param_grid=[{&#39;max_depth&#39;: [1, 2, 3, 4, 5, 6]}],
       pre_dispatch=&#39;2*n_jobs&#39;, refit=True, return_train_score=&#39;warn&#39;,
       scoring=None, verbose=0)
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [107]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># 結果の確認 (valの対する結果)
model_cv.grid_scores_
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="stderr output_area docutils container">
<div class="highlight"><pre>
/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:762: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20
  DeprecationWarning)
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>Out[107]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>[mean: 0.92965, std: 0.01575, params: {&#39;max_depth&#39;: 1},
 mean: 0.95226, std: 0.01969, params: {&#39;max_depth&#39;: 2},
 mean: 0.94221, std: 0.00700, params: {&#39;max_depth&#39;: 3},
 mean: 0.94724, std: 0.02206, params: {&#39;max_depth&#39;: 4},
 mean: 0.94724, std: 0.02810, params: {&#39;max_depth&#39;: 5},
 mean: 0.94472, std: 0.01968, params: {&#39;max_depth&#39;: 6}]
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [108]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># 最も結果が良かったハイパーパラメータ
model_cv.best_params_
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>Out[108]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>{&#39;max_depth&#39;: 2}
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># 最も結果が良かったハイパーパラメータの値を設定したモデル
model = model_cv.best_estimator_
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [110]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># 検証（検証データ）
model.score(X_test_s, t_test)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>Out[110]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>0.9064327485380117
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [111]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># 各入力変数の重要度
model.feature_importances_
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>Out[111]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>array([0.        , 0.00132636, 0.15402681, 0.        , 0.        ,
       0.        , 0.08069227, 0.        , 0.00862537, 0.        ,
       0.06109958, 0.        , 0.        , 0.07705514, 0.        ,
       0.00617919, 0.        , 0.        , 0.        , 0.        ,
       0.00791324, 0.        , 0.20231586, 0.08683122, 0.        ,
       0.02427364, 0.        , 0.25634921, 0.01406416, 0.01924793])
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="ロジスティック回帰">
<h3>2.5.3. ロジスティック回帰<a class="headerlink" href="#ロジスティック回帰" title="このヘッドラインへのパーマリンク">¶</a></h3>
<p>シンプルであるが良く使われる手法のひとつである．回帰という名前がついているが，問題設定としては分類に使用する点に注意されたい．</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># データの準備
from sklearn.datasets import load_boston

breast_cancer = load_breast_cancer()
X = breast_cancer[&#39;data&#39;]
t = breast_cancer[&#39;target&#39;]
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># 訓練と検証データの分割
from sklearn.model_selection import train_test_split

X_train, X_test, t_train, t_test = train_test_split(X, t, test_size=0.3, random_state=0)
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [114]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># モデルのインスタンス化，学習
from sklearn.linear_model import LogisticRegression

model = LogisticRegression()
model.fit(X_train, t_train)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>Out[114]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class=&#39;ovr&#39;, n_jobs=1,
          penalty=&#39;l2&#39;, random_state=None, solver=&#39;liblinear&#39;, tol=0.0001,
          verbose=0, warm_start=False)
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [115]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># 検証（訓練データ）
model.score(X_train, t_train)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>Out[115]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>0.957286432160804
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [116]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># 検証（検証データ）
model.score(X_test, t_test)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>Out[116]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>0.9649122807017544
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
scaler.fit(X_train)

X_train_s = scaler.transform(X_train)
X_test_s = scaler.transform(X_test)
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [118]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># スケーリング後のデータを使って学習
model.fit(X_train_s, t_train)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>Out[118]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class=&#39;ovr&#39;, n_jobs=1,
          penalty=&#39;l2&#39;, random_state=None, solver=&#39;liblinear&#39;, tol=0.0001,
          verbose=0, warm_start=False)
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [119]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># 検証（訓練データ）
model.score(X_train_s, t_train)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>Out[119]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>0.9899497487437185
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [120]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># 検証（検証データ）
model.score(X_test_s, t_test)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>Out[120]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>0.9766081871345029
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>from sklearn.model_selection import GridSearchCV
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># 調整を行うハイパーパラメータの値の候補
param_grid = [
    {&#39;C&#39;: [0.01, 0.1, 1, 10]}
]
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [123]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># 交差検証法を使用したハイパーパラメータの各組合せでの学習
model_cv = GridSearchCV(LogisticRegression(), param_grid, cv=3)
model_cv.fit(X_train_s, t_train)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>Out[123]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>GridSearchCV(cv=3, error_score=&#39;raise&#39;,
       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class=&#39;ovr&#39;, n_jobs=1,
          penalty=&#39;l2&#39;, random_state=None, solver=&#39;liblinear&#39;, tol=0.0001,
          verbose=0, warm_start=False),
       fit_params=None, iid=True, n_jobs=1,
       param_grid=[{&#39;C&#39;: [0.01, 0.1, 1, 10]}], pre_dispatch=&#39;2*n_jobs&#39;,
       refit=True, return_train_score=&#39;warn&#39;, scoring=None, verbose=0)
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [124]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># 結果の確認 (valの対する結果)
model_cv.grid_scores_
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="stderr output_area docutils container">
<div class="highlight"><pre>
/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:762: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20
  DeprecationWarning)
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>Out[124]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>[mean: 0.96985, std: 0.01223, params: {&#39;C&#39;: 0.01},
 mean: 0.97990, std: 0.00935, params: {&#39;C&#39;: 0.1},
 mean: 0.98492, std: 0.01624, params: {&#39;C&#39;: 1},
 mean: 0.97236, std: 0.02323, params: {&#39;C&#39;: 10}]
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [125]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># 最も結果が良かったハイパーパラメータ
model_cv.best_params_
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>Out[125]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>{&#39;C&#39;: 1}
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># 最も結果が良かったハイパーパラメータの値を設定したモデル
model = model_cv.best_estimator_
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [127]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># 検証（検証データ）
model.score(X_test_s, t_test)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>Out[127]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>0.9766081871345029
</pre></div>
</div>
</div>
<p>ロジスティック回帰の特徴は推論の時に出てくる．これまでの分類の手法であれば，新しいサンプルが得られた際の予測値は0か1かのカテゴリの値が得られる．Scikit-learnでは推論には<code class="docutils literal notranslate"><span class="pre">predict</span></code>を使用する．</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># 訓練データの一番最初のサンプルで試しに推論
x_pred = [X_train_s[0]]
y = model.predict(x_pred)
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [129]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>print(y)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[1]
</pre></div></div>
</div>
<p>この結果はどの手法でも同じであるが，ロジスティック回帰を含めた<strong>識別モデル</strong>系の手法では，各カテゴリに属する確率まで求めることができる．</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>y = model.predict_proba(x_pred)
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [131]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>print(y)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[[0.00160119 0.99839881]]
</pre></div></div>
</div>
<p>総和が1となっており，確率が大きいほうのカテゴリ1が選ばれたことがわかる．異常か異常でないかといった分類の場合，異常or異常でないだけでなく，どのくらい異常そうであるかの確率までわかることで，閾値を設けやすくなる．この特性は次の章で紹介するニューラルネットワークでも同じである．</p>
</div>
<div class="section" id="k-means">
<h3>2.5.4. k-means<a class="headerlink" href="#k-means" title="このヘッドラインへのパーマリンク">¶</a></h3>
<p>最後は教師なし学習である<strong>クラスタリング</strong>の手法として有名なk-meansを紹介する．分類では教師データとしてどのカテゴリに属しているかがわかっていたが，クラスタリングではその教師データがない状況で学習を行う．基本的には距離的に近いものをまとめる．</p>
<p>例題では2つのクラスターをあらかじめ用意しておき，正しく分けられるかを確認する．</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>np.random.seed(0)
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>X1 = np.random.randn(50, 2) - 3
X2 = np.random.randn(50, 2) + 3
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># 結合
X = np.r_[X1, X2]
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [135]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>X.shape
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>Out[135]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>(100, 2)
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>%matplotlib inline
import matplotlib.pyplot as plt
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [137]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>plt.scatter(X[:, 0], X[:, 1])
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>Out[137]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>&lt;matplotlib.collections.PathCollection at 0x7f7dbb9cbd30&gt;
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_Introduction_to_ML_libs_184_1.png" src="../_images/notebooks_Introduction_to_ML_libs_184_1.png" />
</div>
</div>
<p>それでは，k-meansを用いてクラスタリングを行う．クラスタリングでは基本的にはわけるクラスターの数がハイパーパラメータとして必要である．<code class="docutils literal notranslate"><span class="pre">n_clusters</span></code>で指定する．</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>from sklearn.cluster import KMeans
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [139]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>model = KMeans(n_clusters=2)
model.fit(X)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>Out[139]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>KMeans(algorithm=&#39;auto&#39;, copy_x=True, init=&#39;k-means++&#39;, max_iter=300,
    n_clusters=2, n_init=10, n_jobs=1, precompute_distances=&#39;auto&#39;,
    random_state=None, tol=0.0001, verbose=0)
</pre></div>
</div>
</div>
<p>予測した結果をもとにクラスタリングを行う．</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>y = model.predict(X)
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [141]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>print(y)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
</pre></div></div>
</div>
<p>Numpyをうまく使うと，条件に当てはまるサンプルだけを抽出できる．</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>X0 = X[y==0]
X1 = X[y==1]
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [143]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>plt.scatter(X0[:, 0], X0[:, 1], color=&#39;red&#39;)
plt.scatter(X1[:, 0], X1[:,1 ], color=&#39;blue&#39;)
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>Out[143]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>&lt;matplotlib.collections.PathCollection at 0x7f7dba09e208&gt;
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_Introduction_to_ML_libs_193_1.png" src="../_images/notebooks_Introduction_to_ML_libs_193_1.png" />
</div>
</div>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="Introduction_to_Neural_Network.html" class="btn btn-neutral float-right" title="3. ニューラルネットワークの基礎" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="Basic_Math_for_ML.html" class="btn btn-neutral" title="1. 機械学習に必要な数学の基礎" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2018, Preferred Networks &amp; キカガク

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../_static/jquery.js"></script>
        <script type="text/javascript" src="../_static/underscore.js"></script>
        <script type="text/javascript" src="../_static/doctools.js"></script>
        <script type="text/javascript" src="../_static/translations.js"></script>
        <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    

  

  <script type="text/javascript" src="../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>