

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="ja" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="ja" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>1. 機械学習に必要な数学の基礎 &mdash; メディカルAIコース オンライン講義資料&lt;Paste&gt;  ドキュメント</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="index" title="索引" href="../genindex.html" />
    <link rel="search" title="検索" href="../search.html" />
    <link rel="next" title="2. 機械学習ライブラリの基礎" href="Introduction_to_ML_libs.html" />
    <link rel="prev" title="メディカルAIコース オンライン講義資料" href="../index.html" /> 

  
  <script src="../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../index.html" class="icon icon-home"> メディカルAIコース オンライン講義資料<Paste>
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">1. 機械学習に必要な数学の基礎</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#微分">1.1. 微分</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#2点間を通る直線の傾き">1.1.1. 2点間を通る直線の傾き</a></li>
<li class="toctree-l3"><a class="reference internal" href="#1点での接線の傾き">1.1.2. 1点での接線の傾き</a></li>
<li class="toctree-l3"><a class="reference internal" href="#微分の公式">1.1.3. 微分の公式</a></li>
<li class="toctree-l3"><a class="reference internal" href="#合成関数の微分">1.1.4. 合成関数の微分</a></li>
<li class="toctree-l3"><a class="reference internal" href="#偏微分">1.1.5. 偏微分</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#線形代数">1.2. 線形代数</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#線形代数は何に役立つのか">1.2.1. 線形代数は何に役立つのか</a></li>
<li class="toctree-l3"><a class="reference internal" href="#スカラー，ベクトル，行列，テンソル">1.2.2. スカラー，ベクトル，行列，テンソル</a></li>
<li class="toctree-l3"><a class="reference internal" href="#足し算・引き算">1.2.3. 足し算・引き算</a></li>
<li class="toctree-l3"><a class="reference internal" href="#内積">1.2.4. 内積</a></li>
<li class="toctree-l3"><a class="reference internal" href="#かけ算（行列積）">1.2.5. かけ算（行列積）</a></li>
<li class="toctree-l3"><a class="reference internal" href="#ベクトル，行列のサイズ">1.2.6. ベクトル，行列のサイズ</a></li>
<li class="toctree-l3"><a class="reference internal" href="#転置">1.2.7. 転置</a></li>
<li class="toctree-l3"><a class="reference internal" href="#単位行列">1.2.8. 単位行列</a></li>
<li class="toctree-l3"><a class="reference internal" href="#逆行列">1.2.9. 逆行列</a></li>
<li class="toctree-l3"><a class="reference internal" href="#線形結合と二次形式">1.2.10. 線形結合と二次形式</a></li>
<li class="toctree-l3"><a class="reference internal" href="#勾配　ベクトルで微分">1.2.11. 勾配　ベクトルで微分</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#統計">1.3. 統計</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#確率や統計は何に使えるのか">1.3.1. 確率や統計は何に使えるのか</a></li>
<li class="toctree-l3"><a class="reference internal" href="#統計量">1.3.2. 統計量</a></li>
<li class="toctree-l3"><a class="reference internal" href="#正規分布">1.3.3. 正規分布</a></li>
<li class="toctree-l3"><a class="reference internal" href="#スケーリング">1.3.4. スケーリング</a></li>
<li class="toctree-l3"><a class="reference internal" href="#外れ値除去">1.3.5. 外れ値除去</a></li>
<li class="toctree-l3"><a class="reference internal" href="#偏微分">1.3.6. 偏微分</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#線形代数">1.4. 線形代数</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#線形代数は何に役立つのか">1.4.1. 線形代数は何に役立つのか</a></li>
<li class="toctree-l3"><a class="reference internal" href="#スカラー，ベクトル，行列，テンソル">1.4.2. スカラー，ベクトル，行列，テンソル</a></li>
<li class="toctree-l3"><a class="reference internal" href="#足し算・引き算">1.4.3. 足し算・引き算</a></li>
<li class="toctree-l3"><a class="reference internal" href="#内積">1.4.4. 内積</a></li>
<li class="toctree-l3"><a class="reference internal" href="#かけ算（行列積）">1.4.5. かけ算（行列積）</a></li>
<li class="toctree-l3"><a class="reference internal" href="#ベクトル，行列のサイズ">1.4.6. ベクトル，行列のサイズ</a></li>
<li class="toctree-l3"><a class="reference internal" href="#転置">1.4.7. 転置</a></li>
<li class="toctree-l3"><a class="reference internal" href="#単位行列">1.4.8. 単位行列</a></li>
<li class="toctree-l3"><a class="reference internal" href="#逆行列">1.4.9. 逆行列</a></li>
<li class="toctree-l3"><a class="reference internal" href="#線形結合と二次形式">1.4.10. 線形結合と二次形式</a></li>
<li class="toctree-l3"><a class="reference internal" href="#勾配　ベクトルで微分">1.4.11. 勾配　ベクトルで微分</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#統計">1.5. 統計</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#確率や統計は何に使えるのか">1.5.1. 確率や統計は何に使えるのか</a></li>
<li class="toctree-l3"><a class="reference internal" href="#統計量">1.5.2. 統計量</a></li>
<li class="toctree-l3"><a class="reference internal" href="#正規分布">1.5.3. 正規分布</a></li>
<li class="toctree-l3"><a class="reference internal" href="#スケーリング">1.5.4. スケーリング</a></li>
<li class="toctree-l3"><a class="reference internal" href="#外れ値除去">1.5.5. 外れ値除去</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="Introduction_to_ML_libs.html">2. 機械学習ライブラリの基礎</a></li>
<li class="toctree-l1"><a class="reference internal" href="Introduction_to_Neural_Network.html">3. ニューラルネットワークの基礎</a></li>
<li class="toctree-l1"><a class="reference internal" href="Introduction_to_Chainer.html">4. Deep Learningフレームワークの基礎</a></li>
<li class="toctree-l1"><a class="reference internal" href="Image_Segmentation.html">5. 実践編: MRI画像のセグメンテーション</a></li>
<li class="toctree-l1"><a class="reference internal" href="Blood_Cell_Detection.html">6. 実践編: 血液の顕微鏡画像からの細胞検出</a></li>
<li class="toctree-l1"><a class="reference internal" href="DNA_Sequence_Data_Analysis.html">7. 実践編：ディープラーニングを使った配列解析</a></li>
<li class="toctree-l1"><a class="reference internal" href="Sequential_Data_Analysis_with_Deep_Learning.html">8. 実践編: ディープラーニングを使ったモニタリングデータの時系列解析</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">メディカルAIコース オンライン講義資料<Paste></a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
      <li>1. 機械学習に必要な数学の基礎</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/notebooks/Basic_Math_for_ML.ipynb.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast,
.nboutput.nblast {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast + .nbinput {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}
</style>
<div class="section" id="機械学習に必要な数学の基礎">
<h1>1. 機械学習に必要な数学の基礎<a class="headerlink" href="#機械学習に必要な数学の基礎" title="このヘッドラインへのパーマリンク">¶</a></h1>
<p>この章では，ディープラーニングを含めた機械学習に必要な数学の基礎である微分，線形代数，統計の3つについて，簡潔に紹介していきます．</p>
<div class="section" id="微分">
<h2>1.1. 微分<a class="headerlink" href="#微分" title="このヘッドラインへのパーマリンク">¶</a></h2>
<p>微分は関数の<strong>接線の傾き</strong>を表します．接線の定義は後で説明しますが，下の図のように関数に接するような直線です．</p>
<p><img alt="image0" src="https://github.com/japan-medical-ai/medical-ai-course-materials/raw/master/notebooks/images/1/01.png" /></p>
<p>例えば、この図の関数において，<span class="math notranslate nohighlight">\(a\)</span>
の点における接線の傾きというのは赤い直線の傾きを指し，傾きが<span class="math notranslate nohighlight">\(+3\)</span>のようになっています．傾きが<span class="math notranslate nohighlight">\(+3\)</span>ということは，入力の値が<span class="math notranslate nohighlight">\(1\)</span>増えたら，関数の値が<span class="math notranslate nohighlight">\(3\)</span>増えるような関数という意味です．このように右肩上がりな直線の傾きは正の値になります．</p>
<p><img alt="image1" src="https://github.com/japan-medical-ai/medical-ai-course-materials/raw/master/notebooks/images/1/02.png" /></p>
<p>それに対し，この <span class="math notranslate nohighlight">\(b\)</span>
の点においては，傾きは-1であり，接線は右肩下がりの直線であります．微分はこのように与えられた関数の各点に接する直線の傾きを求めることができます．</p>
<p>この，微分は機械学習で重要です。これには機械学習が何をしているのかについて</p>
<p>機械学習は、データから望む挙動をする関数を学習するような手法です．これら関数の多くはパラメータによって特徴づけられています．特徴付けられているというのは、そのパラメータを決めればその関数の挙動が決まるというものです．例えば，直線の関数は傾き<span class="math notranslate nohighlight">\(a\)</span>と切点<span class="math notranslate nohighlight">\(b\)</span>の２つのパラメータで特徴づけられ，<span class="math notranslate nohighlight">\(f(x; a, b) = ax + b\)</span>のように表されます．<span class="math notranslate nohighlight">\(;\)</span>の後はそれは引数ではなく、パラメータであることを表します．機械学習の目標は，学習データを使って関数が望むような挙動になるよう，これらのパラメータを決定することです．</p>
<p>機械学習は，目的関数を最小化することで学習，つまり望ましい挙動をするようなパラメータを決定します．この目的関数は関数が望ましい値をとる時に小さく，望ましくない時に大きな値をとるように設計された関数です．例えば，入力と出力のペアからなるデータセット<span class="math notranslate nohighlight">\(D={(x_1, y_1), (x_2, y_2), \ldots, (x_n, y_n)}\)</span>が与えられ，これらの点の近くをできる限り通るような直線を学習したい場合は</p>
<p><span class="math notranslate nohighlight">\(L( \theta) = \sum_{i=1}^n (y_i - f(x_i; \theta))^2\)</span></p>
<p>を目的関数とし、それを最小化するようにします．この式は，それぞれのデータ点で現在のモデルの予測値<span class="math notranslate nohighlight">\(f(x_i; \theta)\)</span>と，正解の二乗誤差の合計であり，予測と正解が一致する時だけ<span class="math notranslate nohighlight">\(0\)</span>、それ以外は間違えるほど大きな正の値をとるような関数です．目的関数では入出力<span class="math notranslate nohighlight">\(x_i, y_i\)</span>が引数ではなく，パラメータ<span class="math notranslate nohighlight">\(\theta\)</span>を引数としていることに注意してください‥</p>
<p>この目的関数がどのような形をとっているのかは一般にわかりませんが，もし（パラメータについての）微分が計算できれば目的関数がパラメータの変化について右肩上がりか、右肩下がりかが分かり目的関数を小さくするようにパラメータを更新することができます．</p>
<p>ここまでで，微分が機械学習においてどのように使われているのかを説明しましたが，もう一度微分に戻り，その定義や拡張について詳しくみていきます．</p>
<div class="section" id="2点間を通る直線の傾き">
<h3>1.1.1. 2点間を通る直線の傾き<a class="headerlink" href="#2点間を通る直線の傾き" title="このヘッドラインへのパーマリンク">¶</a></h3>
<p>はじめに，微分の原理を理解していくために，下図に示す2点間を通る直線の傾き
<span class="math notranslate nohighlight">\(a\)</span> を求めてみましょう．</p>
<p><img alt="image2" src="https://github.com/japan-medical-ai/medical-ai-course-materials/raw/master/notebooks/images/1/04.png" /></p>
<p>傾き<span class="math notranslate nohighlight">\(a\)</span> = <span class="math notranslate nohighlight">\(f(x)\)</span>の変化量/<span class="math notranslate nohighlight">\(x\)</span>の変化量　より、</p>
<div class="math notranslate nohighlight">
\[a = \dfrac{f(x_{2}) - f(x_{1})}{x_{2}-x_{1}}\]</div>
<p>と求まります．このように傾きは入力の単位量の変化あたり関数の値がどれだけ変わるかを表します．</p>
</div>
<div class="section" id="1点での接線の傾き">
<h3>1.1.2. 1点での接線の傾き<a class="headerlink" href="#1点での接線の傾き" title="このヘッドラインへのパーマリンク">¶</a></h3>
<p>次に，与えられた関数の接線の傾きを求めていきます．そのためには，<strong>極限</strong>を知っておく必要があります．極限とは，<span class="math notranslate nohighlight">\(\lim\)</span>
の下に書いた条件に従って値を近づけていく考え方です．例えば，</p>
<div class="math notranslate nohighlight">
\[\displaystyle \lim _{x\rightarrow 0}3x=3\times 0=0\]</div>
<p>は，<span class="math notranslate nohighlight">\(x\)</span>という変数を<span class="math notranslate nohighlight">\(0\)</span>に近づけていったときに式の値がどのような値になるかを与えます．</p>
<p>それでは，下図のある点 <span class="math notranslate nohighlight">\(x\)</span>
における接線の傾き<span class="math notranslate nohighlight">\(a\)</span>を求めていきましょう．先程は関数の2点を通る直線でしたが，今回は1点での接線の傾きです．</p>
<p><img alt="image3" src="https://github.com/japan-medical-ai/medical-ai-course-materials/raw/master/notebooks/images/1/05.png" /></p>
<p>さきほど考えた2点を通る直線と極限を組み合わせて，接線を求めることができます．</p>
<p><img alt="image4" src="https://github.com/japan-medical-ai/medical-ai-course-materials/raw/master/notebooks/images/1/06.png" /></p>
<p>はじめに，<span class="math notranslate nohighlight">\(x\)</span> から <span class="math notranslate nohighlight">\(h\)</span> だけ離れた点 <span class="math notranslate nohighlight">\(x+h\)</span>
を考え，この2点を通る直線の傾きを求めてみます．次にこの<span class="math notranslate nohighlight">\(h\)</span>を<span class="math notranslate nohighlight">\(h \rightarrow 0\)</span>
のように小さくしていけば，直線の開始点と終了点の2点が1点に収束し，1点での接線として考えることができます．これを式でみると</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\begin{split}  \begin{aligned}
  a &amp;=\lim _{h\rightarrow 0}\dfrac {f\left( x+h\right) -f\left( x\right) }{\left( x+h\right) -x}\\
  &amp;=\lim _{h\rightarrow 0}\dfrac {f\left( x+h\right) -f\left( x\right) }{h}\\
   &amp;=\lim _{h\rightarrow 0}\dfrac {f\left( x+h\right) -f\left( x\right) }{h}\\
  \end{aligned}\end{split}\\となります．この式は\ **導関数**\ と呼び，\ :math:`f'(x)`\end{aligned}\end{align} \]</div>
<p>で表されます．また導関数を求めることを<strong>微分する</strong>といいます．また，記号の使い方として，</p>
<div class="math notranslate nohighlight">
\[(\cdot)' = \dfrac{d}{dx}(\cdot)\]</div>
<p>のように表しても構いません．この場合の<span class="math notranslate nohighlight">\(d\)</span>は差分（difference）を表しており，<span class="math notranslate nohighlight">\(d(\cdot)\)</span>が対象の値の変化量，<span class="math notranslate nohighlight">\(dx\)</span>が<span class="math notranslate nohighlight">\(x\)</span>の変化量を表し，それらを小さくしていった時の極限を表します．この記法は煩雑ですがどの変数を対象に微分しているかが明確になるのが正確な表現をすることができます．</p>
</div>
<div class="section" id="微分の公式">
<h3>1.1.3. 微分の公式<a class="headerlink" href="#微分の公式" title="このヘッドラインへのパーマリンク">¶</a></h3>
<p>微分にはいくつか覚えておくと便利な公式があります．以下の3つの公式だけで多くの関数を微分できます．</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}\left( 定数\right) ^{'}&amp;=0 \\
\left( x\right) ^{'}&amp;=1\\
\left( x^{2}\right) ^{'}&amp;=2x
\end{aligned}\end{split}\]</div>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
\left( 定数\right) ^{'}&amp;=0\\
\left( x\right) ^{'}&amp;=1\\
\left( x^{2}\right) ^{'}&amp;=2x
\end{aligned}\end{split}\]</div>
<p>それでは，次の２つの例題を考えながら，具体的な微分の計算に慣れていきましょう．</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\begin{split}  \begin{aligned}
  ( 3x^{2})'&amp;=3\times (x^{2})'\\
  &amp;=3\times 2x\\
  &amp;=6x
  \end{aligned}\end{split}\\この :math:`(3x^{2})' = 3 \times (x^{2})'`\end{aligned}\end{align} \]</div>
<p>の部分に注目してください．微分では，このように定数の係数（変数にかかる数）は微分の演算の外側に出すことができます．また，次の例題でも新しい特性があります．</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
\left( 3x^{2}+4\right)'&amp;=\left( 3x^{2}\right)'+\left( 4\right)'\\
&amp;=3\times \left( x^{2}\right)'+4\times \left( 1\right)'\\
&amp;=3\times 2x+4\times 0\\
&amp;=6x
\end{aligned}\end{split}\]</div>
<p>この例題では，<span class="math notranslate nohighlight">\(\left( 3x^{2}+4\right)'=\left( 3x^{2}\right)'+\left( 4\right)'\)</span>
のように，全体の和をとった後に微分の演算を行っても，それぞれで微分の演算を行った後に和の計算をしても同じとなっています．これは微分の<strong>線形性</strong>と呼ばれる性質であり，この性質を使うことで，微分を簡単に計算できるようになります．</p>
</div>
<div class="section" id="合成関数の微分">
<h3>1.1.4. 合成関数の微分<a class="headerlink" href="#合成関数の微分" title="このヘッドラインへのパーマリンク">¶</a></h3>
<p>機械学習では関数は複雑な形をとり，それらの微分の計算も複雑になりがちです．例えば，</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}  \left\{ (3x + 4)^{2} \right\}'\\の場合，\ :math:`3x+4` という内側の部分と :math:`(\cdot)^{2}`\end{aligned}\end{align} \]</div>
<p>という外側の部分で構成されています．この式を<span class="math notranslate nohighlight">\((9x^2 + 24x + 16)'\)</span>のように展開してから微分を計算してもよいのですが，これが3乗や4乗となってくると展開するのも大変になります．この時に役に立つ考え方が<strong>合成関数の微分</strong>の公式です．合成関数の微分は，内側の微分と外側の微分をそれぞれ行い，その結果をかけ合わせます．</p>
<div class="math notranslate nohighlight">
\[\frac{d}{dx}f(g(x)) = \frac{d}{d u}f(u) \frac{d}{dx} g(x)\]</div>
<p>まず内側の関数を <span class="math notranslate nohighlight">\(u = (3x+4)\)</span> とおいて，</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}  \left\{ (3x + 4)^{2} \right\}' = (u^{2})'\\とします．ここで，\ :math:`(\cdot)'`\end{aligned}\end{align} \]</div>
<p>をもう少し厳密に考える必要が出てきます．今は，<span class="math notranslate nohighlight">\(x\)</span> と <span class="math notranslate nohighlight">\(u\)</span>
の2つの変数が登場しており，<span class="math notranslate nohighlight">\((\cdot)'\)</span> では，<span class="math notranslate nohighlight">\(x\)</span>
で微分しているのか <span class="math notranslate nohighlight">\(u\)</span>
で微分しているのかの区別がつきません．そこで，多少複雑に見えますが，先程紹介した<span class="math notranslate nohighlight">\(d\)</span>を使った記法で微分する変数を厳密に記述すると，</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\begin{split}  \begin{aligned}
  \left\{ (3x + 4)^{2} \right\}' &amp;= \dfrac{d}{dx} \left\{ (3x + 4)^{2} \right\} \\
  &amp;= \dfrac{d}{dx} (u^2) \\
  &amp;=  \dfrac{d}{dx} f(u) \\
  \end{aligned}\end{split}\\となり，\ :math:`u` の関数 :math:`f(u) = u^{2}` に対して，\ :math:`x`\end{aligned}\end{align} \]</div>
<p>で微分していることがわかります．．<span class="math notranslate nohighlight">\(x\)</span>を変化させた時に<span class="math notranslate nohighlight">\(f(u)\)</span>がどれだけ変化するのかはわかりません．そこで，<span class="math notranslate nohighlight">\(x\)</span>を単位量変化させた時に<span class="math notranslate nohighlight">\(u\)</span>がどれだけ変化するのか，<span class="math notranslate nohighlight">\(u\)</span>を単位量変化させた時に<span class="math notranslate nohighlight">\(f(u)\)</span>がどれだけ変化するのかを考え，それらの積を考えます．</p>
<div class="math notranslate nohighlight">
\[\begin{aligned}
\dfrac{df(u)}{dx} = \dfrac{du}{dx} \dfrac{df(u)}{du}
\end{aligned}\]</div>
<p>この時，<span class="math notranslate nohighlight">\(du\)</span>は分子と分母に出現しているので約分して消去してしまえば左辺と右辺は同じであるといった考え方を適用することができます．つまり，合成関数の計算は内側の微分と外側の微分をそれぞれ行い，その結果を掛け合わせれば良いわけです．それぞれの微分の計算は</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\begin{split}  \begin{aligned}
   \dfrac{du}{dx} &amp;= \dfrac{d}{dx} (3x+4) = 3 \\
   \dfrac{df(u)}{du} &amp;= \dfrac{d}{du} u^{2} = 2u \\
  \end{aligned}\end{split}\\となります．これより，\end{aligned}\end{align} \]</div>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
\dfrac{df(u)}{dx} &amp;= \dfrac{du}{dx} \dfrac{df(u)}{du} \\
 &amp;= 3 \times 2u \\
 &amp;= 3 \times 2(3x+4) \\
 &amp;= 6(3x+4)
\end{aligned}\end{split}\]</div>
<p>が得られます．数式こそ多少複雑に見えますが，るだけであり，実際の計算は慣れると簡単に行うことが出来ます．なお，今回は分数の約分という形で大雑把に説明しましたが，実際には極限を使って合成関数の微分が成り立つことを証明できます．ニューラルネットワークの学習では合成関数の微分を使用する場面が何度も登場するため，この計算方法をしっかりと覚えておきましょう．</p>
</div>
<div class="section" id="偏微分">
<h3>1.3.6. 偏微分<a class="headerlink" href="#偏微分" title="このヘッドラインへのパーマリンク">¶</a></h3>
<p>微分最後のトピックとして，<strong>偏微分</strong>を紹介します．偏微分は多変数関数の微分です．機械学習では，1つの入力変数
<span class="math notranslate nohighlight">\(x\)</span> から出力変数 <span class="math notranslate nohighlight">\(y\)</span>
を予測するケースは稀であり，基本的には，複数の入力変数 <span class="math notranslate nohighlight">\(x_{1}\)</span>,
<span class="math notranslate nohighlight">\(x_{2}\)</span>, <span class="math notranslate nohighlight">\(\ldots\)</span>, <span class="math notranslate nohighlight">\(x_{M}\)</span> を用いて出力変数 <span class="math notranslate nohighlight">\(y\)</span>
を予測します．例えば，家賃を予測する場合，部屋の広さだけで予測するよりも，駅からの距離や犯罪発生率などを考慮した方が予測の性能は高まりそうだと考えられます．多変数
<span class="math notranslate nohighlight">\(x_{1}\)</span>, <span class="math notranslate nohighlight">\(x_{2}\)</span>, <span class="math notranslate nohighlight">\(\ldots\)</span>, <span class="math notranslate nohighlight">\(x_{M}\)</span>
を考慮した多変数関数 <span class="math notranslate nohighlight">\(f(x_{1}, x_{2}, \ldots, x_{M})\)</span>
では，各変数で微分することを偏微分と呼び，</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}  \dfrac{\partial}{\partial x_{m}} f(x_{1}, x_{2}, \ldots, x_{M})\\のように表します．大雑把には，\ :math:`d` が :math:`\partial`\end{aligned}\end{align} \]</div>
<p>に変わっただけです．しかも，計算方法は至って単純であり，<span class="math notranslate nohighlight">\(\dfrac{\partial}{\partial x_{m}}\)</span>
の場合は <span class="math notranslate nohighlight">\(x_{m}\)</span> 以外は定数と考えて，<span class="math notranslate nohighlight">\(x_{m}\)</span>
のみ着目して微分を行います．</p>
<p>例題で具体的な計算の流れを確認していきましょう．</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
\dfrac {\partial }{\partial x_{1}}\left( 3x_{1}+4x_{2}\right) &amp;=\dfrac {\partial }{\partial x_{1}}\left( 3x_{1}\right) +\dfrac {\partial }{\partial x_{1}}\left( 4x_{2}\right) \\
&amp;=3\times \dfrac {\partial }{\partial x_{1}}\left( x_{1}\right) +4x_{2}\times \dfrac {\partial }{\partial x_{1}}\left( 1\right) \\
&amp;=3\times 1+4x_{2}\times 0\\
&amp;= 3
\end{aligned}\end{split}\]</div>
<p>偏微分でも微分と同じ線形性の性質が適用できます．今回のケースでは，<span class="math notranslate nohighlight">\(x_{1}\)</span>
にだけ着目するため，<span class="math notranslate nohighlight">\(x_{2}\)</span>
は定数として扱うことを把握しておけば上記の計算の流れが理解できるはずです．これが偏微分であり，参考書にはここからさらに全微分の話に入っていくことが多いですが，ひとまずここまでの計算の方法を理解しておけば，この後の計算は理解することができるはずです．</p>
</div>
</div>
<div class="section" id="線形代数">
<h2>1.4. 線形代数<a class="headerlink" href="#線形代数" title="このヘッドラインへのパーマリンク">¶</a></h2>
<div class="section" id="線形代数は何に役立つのか">
<h3>1.4.1. 線形代数は何に役立つのか<a class="headerlink" href="#線形代数は何に役立つのか" title="このヘッドラインへのパーマリンク">¶</a></h3>
<p>次に重要な概念が<strong>線形代数</strong>です．ベクトル，行列，ランク，逆行列などの概念が登場します．</p>
<p>さて，微分と同様に理論を学ぶ前に，これから学ぶ線形代数という学問がみなさんにとってどのようなメリットをもたらしてくれるかを考えましょう．<span class="math notranslate nohighlight">\(x_{1}\)</span>
や <span class="math notranslate nohighlight">\(x_{2}\)</span>
のように機械学習の中では，似たような複数の変数が登場してきます．これらの複数の変数間の関係を記述する上で線形代数は最も単純な数学ですが驚くほど多くの問題を扱うことができる重要な概念です．ぜひ身に着けていきましょう．</p>
</div>
<div class="section" id="スカラー，ベクトル，行列，テンソル">
<h3>1.4.2. スカラー，ベクトル，行列，テンソル<a class="headerlink" href="#スカラー，ベクトル，行列，テンソル" title="このヘッドラインへのパーマリンク">¶</a></h3>
<p>最初に線形代数で使われる<strong>スカラー</strong>，<strong>ベクトル</strong>，<strong>行列</strong>，<strong>テンソル</strong>の4つを解説します．</p>
<p>スカラーは，1つの値もしくは変数のことです．例えば，</p>
<div class="math notranslate nohighlight">
\[x, \ y,\  M,\  N\]</div>
<p>のように表します．スカラーは例えば温度や身長といった単一の量を表すことに使われます．</p>
<p>ベクトルは，複数のスカラーを縦方向（もしくは横方向）に集めて並べたものであり，</p>
<div class="math notranslate nohighlight">
\[\begin{split}\boldsymbol{x}=\begin{bmatrix}
x_{1} \\
x_{2} \\
x_{3}
\end{bmatrix}, \
\boldsymbol{y}=\begin{bmatrix}
y_{1} \\
y_{2} \\
\vdots \\
y_{N}
\end{bmatrix}\end{split}\]</div>
<p>ように表します．ベクトルの表記は太文字とする場合が多く，スカラーかベクトルかを一目で区別できるようにしています．ベクトルを縦方向に定義するか横方向に定義するかは業界によって異なっていますが，数学や機械学習では縦方向で定義している論文や参考書が多いため，本講義では<strong>ベクトルは縦方向</strong>で統一します．</p>
<p>行列はさらに複数のベクトルをまとめたものであり，</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\begin{split}  \boldsymbol{X}=\begin{bmatrix}
  x_{11} &amp; x_{12} \\
  x_{21} &amp; x_{22} \\
  x_{31} &amp; x_{32}
  \end{bmatrix}\end{split}\\のように表します．行列のサイズは行と列で表現します．例えば，この\end{aligned}\end{align} \]</div>
<p><span class="math notranslate nohighlight">\(\boldsymbol{X}\)</span> は3行2列であり，サイズが(3,
2)の行列と言います．また，行列の値が実数の場合がほとんどであり，よく
<span class="math notranslate nohighlight">\(\boldsymbol{X} \in \mathcal{R}^{3 \times 2}\)</span>のようにサイズを簡潔に表現することがあるため，こちらも覚えておきましょう．行は文字の中に横棒が２つ入っているため横方向の値の集まり，列は文字の中に縦棒が２つはいっているため縦方向の値というように覚えると楽かもしれません．行列の表記は大文字または大文字の太文字とする場合が多いです．</p>
<p>最後に，テンソルは行列をさらにまとめたものであり，図のように行列を奥行き方向にさらに並べたものとみなすことができます．さらにテンソル同士を並べたものもテンソルとよばれます．例えば，RGB
(Red Green Blue)
などの色空間で表現するカラー画像を表現する場合，（行番号，列番号，色）の3つの軸で一つの値を指定することができ，テンソルで表現することができます．</p>
<p><img alt="image5" src="https://github.com/japan-medical-ai/medical-ai-course-materials/raw/master/notebooks/images/1/07.png" /></p>
<p>これまで紹介してきたように，値を並べたものは，スカラー <span class="math notranslate nohighlight">\(\subset\)</span>
ベクトル <span class="math notranslate nohighlight">\(\subset\)</span> 行列 <span class="math notranslate nohighlight">\(\subset\)</span>
テンソルのような関係がありました．線形代数では <span class="math notranslate nohighlight">\(\boldsymbol{y}\)</span> や
<span class="math notranslate nohighlight">\(\boldsymbol{X}\)</span>
といった文字だけで式変形をしていくため，どのような形の数値が取り扱われているかわかりくいのですが，これはベクトルなどと常に意識しておくことでその形を見失わないように注意しましょう．</p>
<table border="1" class="docutils">
<colgroup>
<col width="20%" />
<col width="40%" />
<col width="40%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">&#160;</th>
<th class="head">小文字</th>
<th class="head">大文字</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>細文字</td>
<td>スカラーの変数</td>
<td>スカラーの定数</td>
</tr>
<tr class="row-odd"><td>太文字</td>
<td>ベクトル</td>
<td>行列，テンソル</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="足し算・引き算">
<h3>1.4.3. 足し算・引き算<a class="headerlink" href="#足し算・引き算" title="このヘッドラインへのパーマリンク">¶</a></h3>
<p>行列やベクトルの演算について覚えていきましょう．足し算は同じサイズの行列，ベクトル間だけで成立し，</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}&amp;\begin{bmatrix}
1 \\
2 \\
3
\end{bmatrix}+\begin{bmatrix}
4 \\
5 \\
6
\end{bmatrix}=\begin{bmatrix}
1+4 \\
2+5 \\
3+6
\end{bmatrix}=\begin{bmatrix}
7 \\
8 \\
9
\end{bmatrix}\\
&amp;\begin{bmatrix}
1 &amp; 2 &amp; 3 \\
4 &amp; 5 &amp; 6
\end{bmatrix}+\begin{bmatrix}
7 &amp; 8 &amp; 9 \\
10 &amp; 11 &amp; 12
\end{bmatrix}=\begin{bmatrix}
8 &amp; 10 &amp; 12 \\
14 &amp; 16 &amp; 18
\end{bmatrix}\end{aligned}\end{split}\]</div>
<p>このように行列やベクトルの中の<strong>要素</strong>で対応する場所を足し合わせます．引き算も同様です．計算としては単純なものであり，特別なことはありません．<strong>同じサイズでないと計算が成立しない</strong>ということを覚えておきましょう．</p>
</div>
<div class="section" id="内積">
<h3>1.4.4. 内積<a class="headerlink" href="#内積" title="このヘッドラインへのパーマリンク">¶</a></h3>
<p>同じサイズのベクトル間では内積が定義できます．内積は同じ位置で対応する値を掛けていき，それらを足し合わせたものです．</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}&amp;\begin{bmatrix}1 \\2 \\3\end{bmatrix}\cdot \begin{bmatrix}4 \\5 \\6\end{bmatrix}= 1\cdot4 + 2 \cdot 5  + 3 \cdot 6 = 36 \end{aligned}\end{split}\]</div>
</div>
<div class="section" id="かけ算（行列積）">
<h3>1.4.5. かけ算（行列積）<a class="headerlink" href="#かけ算（行列積）" title="このヘッドラインへのパーマリンク">¶</a></h3>
<p>行列の掛け算は複数パターンあり，一般的に掛け算として認識されているものは<strong>行列積</strong>と呼ばれます．それ以外には外積や要素積（アダマール積）などがあります．行列<span class="math notranslate nohighlight">\(A\)</span>と行列<span class="math notranslate nohighlight">\(B\)</span>の行列積は<span class="math notranslate nohighlight">\(A\)</span>の各行と<span class="math notranslate nohighlight">\(B\)</span>の各列の内積を並べたものとして定義されます．例えば行列Aの2行目の行ベクトルと行列Bの3列目の列ベクトルの内積は結果の行列Cの2行3列目に対応します．</p>
<p><img alt="image6" src="https://github.com/japan-medical-ai/medical-ai-course-materials/raw/master/notebooks/images/1/matrixproduct.png" /></p>
<p>そして，内積が定義される条件はベクトルのサイズが等しいということでしたが，ここでもそれが成り立つために，Aの行のサイズ（=Aの列数）とBの列のサイズ（=Bの行数）が一致する必要があります．以下のように，「行」「列」と線を引きながら計算していきましょう．</p>
<p><img alt="image7" src="https://github.com/japan-medical-ai/medical-ai-course-materials/raw/master/notebooks/images/1/08.png" /></p>
<p>このように，単純に足し算や引き算のように要素ごとの積を扱うわけではないため，最初は計算に慣れが必要です．そして，行列積では計算が成り立つためには，以下の条件を満たす必要があります．</p>
<p><img alt="image8" src="https://github.com/japan-medical-ai/medical-ai-course-materials/raw/master/notebooks/images/1/09.png" /></p>
<p>この行列積は線形代数や機械学習の多くの問題で使われます．行列積はベクトルの集まりとベクトルの集まりの間の大量の内積計算をするようなものです．また，行列では割り算に相当する演算はありませんが，後述する逆行列を使って<span class="math notranslate nohighlight">\(4 / 2 = 4 \times \dfrac{1}{2}\)</span>
のように割り算を逆数（逆行列）の掛け算として記述します．</p>
<p>それでは，この計算条件の確認も踏まえて，下記の３つを練習問題として解いてください．</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\begin{split}  \begin{aligned}
  &amp;\left( 1\right) \begin{bmatrix} 1 &amp; 2 \end{bmatrix}\begin{bmatrix} 3 \\ 4 \end{bmatrix}\\
  &amp;\left( 2\right) \begin{bmatrix} 1 &amp; 2 \\ 3 &amp; 4 \end{bmatrix}\begin{bmatrix} 5 \\ 6 \end{bmatrix}\\
  &amp;\left( 3\right) \begin{bmatrix} 1 &amp; 2 \end{bmatrix}\begin{bmatrix} 3 &amp; 4 \\ 5 &amp; 6 \end{bmatrix}\begin{bmatrix} 3 \\ 1 \end{bmatrix}\end{aligned}\end{split}\\こちらが解答です．\end{aligned}\end{align} \]</div>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
&amp;\left( 1\right) \begin{bmatrix} 1 &amp; 2 \end{bmatrix}\begin{bmatrix} 3 \\ 4 \end{bmatrix} = 1\times 3 + 2 \times 4 = 11\\
&amp;\left( 2\right) \begin{bmatrix} 1 &amp; 2 \\ 3 &amp; 4 \end{bmatrix}\begin{bmatrix} 5 \\ 6 \end{bmatrix} = \begin{bmatrix}1\times 5 + 2\times 6 \\3 \times 5 + 4 \times 6\end{bmatrix} = \begin{bmatrix}17 \\ 39\end{bmatrix}\\
&amp;\left( 3\right)
\begin{bmatrix}
1 &amp; 2
\end{bmatrix}\begin{bmatrix}
3 &amp; 4 \\
5 &amp; 6
\end{bmatrix}\begin{bmatrix}
3 \\
1
\end{bmatrix}
=\begin{bmatrix}
1 &amp; 2
\end{bmatrix}\begin{bmatrix}
3\times 3+4\times 1 \\
5\times 3 +6\times 1
\end{bmatrix}
&amp; \ \ =\begin{bmatrix}
1 &amp; 2
\end{bmatrix}\begin{bmatrix}
13 \\
21
\end{bmatrix}
=1 \times 13+2\times 21
=55
\end{aligned}\end{split}\]</div>
<p>計算のイメージは沸いたでしょうか．実は，この３つの計算は機械学習においてよく出てくる形の計算です．押さえておくべきポイントとして，演算後に形が変わることを覚えておきましょう．</p>
</div>
<div class="section" id="ベクトル，行列のサイズ">
<h3>1.4.6. ベクトル，行列のサイズ<a class="headerlink" href="#ベクトル，行列のサイズ" title="このヘッドラインへのパーマリンク">¶</a></h3>
<p>計算を行う上でベクトル，行列の<strong>サイズ</strong>を常に意識しておくことが機械学習を円滑に理解するためのポイントとなります．例えば先ほどの３つの練習問題のサイズがどのように変化したかをまとめると，</p>
<p><img alt="image9" src="https://github.com/japan-medical-ai/medical-ai-course-materials/raw/master/notebooks/images/1/10.png" /></p>
<p>のとなります．もともとがベクトルや行列であっても，演算後にスカラーになるケースもあることがわかります．なぜこのサイズが変化する感覚をつかんでおくことが大事になるのでしょうか．</p>
<p>今回は計算結果を数値で追っていましたが，これからの計算はすべて数値ではなく文字で表現して扱います．例えば
<span class="math notranslate nohighlight">\(\boldsymbol{x}^{T}\boldsymbol{A}\boldsymbol{y}\)</span>
を見て，スカラーであると瞬時に判断できるようになる必要があります．ここで，ベクトルは縦向きで定義するため，横向きのベクトルは<strong>転置</strong>（記号は上付きの
<span class="math notranslate nohighlight">\(T\)</span>）を使うことによって表現しています．</p>
</div>
<div class="section" id="転置">
<h3>1.4.7. 転置<a class="headerlink" href="#転置" title="このヘッドラインへのパーマリンク">¶</a></h3>
<p>ベクトルは縦向きが基本としていましたが，先程の計算問題などでは，しばしば横向きのベクトルが出てきました．そこで登場するベクトルの縦と横を入れ替える演算のことを<strong>転置</strong>（Transpose）と呼びます．例えば，</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}\boldsymbol{x}&amp;=\begin{bmatrix}
1 \\
2 \\
3
\end{bmatrix}, \
\boldsymbol{x}^{T}=\begin{bmatrix} 1 &amp; 2 &amp; 3 \end{bmatrix} \\
\boldsymbol{X}&amp;=\begin{bmatrix}
1 &amp; 4 \\
2 &amp; 5 \\
3 &amp; 6
\end{bmatrix}, \
\boldsymbol{X}^{T}=\begin{bmatrix}
1 &amp; 2 &amp; 3 \\
4 &amp; 5 &amp; 6
\end{bmatrix}\end{aligned}\end{split}\]</div>
<p>のようになります．このように転置自体の演算は簡単です．先程の行列積の演算も正確には各行の転値と行列の内積となります．転置では下記3つの公式を覚えておくと，これからの計算が楽になります．</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}&amp;\left( 1\right) \ \left( \boldsymbol{A}^{T}\right)^{T}=\boldsymbol{A}\\
&amp;\left( 2\right) \ \left( \boldsymbol{A}\boldsymbol{B}\right) ^{T}=\boldsymbol{B}^{T}\boldsymbol{A}^{T}\\
&amp;\left( 3\right) \ \left( \boldsymbol{A}\boldsymbol{B}\boldsymbol{C}\right) ^{T}=\boldsymbol{C}^{T}\boldsymbol{B}^{T}\boldsymbol{A}^{T}\end{aligned}\end{split}\]</div>
</div>
<div class="section" id="単位行列">
<h3>1.4.8. 単位行列<a class="headerlink" href="#単位行列" title="このヘッドラインへのパーマリンク">¶</a></h3>
<p>単位行列とは，スカラーの１に対応した性質をもつ行列です．どのような性質かというと，<span class="math notranslate nohighlight">\(10\times1\)</span>
のように，その数を任意の数に乗じても変わらないという性質です．行列の演算において，これと同様の働きをする行列が<strong>単位行列</strong>であり，</p>
<div class="math notranslate nohighlight">
\[\begin{split}\boldsymbol{I}=\begin{bmatrix}
1 &amp; 0 &amp; \ldots  &amp; 0 \\
0 &amp; 1 &amp; \ldots  &amp; 0 \\
\vdots &amp; \vdots  &amp; \ddots  &amp; \vdots  \\
0 &amp; 0 &amp; \ldots  &amp; 1
\end{bmatrix}\end{split}\]</div>
<p>のような形をしています．行列の斜めの要素を<strong>対角要素</strong>と呼び，それ以外の要素を非対角要素とよびます．単位行列は，対角要素が1で，非対角要素が0であるような行列です．例えば，
<span class="math notranslate nohighlight">\(\boldsymbol{I} \in \mathcal{R}^{2\times 2}\)</span> の場合，</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\begin{split}  \boldsymbol{I} =\begin{bmatrix}
  1 &amp; 0 \\
  0 &amp; 1
  \end{bmatrix}\end{split}\\であり，\ :math:`\boldsymbol{I} \in \mathcal{R}^{3\times 3}` の場合，\end{aligned}\end{align} \]</div>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\begin{split}  \boldsymbol{I}=\begin{bmatrix}
  1 &amp; 0 &amp; 0 \\
  0 &amp; 1 &amp; 0 \\
  0 &amp; 0 &amp; 1
  \end{bmatrix}\end{split}\\となります．\end{aligned}\end{align} \]</div>
<p>実際に計算して，元の行列と値が変わらないかを確認してみると，</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\begin{split}  \begin{aligned}\begin{bmatrix}
  1 &amp; 2 \\
  3 &amp; 4
  \end{bmatrix}\begin{bmatrix}
  1 &amp; 0 \\
  0 &amp; 1
  \end{bmatrix}
  &amp;=\begin{bmatrix}
  1\times 1+2\times 6 &amp; 1\times 0+2\times 1 \\
  3\times 1+4\times 0 &amp; 3\times 0+4\times 1
  \end{bmatrix}\\
  &amp;=
  \begin{bmatrix}
  1 &amp; 2 \\
  3 &amp; 4
  \end{bmatrix}
  \end{aligned}\end{split}\\のように，確かに元の値と同じであることがわかりました．単位行列\end{aligned}\end{align} \]</div>
<p><span class="math notranslate nohighlight">\(\boldsymbol{I}\)</span> は任意の行列<span class="math notranslate nohighlight">\(\boldsymbol{A}\)</span>に対し</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\begin{split}  \begin{aligned}
  \boldsymbol{A}\boldsymbol{I}&amp;=\boldsymbol{A}\\
  \boldsymbol{I}\boldsymbol{A}&amp;=\boldsymbol{A}
  \end{aligned}\end{split}\\が成り立ちます．\end{aligned}\end{align} \]</div>
</div>
<div class="section" id="逆行列">
<h3>1.4.9. 逆行列<a class="headerlink" href="#逆行列" title="このヘッドラインへのパーマリンク">¶</a></h3>
<p><strong>逆行列</strong>とは</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}  2 \times 2^{-1} = 1\\のようなスカラーの逆数に対応するような行列です．英語では **Inverse\end{aligned}\end{align} \]</div>
<p>Matrix**とよびます．</p>
<p>逆行列の定義は</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\begin{split}  \begin{aligned}
  \boldsymbol{A}\boldsymbol{A}^{-1}=\boldsymbol{I}\\
  \boldsymbol{A}^{-1}\boldsymbol{A}=\boldsymbol{I}
  \end{aligned}\end{split}\\であり，ここで，\ :math:`\boldsymbol{I}`\end{aligned}\end{align} \]</div>
<p>は単位行列です．この逆行列も機械学習の計算過程に頻出するため覚えておきましょう．大学で習う線形代数の授業では，サイズが<span class="math notranslate nohighlight">\(2 \times 2\)</span>
や <span class="math notranslate nohighlight">\(3 \times 3\)</span>
であるような行列の逆行列の計算方法について習いますが，機械学習で扱う行列のサイズは
<span class="math notranslate nohighlight">\(10 \times 10, 1000 \times 1000\)</span>
と大きく，逆行列を効率的に求める計算手法が提案されています．その計算方法については必ずしも知っておく必要はありませんが，どのような行列においても逆行列を計算できるわけではないため，逆行列が計算できるための条件は知っておきましょう．逆行列は<strong>正方行列</strong>と呼ばれる行と列のサイズが同じであるような行列でないと計算できません．</p>
<p>もう一つの条件についてはそれを説明するのに必要な概念をまだ紹介していませんが，行列がフルランク（行列のランクが行数=列数）であること，これと等価で行列値が非0である必要があります．実は世の中の多くの行列はこれらを満たしませんが，対角成分に非ゼロの値を足すことで行列をフルランクにし，逆行列を計算できるようになります．もしアルゴリズムの中で逆行列を求める前に対角要素に小さな値を足すような操作があれば，それは逆行列を計算できるようにしていると思ってください．</p>
<p><img alt="image10" src="https://github.com/japan-medical-ai/medical-ai-course-materials/raw/master/notebooks/images/1/11.png" /></p>
</div>
<div class="section" id="線形結合と二次形式">
<h3>1.4.10. 線形結合と二次形式<a class="headerlink" href="#線形結合と二次形式" title="このヘッドラインへのパーマリンク">¶</a></h3>
<p>機械学習の式によく出てくる形式として
<span class="math notranslate nohighlight">\(\boldsymbol{b}^{T}\boldsymbol{x}\)</span> と
<span class="math notranslate nohighlight">\(\boldsymbol{x}^{T}\boldsymbol{A}\boldsymbol{x}\)</span>
のような２形式があります．前者は*線形結合<strong>もしくは</strong>一次結合<strong>，後者は</strong>二次形式**と呼ばれています．中学校数学でいうところの，一次式や二次式の話と考えてもらうと分かりやすいと思います．</p>
<p>線形結合の計算の中身を見てみると，</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\begin{split}  \begin{aligned}
  \boldsymbol{b}&amp;=\begin{bmatrix}
  1 \\
  2
  \end{bmatrix},\
  \boldsymbol{x}=\begin{bmatrix}
  x_{1} \\
  x_{2}
  \end{bmatrix}\\
  \boldsymbol{b}^{T}\boldsymbol{x}&amp;=\begin{bmatrix}
  1 &amp; 2
  \end{bmatrix}\begin{bmatrix}
  x_{1} \\
  x_{2}
  \end{bmatrix}=x_{1}+2x_{2}\end{aligned}\end{split}\\のように :math:`\boldsymbol{x}` の要素である :math:`x_{1}` もしくは\end{aligned}\end{align} \]</div>
<p><span class="math notranslate nohighlight">\(x_{2}\)</span> に関して，一次式となっていることがわかります．</p>
<p>また，二次形式も同様に計算の中身を確認してみると，</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\begin{split}  \begin{aligned}
  \boldsymbol{A}&amp;=\begin{bmatrix}
  1 &amp; 2 \\
  3 &amp; 4
  \end{bmatrix},\
  \boldsymbol{x}=\begin{bmatrix}
  x_{1} \\
  x_{2}
  \end{bmatrix}\\
  \boldsymbol{x}^{T}\boldsymbol{A}\boldsymbol{x}
  &amp;=\begin{bmatrix} x_{1} &amp; x_{2}\end{bmatrix}
  \begin{bmatrix}
  1 &amp; 2 \\
  3 &amp; 4
  \end{bmatrix}\begin{bmatrix}
  x_{1} \\
  x_{2}
  \end{bmatrix}\\
  &amp;=\begin{bmatrix}x_{1} &amp; x_{2}\end{bmatrix} \begin{bmatrix}
  x_{1}+2x_{2} \\
  3x_{1}+4x_{2}
  \end{bmatrix}\\
  &amp;=x_{1}\left( x_{1}+2x_{2}\right) +x_{2}\left( 3x_{1}+4x_{2}\right) \\
  &amp;=x^{2}_{1}+5x_{1}x_{2}+4x_{2}^{2}\end{aligned}\end{split}\\となり，各要素において二次式となっていることがわかります．\end{aligned}\end{align} \]</div>
<p>そして，一般にこれらを足し合わせて，</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}  \boldsymbol{x}^{T}\boldsymbol{A}\boldsymbol{x} + \boldsymbol{b}^{T}\boldsymbol{x} + c\\のように二次関数を表現します．ここで，\ :math:`c`\end{aligned}\end{align} \]</div>
<p>はスカラーの定数項です．</p>
</div>
<div class="section" id="勾配　ベクトルで微分">
<h3>1.4.11. 勾配　ベクトルで微分<a class="headerlink" href="#勾配　ベクトルで微分" title="このヘッドラインへのパーマリンク">¶</a></h3>
<p>微分は入力を変えた場合の関数値の変化量と説明しました．同様に関数の入力がベクトルであり，ベクトルで微分をとることも考えることができます．</p>
<p>機械学習で使われるのが勾配です．これは関数をそれぞれのベクトルの成分毎に偏微分を計算し，それらを並べてベクトルにしたものです．</p>
<p>勾配の計算を紹介する前に，下記の例題を計算しましょう．</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
\boldsymbol{b}&amp;=\begin{bmatrix}
3 \\
4
\end{bmatrix}, \
\boldsymbol{x}=\begin{bmatrix}
x_{1} \\
x_{2}
\end{bmatrix}\\
\boldsymbol{b}^{T}\boldsymbol{x}&amp;=\begin{bmatrix}
3 &amp; 4
\end{bmatrix}\begin{bmatrix}
x_{1} \\
x_{2}
\end{bmatrix}
=3x_{1}+4x_{2}\end{aligned}\end{split}\]</div>
<p>この計算は線形結合としてすでに紹介していますが，ここからが本題です．この
<span class="math notranslate nohighlight">\(\boldsymbol{b}^{T}\boldsymbol{x}\)</span> を ベクトル
<span class="math notranslate nohighlight">\(\boldsymbol{x}\)</span>
で微分したいというシチュエーションが機械学習の中では登場します．つまり，</p>
<div class="math notranslate nohighlight">
\[\dfrac {\partial }{\partial \boldsymbol{x}}\left( \boldsymbol{b}^{T}\boldsymbol{x}\right)\]</div>
<p>を求めたいというわけです．これを<strong>ベクトルで微分</strong>すると言います．ベクトルで微分をとる場合はそれぞれのベクトルの成分<span class="math notranslate nohighlight">\(x_1, x_2\)</span>毎に偏微分を計算し，それを並べます．今回の例の場合は</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\begin{split}  \begin{aligned}
  \dfrac {\partial }{\partial \boldsymbol{x}}\left( \boldsymbol{b}^{T}\boldsymbol{x}\right) &amp;=\dfrac {\partial }{\partial \boldsymbol{x}}\left( 3x_{1}+4x_{2}\right) \\
  &amp;=\begin{bmatrix}
  \dfrac {\partial }{\partial x_{1}} \left( 3x_{1}+4x_{2}\right)  \\
  \dfrac {\partial }{\partial x_{2}} \left( 3x_{1}+4x_{2}\right)
  \end{bmatrix}
  \end{aligned}\end{split}\\のように，ベクトルの要素（今回だと\end{aligned}\end{align} \]</div>
<p><span class="math notranslate nohighlight">\(x_1\)</span>と<span class="math notranslate nohighlight">\(x_{2}\)</span>）のそれぞれで偏微分した値をベクトルとして格納していくだけです．一見複雑そうに見えますが，シンプルな演算で構成されていることがわかります．実際に計算していくと，</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}\dfrac {\partial }{\partial x_{1}}\left( 3x_{1}+4x_{2}\right) &amp;=\dfrac {\partial }{\partial x_{1}}\left( 3x_{1}\right) +\dfrac {\partial }{\partial x_{1}}\left( 4x_{2}\right) \\
&amp;=3\times \dfrac {\partial }{\partial x_{1}}\left( x_{1}\right) +4x_{2}\times \dfrac {\partial }{\partial x_{1}}\left( 1\right) \\
&amp;=3\times 1+4x_{2}\times 0\\
&amp;=3\end{aligned}\end{split}\]</div>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}\dfrac {\partial }{\partial x_{2}}\left( 3x_{1}+4x_{2}\right)&amp;=\dfrac {\partial }{\partial x_{2}}\left( 3x_{1}\right) +\dfrac {\partial }{\partial x_{2}}\left( 4x_{2}\right) \\
&amp;=3x_{1}\times \dfrac {\partial }{\partial x_{2}}\left( 1\right) +4\times \dfrac {\partial }{ax_{2}}\left( x_{2}\right) \\
&amp;=3x_{1} \times 0 + 4 \times 1 \\
&amp;= 4
\end{aligned}\end{split}\]</div>
<p>となり，下記の計算結果が得られます．</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\begin{split}  \begin{aligned}
  \dfrac {\partial }{\partial \boldsymbol{x}}\left( \boldsymbol{b}^{T}\boldsymbol{x}\right)
  &amp;=\begin{bmatrix}
  \dfrac {\partial }{\partial x_{1}} \left( 3x_{1}+4x_{2}\right)  \\
  \dfrac {\partial }{\partial x_{2}} \left( 3x_{1}+4x_{2}\right)
  \end{bmatrix} =\begin{bmatrix}
  3  \\
  4
  \end{bmatrix} = \boldsymbol{b}
  \end{aligned}\end{split}\\ここで，ベクトルで微分した結果が最初の :math:`\boldsymbol{b}`\end{aligned}\end{align} \]</div>
<p>と同じになっていることがわかります．これはたまたまではなく，一般的に成り立ちますが，この結果は最後に公式としてまとめましょう．</p>
<p>もう一問，以下の例題を考えましょう．</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\begin{split}  \begin{aligned}
  \boldsymbol{x}&amp;=\begin{bmatrix}
  x_{1} \\
  x_{2}
  \end{bmatrix}\\
  \dfrac {\partial }{\partial \boldsymbol{x}}\left( 1\right) &amp;=\begin{bmatrix}
  \dfrac {\partial }{\partial x_{1}}\left( 1\right)  \\
  \dfrac {\partial }{\partial x_{2}}\left( 1\right)
  \end{bmatrix}
  =\begin{bmatrix}
  0 \\
  0
  \end{bmatrix}=\boldsymbol{0}\end{aligned}\end{split}\\もちろん，偏微分を行う対象の変数が含まれていない場合は 0\end{aligned}\end{align} \]</div>
<p>となります．要素が 0
のみで構成されたベクトルを<strong>零（ゼロ）ベクトル</strong>と言います．</p>
<p>これらを踏まえて，公式としてまとめておきましょう．</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\begin{split}  \begin{aligned}
  &amp;\left( 1\right) \ \dfrac {\partial}{\partial \boldsymbol{x}}\left( c\right) = \boldsymbol{0}\\
  &amp;\left( 2\right) \ \dfrac {\partial }{\partial \boldsymbol{x}}\left( \boldsymbol{b}^{T}\boldsymbol{x}\right) = \boldsymbol{b}\\
  &amp;\left( 3\right) \ \dfrac {\partial }{\partial \boldsymbol{x}}\left( \boldsymbol{x}^{T}\boldsymbol{A}\boldsymbol{x}\right) =\left( \boldsymbol{A}+\boldsymbol{A}^{T}\right) \boldsymbol{x}\end{aligned}\end{split}\\(1)と(2) に関してはすでに計算したものであり，(3)\end{aligned}\end{align} \]</div>
<p>に関しては導出が少し複雑なので省略しますが，数値を代入して確認してみてください．こちらの3つの公式は機械学習を学んでいく上で非常に重要な公式となりますので，必ず覚えておきましょう．</p>
<p>こういった行列などにおける公式は他にもたくさんあり，論文などを読む際にはどういった公式があるのかを知っておくことも重要です．（例えば，<a class="reference external" href="https://www.math.uwaterloo.ca/~hwolkowi/matrixcookbook.pdf">The
Matrix
Cookbook</a>
が無料で公開されているので，参考にしてみてください．）</p>
</div>
</div>
<div class="section" id="統計">
<h2>1.5. 統計<a class="headerlink" href="#統計" title="このヘッドラインへのパーマリンク">¶</a></h2>
<div class="section" id="確率や統計は何に使えるのか">
<h3>1.5.1. 確率や統計は何に使えるのか<a class="headerlink" href="#確率や統計は何に使えるのか" title="このヘッドラインへのパーマリンク">¶</a></h3>
<p>機械学習といえば確率や統計といったイメージで勉強する人も多いと思いますが，簡単なアルゴリズムであれば，微分と線形代数を理解しておくだけで説明することができ，確率や統計が出てくることはありません．それでは，確率，統計では何を行うことができるのでしょうか．</p>
<p>それは，<strong>データの分布の情報を定量評価できる</strong>ことと，<strong>データの分布を定式化できる</strong>ことです．一見，同じように見えるかも知れませんが，目的がそれぞれ異なります．前者では，データの平均などといった情報を知ることで，アルゴリズム以前の<strong>データ前処理</strong>として使うことができます．後者では，分布の情報を定式化して<strong>機械学習のモデル</strong>に使用していきます．要するに使い道が前処理なのか，モデル化なのか，という違いです．前者の場合，学ぶべき数学が少なくて済むことに対し，後者の場合，<strong>ベイズ統計</strong>と呼ばれる生成モデルを取り扱うための数学が必要となり，多くの前提知識を必要とします．確率統計とひとまとめで呼ばれがちですが，前者が統計で，後者は確率として区別しています．</p>
<p>ここでは，まずデータの前処理のための統計を学んでいきましょう．この統計を学ぶことによって，次の2つの問題に対して解決策を提示できるようになります．各入力変数の値が0～100であったり，0～1であったり，スケールがばらばらであり，アルゴリズム内部でデータを扱う際にそのスケールの差による悪影響を受ける場合があります．このスケールを揃える方法を考えます．また，データの<strong>欠損値</strong>は簡単に見つけることができるため取り除くのは難しくありませんが，データの<strong>外れ値</strong>は「どのようなデータが外れているのか」といった定義が必要になります．この<strong>スケーリング</strong>と<strong>外れ値除去</strong>は，データの前処理として実務ではほぼ必ず行うものであり，重要なパートといえます．</p>
</div>
<div class="section" id="統計量">
<h3>1.5.2. 統計量<a class="headerlink" href="#統計量" title="このヘッドラインへのパーマリンク">¶</a></h3>
<p>ここでは，よく使う統計量である平均と分散について紹介します．</p>
<p>まずはじめに紹介するのは，最も有名な統計量である<strong>平均</strong>です．たとえば，300円,
400円, 500円の平均は，</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}  \dfrac{300 + 400 + 500}{3} = 400\\となり，すべてを足し合わせて対象の数で割ります．これを定式化すると，\end{aligned}\end{align} \]</div>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}  \begin{aligned}\overline {x}=\dfrac {x_{1}+x_{2}+\ldots +x_{N}}{N}
  =\dfrac {1}{N}\sum ^{N}_{n=1}x_{n}\end{aligned}\\のようになります．\ :math:`n`\end{aligned}\end{align} \]</div>
<p>は<strong>サンプルの数</strong>を表すときの文字として使用します．平均は，
<span class="math notranslate nohighlight">\(\bar{x}\)</span> や <span class="math notranslate nohighlight">\(\mu\)</span>
といった記号で表わされるのが一般的です．データの分布においては，その重心に相当する値となります．</p>
<p>次に，<strong>分散</strong>を紹介します．分散の定義は</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}  \begin{aligned}\sigma ^{2}=\dfrac {1}{N}\sum ^{N}_{n=1}\left( x_{n}-\overline {x}\right) ^{2}\end{aligned}\\です．各サンプルの平均 :math:`\bar{x}` からの差分 :math:`x- \bar{x}`\end{aligned}\end{align} \]</div>
<p>を計算し，それが二乗誤差の場合と同様，正と負の値を持ってしまうため，二乗してすべてを正にしてから<strong>総和</strong>を取って，平均の値を計算しています．つまり，平均からどの程度離れているか（の二乗）の平均値といえます．分散にはもう一つ定義があり，</p>
<div class="math notranslate nohighlight">
\[\begin{aligned}
\sigma ^{2}=\dfrac {1}{N-1}\sum ^{N}_{n=1}\left( x_{n}-\overline {x}\right) ^{2}
\end{aligned}\]</div>
<p>と表す場合もありあります．前者は<strong>母分散</strong>といい，後者は<strong>不偏分散</strong>といいます．これらの式の導出は他書に譲るとして，ここではその使い分けについて説明します．</p>
<p><img alt="image11" src="https://github.com/japan-medical-ai/medical-ai-course-materials/raw/master/notebooks/images/1/12.png" /></p>
<p>データ解析を行う際に，<strong>母集団</strong>に対する解析か<strong>標本集団</strong>に対する解析かを意識します．母集団とは解析を行いたい想定の範囲に対して，すべてのデータが揃っている場合であり，標本集団はそのうちの一部を抽出する場合です．例えば，全国の小学生の身長と体重を集計する場合に，全国の小学生を一人の抜け漏れもなく集められれば母集団であり，各都道府県で100人ずつ抜き出して集計する場合は標本集団です．母集団のデータを集めることは現実的に難しいことが多く，標本集団のデータから母集団の分布を推定することが一般的です．そうなると，基本的には標本集団向けである不偏分散を使用することになります．</p>
<p>さて，分散についての定義がわかったところで，これは何に使えるのでしょうか．分散はデータのばらつきを定量評価することができます．実験をしたときに，このばらつきが多ければ，各実験で再現性を確保できていないことを見つけることができるように，何度か試行して平均に集まっていることが望ましい状況において，ざっくりと感覚で議論するのではなく，定量評価できることはとても助かります．また，0～1のスケールのデータでは，分散は小さな値になり，0～1000のスケールのデータでは，分散は大きな値になります．もちろん，そのデータのばらつき具合にもよりますが，分散を使えば<strong>スケールの違い</strong>も評価することができます．そのため，この情報はスケーリングに使えそうであることがわかります．</p>
<p>最後に<strong>標準偏差</strong>です．分散では各サンプルの平均からの差の二乗の合計のため，単位は元の単位の二乗となっています．例えば元の単位がkgであれば，分散はkg*kgというスケールになります．これでは，分散が大きいかどうかを議論する場合に混乱してしまいます．そこで，元のスケールで議論するため，</p>
<div class="math notranslate nohighlight">
\[\sigma = \sqrt{\sigma^{2}}\]</div>
<p>のような分散の平方根を用いてばらつきをみます．これを標準偏差と呼びます．</p>
<p>それでは，定義と使い道が見えてきたところで，練習問題で具体的な計算手順の確認を行いましょう．以下の①と②のデータに対して，平均，分散，標準偏差を求めてください．ただし，今回は母分散を使用することとします．</p>
<p><img alt="image12" src="https://github.com/japan-medical-ai/medical-ai-course-materials/raw/master/notebooks/images/1/13.png" /></p>
<p>①の解答は以下の通りです．</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\begin{split}  \begin{aligned}
  \bar{x}&amp;=\dfrac {1}{5}\left( -2-1+0+1+2\right) =0\\
  \sigma ^{2}&amp;=\dfrac {1}{5}\left\{ \left( -2-0\right) ^{2}+\left( -1-0\right) ^{2}+(0-0)^{2}+(1-0)^{2}+(2-0)^{2}\right\} \\
  &amp;=\dfrac {1}{5}\times 10=2\\
  \sigma &amp;=\sqrt {2}
  \end{aligned}\end{split}\\また，②の解答は以下の通りです．\end{aligned}\end{align} \]</div>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
\overline {x}&amp;=\dfrac {1}{5}\left( -4-2+0+2+4\right) =0\\
\sigma ^{2}&amp;=\dfrac {1}{5}\left\{ \left( -4-0\right) ^{2}+\left( -2-0\right) ^{2}+\left( 0-0\right) ^{2}+\left( 2-0\right) ^{2}+\left( 4-0\right) ^{2}\right\} \\
&amp;=\dfrac {1}{5}\times 40=8\\
\sigma &amp;=\sqrt {8}=2\sqrt {2}
\end{aligned}\end{split}\]</div>
<p>これより，②のケースの方が分散が大きく，データのばらつきが大きいことがわかります．</p>
</div>
<div class="section" id="正規分布">
<h3>1.5.3. 正規分布<a class="headerlink" href="#正規分布" title="このヘッドラインへのパーマリンク">¶</a></h3>
<p>確率では何度も登場する<strong>正規分布</strong>です．<strong>ガウス分布</strong>とも呼ばれています．</p>
<p><img alt="image13" src="https://github.com/japan-medical-ai/medical-ai-course-materials/raw/master/notebooks/images/1/14.png" /></p>
<p>では，なぜこの正規分布がよく登場するのでしょうか．その理由として，以下のような物理的・数学的背景があります．</p>
<ul class="simple">
<li>物理現象でこの分布に従うことがよくある</li>
<li>数式が扱いやすい</li>
</ul>
<p>独立で多数の因子の和として表される確率変数は中心極限定理より正規分布に従うことが知られており，物理現象でこのような確率変数は多く扱われます．（一方で正規分布ではないような分布に対し正規分布にあてはめて考えてしまい誤った結論を導く場合も多々あります．）正規分布の数式が扱いやすいのは，正規分布は指数型分布族とよばれる形をしており，効率的な計算（尤度や事後確率分布など）ができるためです．</p>
<p>正規分布では平均 <span class="math notranslate nohighlight">\(\mu\)</span> と標準偏差 <span class="math notranslate nohighlight">\(\sigma\)</span>
に対して，何%がその分布に入っているかといった議論を良く行います．例えば，<span class="math notranslate nohighlight">\(\mu \pm 3\sigma\)</span>
の範囲内に，データの全体の99.7%が入るため，この <span class="math notranslate nohighlight">\(\mu \pm 3 \sigma\)</span>
に入らない領域を外れ値として定義するといった使い方をします．</p>
</div>
<div class="section" id="スケーリング">
<h3>1.5.4. スケーリング<a class="headerlink" href="#スケーリング" title="このヘッドラインへのパーマリンク">¶</a></h3>
<p>スケーリングはどのアルゴリズムでも前処理として重要になってきますが，ここでは簡単に２つの事例を紹介します．</p>
<p>まず１つ目が距離の問題です．スケールが異なる変数 <span class="math notranslate nohighlight">\(x_{1}\)</span> と
<span class="math notranslate nohighlight">\(x_{2}\)</span>
があった場合に，下記の図のような状況になります．ここで，縦軸と横軸のスケールが大きく異なりますが，わざと同じようなスケールに見えるようにプロットしています．</p>
<p><img alt="image14" src="https://github.com/japan-medical-ai/medical-ai-course-materials/raw/master/notebooks/images/1/15.png" /></p>
<p>この２点間の距離 <span class="math notranslate nohighlight">\(d\)</span> を求めると，</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\begin{split}  \begin{aligned}
  d&amp;=\sqrt {\left( 100-1000\right) ^{2}+\left( 0.1-1\right) ^{2}}\\
  &amp;= \sqrt {900^{2}+0.9^{2}}\\
  &amp;= \sqrt {810000+0.81} \\
  &amp;= \sqrt {810000.81}
  \end{aligned}\end{split}\\のようになります．ここで着目したい点として，\ :math:`x_{1}` と\end{aligned}\end{align} \]</div>
<p><span class="math notranslate nohighlight">\(x_{2}\)</span>のどちらが距離 <span class="math notranslate nohighlight">\(d\)</span>
に対して影響を与えているかですが，明らかに <span class="math notranslate nohighlight">\(x_{1}\)</span>
です．<span class="math notranslate nohighlight">\(x_{2}\)</span>
に関しては，スケールが小さいがゆえにほとんど影響を与えていません．これでは
<span class="math notranslate nohighlight">\(x_{2}\)</span>
がデータの意味として重要な場合においても考慮できません．こうした問題を解決する方法の一つが，ここで紹介する<strong>スケーリング</strong>です．代表的なスケーリングの方法としては２つあります．</p>
<p>１つ目が，サンプル集合を<strong>最小値0</strong>，<strong>最大値1</strong>にスケーリングする方法です．これを<strong>Min-Max
スケーリング</strong>と呼びます．この方法は単純で，各変数ごとに最小値
<span class="math notranslate nohighlight">\(x_{\min}\)</span> と最大値 <span class="math notranslate nohighlight">\(x_{\max}\)</span>
を求めておき，すべてのデータに対して，</p>
<div class="math notranslate nohighlight">
\[\widetilde{x} = \dfrac{x - x_{\min}}{x_{\max} - x_{\min}}\]</div>
<p>の計算を行います．Min-Maxスケーリングには計算が単純というメリットがある反面，下図の例ように<span class="math notranslate nohighlight">\(x_1\)</span>で外れ値を持つデータ点が存在するような場合，<span class="math notranslate nohighlight">\(x_{\max}\)</span>
が外れ値であるこの一点に大きく引っ張られてしまうという弱点があります．</p>
<p><img alt="image15" src="https://github.com/japan-medical-ai/medical-ai-course-materials/raw/master/notebooks/images/1/16.png" /></p>
<p>もう１つのスケーリングの方法として，<strong>平均0</strong>，<strong>標準偏差1</strong>
にスケーリングする方法があります．分散含め，標準偏差ではデータのばらつきを定量評価することができ，</p>
<div class="math notranslate nohighlight">
\[\widetilde{x}  = \dfrac{x - \bar{x}}{\sigma}\]</div>
<p>のように，標準偏差で割ることで，スケールを統一することができます．分散を計算した例題の①に対して，適用してみると，</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\begin{split}  \begin{aligned}
  x_{1}&amp;=\dfrac {-2-0}{\sqrt {2}}=-\dfrac {2}{\sqrt {2}}\\
  x_{2}&amp;=\dfrac {-1-0}{\sqrt {2}}=-\dfrac {1}{\sqrt {2}}\\
  x_{3}&amp;=\dfrac {0-0}{\sqrt {2}}=0\\
  x_{4}&amp;=\dfrac {1-0}{\sqrt {2}}=\dfrac {1}{\sqrt {2}}\\
  x_{5}&amp;=\dfrac {2-0}{\sqrt {2}}=\dfrac {2}{\sqrt {2}}
  \end{aligned}\end{split}\\のように，データが変換されます．この時の平均と標準偏差を求めてみると，\end{aligned}\end{align} \]</div>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
\overline {x}&amp;=\dfrac {1}{5}\left( -\dfrac {2}{\sqrt {2}}-\dfrac {1}{\sqrt {2}}+0+\dfrac {1}{\sqrt {2}}+\dfrac {2}{\sqrt {2}}\right) =0\\
\sigma ^{2}&amp;=\dfrac {1}{5}\left\{ \left( -\dfrac {2}{\sqrt {2}}-0\right) ^{2}+\left( -\dfrac {1}{\sqrt {2}}-0\right) ^{2}+\left( 0-0\right) ^{2}
 +\left( \dfrac {1}{\sqrt {2}}-0\right) ^{2}+\left( \dfrac {2}{\sqrt {2}}-0\right) ^{2}\right\} =1\\
\sigma &amp;=\sqrt {\sigma ^{2}}=1
\end{aligned}\end{split}\]</div>
<p>のように，平均0，標準偏差1にスケーリングできていることがわかります．この方法であれば，統計量を使用するため全体の傾向で議論することができ，１点だけの外れ値のようなケースには強い（これを<strong>ロバスト</strong>と表現する）と言えます．</p>
</div>
<div class="section" id="外れ値除去">
<h3>1.5.5. 外れ値除去<a class="headerlink" href="#外れ値除去" title="このヘッドラインへのパーマリンク">¶</a></h3>
<p>以下のように時間によって変動するようなデータを扱うとしましょう．例えば，横軸が時刻，縦軸がCPUの負荷率(%)と考えるとわかりやすいと思います．</p>
<p><img alt="image16" src="https://github.com/japan-medical-ai/medical-ai-course-materials/raw/master/notebooks/images/1/17.png" /></p>
<p>このデータに対して，CPUの負荷率の異常（外れ値）を検出したい場合，どのようにこの外れ値を定義して検出すれば良いでしょうか．その答えは，値の<strong>頻度</strong>に着目することです．</p>
<p><img alt="image17" src="https://github.com/japan-medical-ai/medical-ai-course-materials/raw/master/notebooks/images/1/18.png" /></p>
<p>上図のように，平均に対して線を引き，それぞれの値において頻度を算出してヒストグラムを描いてみると正規分布が現れます．物理現象として正規分布に従うものが多いと説明しましたが，このように中心付近の値の頻度は多く，離れるほど頻度が少なくなっていく現象では正規分布をあてはめることができます．そして，外れ値を定義するために，データの平均
<span class="math notranslate nohighlight">\(\mu\)</span> と標準偏差 <span class="math notranslate nohighlight">\(\sigma\)</span>
を計算し，<span class="math notranslate nohighlight">\(\mu \pm 3\sigma\)</span>の値に線を引けば，外れ値除去を行うことができます．これを<strong>3σ法</strong>と呼び，理論がシンプルかつ，プログラムの実装的にも平均と標準偏差だけで行えて簡単です．外れ値の回数が多い場合などは平均や標準偏差がその外れ値に引っ張られ，3σ法ではうまく対処できない場合があり，そのような場合には中央値をベースとした<strong>Hampel判別法</strong>を用います．</p>
<p>この他，データを大きい順に並べてそれらの上位10%，下位10%を取り除くといったことも行われます．</p>
<p>まず内側の関数を <span class="math notranslate nohighlight">\(u = (3x+4)\)</span> とおいて，</p>
<div class="math notranslate nohighlight">
\[\left\{ (3x + 4)^{2} \right\}' = (u^{2})'\]</div>
<p>とします．ここで，<span class="math notranslate nohighlight">\((\cdot)'\)</span>
をもう少し厳密に考える必要が出てきます．今は，<span class="math notranslate nohighlight">\(x\)</span> と <span class="math notranslate nohighlight">\(u\)</span>
の2つの変数が登場しており，<span class="math notranslate nohighlight">\((\cdot)'\)</span> では，<span class="math notranslate nohighlight">\(x\)</span>
で微分しているのか <span class="math notranslate nohighlight">\(u\)</span>
で微分しているのかの区別がつきません．そこで，多少複雑に見えますが，先程紹介した<span class="math notranslate nohighlight">\(d\)</span>を使った記法で微分する変数を厳密に記述すると，</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
\left\{ (3x + 4)^{2} \right\}' &amp;= \dfrac{d}{dx} \left\{ (3x + 4)^{2} \right\} \\
&amp;= \dfrac{d}{dx} (u^2) \\
&amp;=  \dfrac{d}{dx} f(u) \\
\end{aligned}\end{split}\]</div>
<p>となり，<span class="math notranslate nohighlight">\(u\)</span> の関数 <span class="math notranslate nohighlight">\(f(u) = u^{2}\)</span> に対して，<span class="math notranslate nohighlight">\(x\)</span>
で微分していることがわかります．．<span class="math notranslate nohighlight">\(x\)</span>を変化させた時に<span class="math notranslate nohighlight">\(f(u)\)</span>がどれだけ変化するのかはわかりません．そこで，<span class="math notranslate nohighlight">\(x\)</span>を単位量変化させた時に<span class="math notranslate nohighlight">\(u\)</span>がどれだけ変化するのか，<span class="math notranslate nohighlight">\(u\)</span>を単位量変化させた時に<span class="math notranslate nohighlight">\(f(u)\)</span>がどれだけ変化するのかを考え，それらの積を考えます．</p>
<div class="math notranslate nohighlight">
\[\begin{aligned}
\dfrac{df(u)}{dx} = \dfrac{du}{dx} \dfrac{df(u)}{du}
\end{aligned}\]</div>
<p>この時，<span class="math notranslate nohighlight">\(du\)</span>は分子と分母に出現しているので約分して消去してしまえば左辺と右辺は同じであるといった考え方を適用することができます．つまり，合成関数の計算は内側の微分と外側の微分をそれぞれ行い，その結果を掛け合わせれば良いわけです．それぞれの微分の計算は</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
 \dfrac{du}{dx} &amp;= \dfrac{d}{dx} (3x+4) = 3 \\
 \dfrac{df(u)}{du} &amp;= \dfrac{d}{du} u^{2} = 2u \\
\end{aligned}\end{split}\]</div>
<p>となります．これより，</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
\dfrac{df(u)}{dx} &amp;= \dfrac{du}{dx} \dfrac{df(u)}{du} \\
 &amp;= 3 \times 2u \\
 &amp;= 3 \times 2(3x+4) \\
 &amp;= 6(3x+4)
\end{aligned}\end{split}\]</div>
<p>が得られます．数式こそ多少複雑に見えますが，内側と外側をそれぞれ微分して掛け合わせるだけであり，実際の計算は慣れると簡単に行うことが出来ます．なお，今回は分数の約分という形で大雑把に説明しましたが，実際には極限を使って合成関数の微分が成り立つことを証明できます．ニューラルネットワークの学習では合成関数の微分を使用する場面が何度も登場するため，この計算方法をしっかりと覚えておきましょう．</p>
</div>
<div class="section" id="偏微分">
<span id="id26"></span><h3>1.3.6. 偏微分<a class="headerlink" href="#偏微分" title="このヘッドラインへのパーマリンク">¶</a></h3>
<p>微分最後のトピックとして，<strong>偏微分</strong>を紹介します．偏微分は多変数関数の微分です．機械学習では，1つの入力変数
<span class="math notranslate nohighlight">\(x\)</span> から出力変数 <span class="math notranslate nohighlight">\(y\)</span>
を予測するケースは稀であり，基本的には，複数の入力変数 <span class="math notranslate nohighlight">\(x_{1}\)</span>,
<span class="math notranslate nohighlight">\(x_{2}\)</span>, <span class="math notranslate nohighlight">\(\ldots\)</span>, <span class="math notranslate nohighlight">\(x_{M}\)</span> を用いて出力変数 <span class="math notranslate nohighlight">\(y\)</span>
を予測します．例えば，家賃を予測する場合，部屋の広さだけで予測するよりも，駅からの距離や犯罪発生率などを考慮した方が予測の性能は高まりそうだと考えられます．多変数
<span class="math notranslate nohighlight">\(x_{1}\)</span>, <span class="math notranslate nohighlight">\(x_{2}\)</span>, <span class="math notranslate nohighlight">\(\ldots\)</span>, <span class="math notranslate nohighlight">\(x_{M}\)</span>
を考慮した多変数関数 <span class="math notranslate nohighlight">\(f(x_{1}, x_{2}, \ldots, x_{M})\)</span>
では，各変数で微分することを偏微分と呼び，</p>
<div class="math notranslate nohighlight">
\[\dfrac{\partial}{\partial x_{m}} f(x_{1}, x_{2}, \ldots, x_{M})\]</div>
<p>のように表します．大雑把には，<span class="math notranslate nohighlight">\(d\)</span> が <span class="math notranslate nohighlight">\(\partial\)</span>
に変わっただけです．しかも，計算方法は至って単純であり，<span class="math notranslate nohighlight">\(\dfrac{\partial}{\partial x_{m}}\)</span>
の場合は <span class="math notranslate nohighlight">\(x_{m}\)</span> 以外は定数と考えて，<span class="math notranslate nohighlight">\(x_{m}\)</span>
のみ着目して微分を行います．</p>
<p>例題で具体的な計算の流れを確認していきましょう．</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
\dfrac {\partial }{\partial x_{1}}\left( 3x_{1}+4x_{2}\right) &amp;=\dfrac {\partial }{\partial x_{1}}\left( 3x_{1}\right) +\dfrac {\partial }{\partial x_{1}}\left( 4x_{2}\right) \\
&amp;=3\times \dfrac {\partial }{\partial x_{1}}\left( x_{1}\right) +4x_{2}\times \dfrac {\partial }{\partial x_{1}}\left( 1\right) \\
&amp;=3\times 1+4x_{2}\times 0\\
&amp;= 3
\end{aligned}\end{split}\]</div>
<p>偏微分でも微分と同じ線形性の性質が適用できます．今回のケースでは，<span class="math notranslate nohighlight">\(x_{1}\)</span>
にだけ着目するため，<span class="math notranslate nohighlight">\(x_{2}\)</span>
は定数として扱うことを把握しておけば上記の計算の流れが理解できるはずです．これが偏微分であり，参考書にはここからさらに全微分の話に入っていくことが多いですが，ひとまずここまでの計算の方法を理解しておけば，この後の計算は理解することができるはずです．</p>
</div>
</div>
<div class="section" id="線形代数">
<span id="id28"></span><h2>1.4. 線形代数<a class="headerlink" href="#線形代数" title="このヘッドラインへのパーマリンク">¶</a></h2>
<div class="section" id="線形代数は何に役立つのか">
<span id="id30"></span><h3>1.4.1. 線形代数は何に役立つのか<a class="headerlink" href="#線形代数は何に役立つのか" title="このヘッドラインへのパーマリンク">¶</a></h3>
<p>次に重要な概念が<strong>線形代数</strong>です．ベクトル，行列，ランク，逆行列などの概念が登場します．</p>
<p>さて，微分と同様に理論を学ぶ前に，これから学ぶ線形代数という学問がみなさんにとってどのようなメリットをもたらしてくれるかを考えましょう．<span class="math notranslate nohighlight">\(x_{1}\)</span>
や <span class="math notranslate nohighlight">\(x_{2}\)</span>
のように機械学習の中では，似たような複数の変数が登場してきます．これらの複数の変数間の関係を記述する上で線形代数は最も単純な数学ですが驚くほど多くの問題を扱うことができる重要な概念です．ぜひ身に着けていきましょう．</p>
</div>
<div class="section" id="スカラー，ベクトル，行列，テンソル">
<span id="id32"></span><h3>1.4.2. スカラー，ベクトル，行列，テンソル<a class="headerlink" href="#スカラー，ベクトル，行列，テンソル" title="このヘッドラインへのパーマリンク">¶</a></h3>
<p>最初に線形代数で使われる<strong>スカラー</strong>，<strong>ベクトル</strong>，<strong>行列</strong>，<strong>テンソル</strong>の4つを解説します．</p>
<p>スカラーは，1つの値もしくは変数のことです．例えば，</p>
<div class="math notranslate nohighlight">
\[x, \ y,\  M,\  N\]</div>
<p>のように表します．スカラーは例えば温度や身長といった単一の量を表すことに使われます．</p>
<p>ベクトルは，複数のスカラーを縦方向（もしくは横方向）に集めて並べたものであり，</p>
<div class="math notranslate nohighlight">
\[\begin{split}\boldsymbol{x}=\begin{bmatrix}
x_{1} \\
x_{2} \\
x_{3}
\end{bmatrix}, \
\boldsymbol{y}=\begin{bmatrix}
y_{1} \\
y_{2} \\
\vdots \\
y_{N}
\end{bmatrix}\end{split}\]</div>
<p>ように表します．ベクトルの表記は太文字とする場合が多く，スカラーかベクトルかを一目で区別できるようにしています．ベクトルを縦方向に定義するか横方向に定義するかは業界によって異なっていますが，数学や機械学習では縦方向で定義している論文や参考書が多いため，本講義では<strong>ベクトルは縦方向</strong>で統一します．</p>
<p>行列はさらに複数のベクトルをまとめたものであり，</p>
<div class="math notranslate nohighlight">
\[\begin{split}\boldsymbol{X}=\begin{bmatrix}
x_{11} &amp; x_{12} \\
x_{21} &amp; x_{22} \\
x_{31} &amp; x_{32}
\end{bmatrix}\end{split}\]</div>
<p>のように表します．行列のサイズは行と列で表現します．例えば，この
<span class="math notranslate nohighlight">\(\boldsymbol{X}\)</span> は3行2列であり，サイズが(3,
2)の行列と言います．また，行列の値が実数の場合がほとんどであり，よく
<span class="math notranslate nohighlight">\(\boldsymbol{X} \in \mathcal{R}^{3 \times 2}\)</span>のようにサイズを簡潔に表現することがあるため，こちらも覚えておきましょう．行は文字の中に横棒が２つ入っているため横方向の値の集まり，列は文字の中に縦棒が２つはいっているため縦方向の値というように覚えると楽かもしれません．行列の表記は大文字または大文字の太文字とする場合が多いです．</p>
<p>最後に，テンソルは行列をさらにまとめたものであり，図のように行列を奥行き方向にさらに並べたものとみなすことができます．さらにテンソル同士を並べたものもテンソルとよばれます．例えば，RGB
(Red Green Blue)
などの色空間で表現するカラー画像を表現する場合，（行番号，列番号，色）の3つの軸で一つの値を指定することができ，テンソルで表現することができます．</p>
<p><img alt="image18" src="https://github.com/japan-medical-ai/medical-ai-course-materials/raw/master/notebooks/images/1/07.png" /></p>
<p>これまで紹介してきたように，値を並べたものは，スカラー <span class="math notranslate nohighlight">\(\subset\)</span>
ベクトル <span class="math notranslate nohighlight">\(\subset\)</span> 行列 <span class="math notranslate nohighlight">\(\subset\)</span>
テンソルのような関係がありました．線形代数では <span class="math notranslate nohighlight">\(\boldsymbol{y}\)</span> や
<span class="math notranslate nohighlight">\(\boldsymbol{X}\)</span>
といった文字だけで式変形をしていくため，どのような形の数値が取り扱われているかわかりくいのですが，これはベクトルなどと常に意識しておくことでその形を見失わないように注意しましょう．</p>
<table border="1" class="docutils">
<colgroup>
<col width="20%" />
<col width="40%" />
<col width="40%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">&#160;</th>
<th class="head">小文字</th>
<th class="head">大文字</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>細文字</td>
<td>スカラーの変数</td>
<td>スカラーの定数</td>
</tr>
<tr class="row-odd"><td>太文字</td>
<td>ベクトル</td>
<td>行列，テンソル</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="足し算・引き算">
<span id="id34"></span><h3>1.4.3. 足し算・引き算<a class="headerlink" href="#足し算・引き算" title="このヘッドラインへのパーマリンク">¶</a></h3>
<p>行列やベクトルの演算について覚えていきましょう．足し算は同じサイズの行列，ベクトル間だけで成立し，</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}&amp;\begin{bmatrix}
1 \\
2 \\
3
\end{bmatrix}+\begin{bmatrix}
4 \\
5 \\
6
\end{bmatrix}=\begin{bmatrix}
1+4 \\
2+5 \\
3+6
\end{bmatrix}=\begin{bmatrix}
7 \\
8 \\
9
\end{bmatrix}\\
&amp;\begin{bmatrix}
1 &amp; 2 &amp; 3 \\
4 &amp; 5 &amp; 6
\end{bmatrix}+\begin{bmatrix}
7 &amp; 8 &amp; 9 \\
10 &amp; 11 &amp; 12
\end{bmatrix}=\begin{bmatrix}
8 &amp; 10 &amp; 12 \\
14 &amp; 16 &amp; 18
\end{bmatrix}\end{aligned}\end{split}\]</div>
<p>このように行列やベクトルの中の<strong>要素</strong>で対応する場所を足し合わせます．引き算も同様です．計算としては単純なものであり，特別なことはありません．<strong>同じサイズでないと計算が成立しない</strong>ということを覚えておきましょう．</p>
</div>
<div class="section" id="内積">
<span id="id36"></span><h3>1.4.4. 内積<a class="headerlink" href="#内積" title="このヘッドラインへのパーマリンク">¶</a></h3>
<p>同じサイズのベクトル間では内積が定義できます．内積は同じ位置で対応する値を掛けていき，それらを足し合わせたものです．</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}&amp;\begin{bmatrix}1 \\2 \\3\end{bmatrix}\cdot \begin{bmatrix}4 \\5 \\6\end{bmatrix}= 1\cdot4 + 2 \cdot 5  + 3 \cdot 6 = 36 \end{aligned}\end{split}\]</div>
</div>
<div class="section" id="かけ算（行列積）">
<span id="id38"></span><h3>1.4.5. かけ算（行列積）<a class="headerlink" href="#かけ算（行列積）" title="このヘッドラインへのパーマリンク">¶</a></h3>
<p>行列の掛け算は複数パターンあり，一般的に掛け算として認識されているものは<strong>行列積</strong>と呼ばれます．それ以外には外積や要素積（アダマール積）などがあります．行列<span class="math notranslate nohighlight">\(A\)</span>と行列<span class="math notranslate nohighlight">\(B\)</span>の行列積は<span class="math notranslate nohighlight">\(A\)</span>の各行と<span class="math notranslate nohighlight">\(B\)</span>の各列の内積を並べたものとして定義されます．例えば行列Aの2行目の行ベクトルと行列Bの3列目の列ベクトルの内積は結果の行列Cの2行3列目に対応します．</p>
<p><img alt="image19" src="https://github.com/japan-medical-ai/medical-ai-course-materials/raw/master/notebooks/images/1/matrixproduct.png" /></p>
<p>そして，内積が定義される条件はベクトルのサイズが等しいということでしたが，ここでもそれが成り立つために，Aの行のサイズ（=Aの列数）とBの列のサイズ（=Bの行数）が一致する必要があります．以下のように，「行」「列」と線を引きながら計算していきましょう．</p>
<p><img alt="image20" src="https://github.com/japan-medical-ai/medical-ai-course-materials/raw/master/notebooks/images/1/08.png" /></p>
<p>このように，単純に足し算や引き算のように要素ごとの積を扱うわけではないため，最初は計算に慣れが必要です．そして，行列積では計算が成り立つためには，以下の条件を満たす必要があります．</p>
<p><img alt="image21" src="https://github.com/japan-medical-ai/medical-ai-course-materials/raw/master/notebooks/images/1/09.png" /></p>
<p>この行列積は線形代数や機械学習の多くの問題で使われます．行列積はベクトルの集まりとベクトルの集まりの間の大量の内積計算をするようなものです．また，行列では割り算に相当する演算はありませんが，後述する逆行列を使って<span class="math notranslate nohighlight">\(4 / 2 = 4 \times \dfrac{1}{2}\)</span>
のように割り算を逆数（逆行列）の掛け算として記述します．</p>
<p>それでは，この計算条件の確認も踏まえて，下記の３つを練習問題として解いてください．</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
&amp;\left( 1\right) \begin{bmatrix} 1 &amp; 2 \end{bmatrix}\begin{bmatrix} 3 \\ 4 \end{bmatrix}\\
&amp;\left( 2\right) \begin{bmatrix} 1 &amp; 2 \\ 3 &amp; 4 \end{bmatrix}\begin{bmatrix} 5 \\ 6 \end{bmatrix}\\
&amp;\left( 3\right) \begin{bmatrix} 1 &amp; 2 \end{bmatrix}\begin{bmatrix} 3 &amp; 4 \\ 5 &amp; 6 \end{bmatrix}\begin{bmatrix} 3 \\ 1 \end{bmatrix}\end{aligned}\end{split}\]</div>
<p>こちらが解答です．</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
&amp;\left( 1\right) \begin{bmatrix} 1 &amp; 2 \end{bmatrix}\begin{bmatrix} 3 \\ 4 \end{bmatrix} = 1\times 3 + 2 \times 4 = 11\\
&amp;\left( 2\right) \begin{bmatrix} 1 &amp; 2 \\ 3 &amp; 4 \end{bmatrix}\begin{bmatrix} 5 \\ 6 \end{bmatrix} = \begin{bmatrix}1\times 5 + 2\times 6 \\3 \times 5 + 4 \times 6\end{bmatrix} = \begin{bmatrix}17 \\ 39\end{bmatrix}\\
&amp;\left( 3\right)
\begin{bmatrix}
1 &amp; 2
\end{bmatrix}\begin{bmatrix}
3 &amp; 4 \\
5 &amp; 6
\end{bmatrix}\begin{bmatrix}
3 \\
1
\end{bmatrix}
=\begin{bmatrix}
1 &amp; 2
\end{bmatrix}\begin{bmatrix}
3\times 3+4\times 1 \\
5\times 3 +6\times 1
\end{bmatrix}
&amp; \ \ =\begin{bmatrix}
1 &amp; 2
\end{bmatrix}\begin{bmatrix}
13 \\
21
\end{bmatrix}
=1 \times 13+2\times 21
=55
\end{aligned}\end{split}\]</div>
<p>計算のイメージは沸いたでしょうか．実は，この３つの計算は機械学習においてよく出てくる形の計算です．押さえておくべきポイントとして，演算後に形が変わることを覚えておきましょう．</p>
</div>
<div class="section" id="ベクトル，行列のサイズ">
<span id="id40"></span><h3>1.4.6. ベクトル，行列のサイズ<a class="headerlink" href="#ベクトル，行列のサイズ" title="このヘッドラインへのパーマリンク">¶</a></h3>
<p>計算を行う上でベクトル，行列の<strong>サイズ</strong>を常に意識しておくことが機械学習を円滑に理解するためのポイントとなります．例えば先ほどの３つの練習問題のサイズがどのように変化したかをまとめると，</p>
<p><img alt="image22" src="https://github.com/japan-medical-ai/medical-ai-course-materials/raw/master/notebooks/images/1/10.png" /></p>
<p>のとなります．もともとがベクトルや行列であっても，演算後にスカラーになるケースもあることがわかります．なぜこのサイズが変化する感覚をつかんでおくことが大事になるのでしょうか．</p>
<p>今回は計算結果を数値で追っていましたが，これからの計算はすべて数値ではなく文字で表現して扱います．例えば
<span class="math notranslate nohighlight">\(\boldsymbol{x}^{T}\boldsymbol{A}\boldsymbol{y}\)</span>
を見て，スカラーであると瞬時に判断できるようになる必要があります．ここで，ベクトルは縦向きで定義するため，横向きのベクトルは<strong>転置</strong>（記号は上付きの
<span class="math notranslate nohighlight">\(T\)</span>）を使うことによって表現しています．</p>
</div>
<div class="section" id="転置">
<span id="id42"></span><h3>1.4.7. 転置<a class="headerlink" href="#転置" title="このヘッドラインへのパーマリンク">¶</a></h3>
<p>ベクトルは縦向きが基本としていましたが，先程の計算問題などでは，しばしば横向きのベクトルが出てきました．そこで登場するベクトルの縦と横を入れ替える演算のことを<strong>転置</strong>（Transpose）と呼びます．例えば，</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}\boldsymbol{x}&amp;=\begin{bmatrix}
1 \\
2 \\
3
\end{bmatrix}, \
\boldsymbol{x}^{T}=\begin{bmatrix} 1 &amp; 2 &amp; 3 \end{bmatrix} \\
\boldsymbol{X}&amp;=\begin{bmatrix}
1 &amp; 4 \\
2 &amp; 5 \\
3 &amp; 6
\end{bmatrix}, \
\boldsymbol{X}^{T}=\begin{bmatrix}
1 &amp; 2 &amp; 3 \\
4 &amp; 5 &amp; 6
\end{bmatrix}\end{aligned}\end{split}\]</div>
<p>のようになります．このように転置自体の演算は簡単です．先程の行列積の演算も正確には各行の転値と行列の内積となります．転置では下記3つの公式を覚えておくと，これからの計算が楽になります．</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}&amp;\left( 1\right) \ \left( \boldsymbol{A}^{T}\right)^{T}=\boldsymbol{A}\\
&amp;\left( 2\right) \ \left( \boldsymbol{A}\boldsymbol{B}\right) ^{T}=\boldsymbol{B}^{T}\boldsymbol{A}^{T}\\
&amp;\left( 3\right) \ \left( \boldsymbol{A}\boldsymbol{B}\boldsymbol{C}\right) ^{T}=\boldsymbol{C}^{T}\boldsymbol{B}^{T}\boldsymbol{A}^{T}\end{aligned}\end{split}\]</div>
</div>
<div class="section" id="単位行列">
<span id="id44"></span><h3>1.4.8. 単位行列<a class="headerlink" href="#単位行列" title="このヘッドラインへのパーマリンク">¶</a></h3>
<p>単位行列とは，スカラーの１に対応した性質をもつ行列です．どのような性質かというと，<span class="math notranslate nohighlight">\(10\times1\)</span>
のように，その数を任意の数に乗じても変わらないという性質です．行列の演算において，これと同様の働きをする行列が<strong>単位行列</strong>であり，</p>
<div class="math notranslate nohighlight">
\[\begin{split}\boldsymbol{I}=\begin{bmatrix}
1 &amp; 0 &amp; \ldots  &amp; 0 \\
0 &amp; 1 &amp; \ldots  &amp; 0 \\
\vdots &amp; \vdots  &amp; \ddots  &amp; \vdots  \\
0 &amp; 0 &amp; \ldots  &amp; 1
\end{bmatrix}\end{split}\]</div>
<p>のような形をしています．行列の斜めの要素を<strong>対角要素</strong>と呼び，それ以外の要素を非対角要素とよびます．単位行列は，対角要素が1で，非対角要素が0であるような行列です．例えば，
<span class="math notranslate nohighlight">\(\boldsymbol{I} \in \mathcal{R}^{2\times 2}\)</span> の場合，</p>
<div class="math notranslate nohighlight">
\[\begin{split}\boldsymbol{I} =\begin{bmatrix}
1 &amp; 0 \\
0 &amp; 1
\end{bmatrix}\end{split}\]</div>
<p>であり，<span class="math notranslate nohighlight">\(\boldsymbol{I} \in \mathcal{R}^{3\times 3}\)</span> の場合，</p>
<div class="math notranslate nohighlight">
\[\begin{split}\boldsymbol{I}=\begin{bmatrix}
1 &amp; 0 &amp; 0 \\
0 &amp; 1 &amp; 0 \\
0 &amp; 0 &amp; 1
\end{bmatrix}\end{split}\]</div>
<p>となります．</p>
<p>実際に計算して，元の行列と値が変わらないかを確認してみると，</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}\begin{bmatrix}
1 &amp; 2 \\
3 &amp; 4
\end{bmatrix}\begin{bmatrix}
1 &amp; 0 \\
0 &amp; 1
\end{bmatrix}
&amp;=\begin{bmatrix}
1\times 1+2\times 6 &amp; 1\times 0+2\times 1 \\
3\times 1+4\times 0 &amp; 3\times 0+4\times 1
\end{bmatrix}\\
&amp;=
\begin{bmatrix}
1 &amp; 2 \\
3 &amp; 4
\end{bmatrix}
\end{aligned}\end{split}\]</div>
<p>のように，確かに元の値と同じであることがわかりました．単位行列
<span class="math notranslate nohighlight">\(\boldsymbol{I}\)</span> は任意の行列<span class="math notranslate nohighlight">\(\boldsymbol{A}\)</span>に対し</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
\boldsymbol{A}\boldsymbol{I}&amp;=\boldsymbol{A}\\
\boldsymbol{I}\boldsymbol{A}&amp;=\boldsymbol{A}
\end{aligned}\end{split}\]</div>
<p>が成り立ちます．</p>
</div>
<div class="section" id="逆行列">
<span id="id46"></span><h3>1.4.9. 逆行列<a class="headerlink" href="#逆行列" title="このヘッドラインへのパーマリンク">¶</a></h3>
<p><strong>逆行列</strong>とは</p>
<div class="math notranslate nohighlight">
\[2 \times 2^{-1} = 1\]</div>
<p>のようなスカラーの逆数に対応するような行列です．英語では <strong>Inverse
Matrix</strong>とよびます．</p>
<p>逆行列の定義は</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
\boldsymbol{A}\boldsymbol{A}^{-1}=\boldsymbol{I}\\
\boldsymbol{A}^{-1}\boldsymbol{A}=\boldsymbol{I}
\end{aligned}\end{split}\]</div>
<p>であり，ここで，<span class="math notranslate nohighlight">\(\boldsymbol{I}\)</span>
は単位行列です．この逆行列も機械学習の計算過程に頻出するため覚えておきましょう．大学で習う線形代数の授業では，サイズが<span class="math notranslate nohighlight">\(2 \times 2\)</span>
や <span class="math notranslate nohighlight">\(3 \times 3\)</span>
であるような行列の逆行列の計算方法について習いますが，機械学習で扱う行列のサイズは
<span class="math notranslate nohighlight">\(10 \times 10, 1000 \times 1000\)</span>
と大きく，逆行列を効率的に求める計算手法が提案されています．その計算方法については必ずしも知っておく必要はありませんが，どのような行列においても逆行列を計算できるわけではないため，逆行列が計算できるための条件は知っておきましょう．逆行列は<strong>正方行列</strong>と呼ばれる行と列のサイズが同じであるような行列でないと計算できません．</p>
<p>もう一つの条件についてはそれを説明するのに必要な概念をまだ紹介していませんが，行列がフルランク（行列のランクが行数=列数）であること，これと等価で行列値が非0である必要があります．実は世の中の多くの行列はこれらを満たしませんが，対角成分に非ゼロの値を足すことで行列をフルランクにし，逆行列を計算できるようになります．もしアルゴリズムの中で逆行列を求める前に対角要素に小さな値を足すような操作があれば，それは逆行列を計算できるようにしていると思ってください．</p>
<p><img alt="image23" src="https://github.com/japan-medical-ai/medical-ai-course-materials/raw/master/notebooks/images/1/11.png" /></p>
</div>
<div class="section" id="線形結合と二次形式">
<span id="id48"></span><h3>1.4.10. 線形結合と二次形式<a class="headerlink" href="#線形結合と二次形式" title="このヘッドラインへのパーマリンク">¶</a></h3>
<p>機械学習の式によく出てくる形式として
<span class="math notranslate nohighlight">\(\boldsymbol{b}^{T}\boldsymbol{x}\)</span> と
<span class="math notranslate nohighlight">\(\boldsymbol{x}^{T}\boldsymbol{A}\boldsymbol{x}\)</span>
のような２形式があります．前者は*線形結合<strong>もしくは</strong>一次結合<strong>，後者は</strong>二次形式**と呼ばれています．中学校数学でいうところの，一次式や二次式の話と考えてもらうと分かりやすいと思います．</p>
<p>線形結合の計算の中身を見てみると，</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
\boldsymbol{b}&amp;=\begin{bmatrix}
1 \\
2
\end{bmatrix},\
\boldsymbol{x}=\begin{bmatrix}
x_{1} \\
x_{2}
\end{bmatrix}\\
\boldsymbol{b}^{T}\boldsymbol{x}&amp;=\begin{bmatrix}
1 &amp; 2
\end{bmatrix}\begin{bmatrix}
x_{1} \\
x_{2}
\end{bmatrix}=x_{1}+2x_{2}\end{aligned}\end{split}\]</div>
<p>のように <span class="math notranslate nohighlight">\(\boldsymbol{x}\)</span> の要素である <span class="math notranslate nohighlight">\(x_{1}\)</span> もしくは
<span class="math notranslate nohighlight">\(x_{2}\)</span> に関して，一次式となっていることがわかります．</p>
<p>また，二次形式も同様に計算の中身を確認してみると，</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
\boldsymbol{A}&amp;=\begin{bmatrix}
1 &amp; 2 \\
3 &amp; 4
\end{bmatrix},\
\boldsymbol{x}=\begin{bmatrix}
x_{1} \\
x_{2}
\end{bmatrix}\\
\boldsymbol{x}^{T}\boldsymbol{A}\boldsymbol{x}
&amp;=\begin{bmatrix} x_{1} &amp; x_{2}\end{bmatrix}
\begin{bmatrix}
1 &amp; 2 \\
3 &amp; 4
\end{bmatrix}\begin{bmatrix}
x_{1} \\
x_{2}
\end{bmatrix}\\
&amp;=\begin{bmatrix}x_{1} &amp; x_{2}\end{bmatrix} \begin{bmatrix}
x_{1}+2x_{2} \\
3x_{1}+4x_{2}
\end{bmatrix}\\
&amp;=x_{1}\left( x_{1}+2x_{2}\right) +x_{2}\left( 3x_{1}+4x_{2}\right) \\
&amp;=x^{2}_{1}+5x_{1}x_{2}+4x_{2}^{2}\end{aligned}\end{split}\]</div>
<p>となり，各要素において二次式となっていることがわかります．</p>
<p>そして，一般にこれらを足し合わせて，</p>
<div class="math notranslate nohighlight">
\[\boldsymbol{x}^{T}\boldsymbol{A}\boldsymbol{x} + \boldsymbol{b}^{T}\boldsymbol{x} + c\]</div>
<p>のように二次関数を表現します．ここで，<span class="math notranslate nohighlight">\(c\)</span>
はスカラーの定数項です．</p>
</div>
<div class="section" id="勾配　ベクトルで微分">
<span id="id50"></span><h3>1.4.11. 勾配　ベクトルで微分<a class="headerlink" href="#勾配　ベクトルで微分" title="このヘッドラインへのパーマリンク">¶</a></h3>
<p>微分は入力を変えた場合の関数値の変化量と説明しました．同様に関数の入力がベクトルであり，ベクトルで微分をとることも考えることができます．</p>
<p>機械学習で使われるのが勾配です．これは関数をそれぞれのベクトルの成分毎に偏微分を計算し，それらを並べてベクトルにしたものです．</p>
<p>勾配の計算を紹介する前に，下記の例題を計算しましょう．</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
\boldsymbol{b}&amp;=\begin{bmatrix}
3 \\
4
\end{bmatrix}, \
\boldsymbol{x}=\begin{bmatrix}
x_{1} \\
x_{2}
\end{bmatrix}\\
\boldsymbol{b}^{T}\boldsymbol{x}&amp;=\begin{bmatrix}
3 &amp; 4
\end{bmatrix}\begin{bmatrix}
x_{1} \\
x_{2}
\end{bmatrix}
=3x_{1}+4x_{2}\end{aligned}\end{split}\]</div>
<p>この計算は線形結合としてすでに紹介していますが，ここからが本題です．この
<span class="math notranslate nohighlight">\(\boldsymbol{b}^{T}\boldsymbol{x}\)</span> を ベクトル
<span class="math notranslate nohighlight">\(\boldsymbol{x}\)</span>
で微分したいというシチュエーションが機械学習の中では登場します．つまり，</p>
<div class="math notranslate nohighlight">
\[\dfrac {\partial }{\partial \boldsymbol{x}}\left( \boldsymbol{b}^{T}\boldsymbol{x}\right)\]</div>
<p>を求めたいというわけです．これを<strong>ベクトルで微分</strong>すると言います．ベクトルで微分をとる場合はそれぞれのベクトルの成分<span class="math notranslate nohighlight">\(x_1, x_2\)</span>毎に偏微分を計算し，それを並べます．今回の例の場合は</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
\dfrac {\partial }{\partial \boldsymbol{x}}\left( \boldsymbol{b}^{T}\boldsymbol{x}\right) &amp;=\dfrac {\partial }{\partial \boldsymbol{x}}\left( 3x_{1}+4x_{2}\right) \\
&amp;=\begin{bmatrix}
\dfrac {\partial }{\partial x_{1}} \left( 3x_{1}+4x_{2}\right)  \\
\dfrac {\partial }{\partial x_{2}} \left( 3x_{1}+4x_{2}\right)
\end{bmatrix}
\end{aligned}\end{split}\]</div>
<p>のように，ベクトルの要素（今回だと
<span class="math notranslate nohighlight">\(x_1\)</span>と<span class="math notranslate nohighlight">\(x_{2}\)</span>）のそれぞれで偏微分した値をベクトルとして格納していくだけです．一見複雑そうに見えますが，シンプルな演算で構成されていることがわかります．実際に計算していくと，</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}\dfrac {\partial }{\partial x_{1}}\left( 3x_{1}+4x_{2}\right) &amp;=\dfrac {\partial }{\partial x_{1}}\left( 3x_{1}\right) +\dfrac {\partial }{\partial x_{1}}\left( 4x_{2}\right) \\
&amp;=3\times \dfrac {\partial }{\partial x_{1}}\left( x_{1}\right) +4x_{2}\times \dfrac {\partial }{\partial x_{1}}\left( 1\right) \\
&amp;=3\times 1+4x_{2}\times 0\\
&amp;=3\end{aligned}\end{split}\]</div>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}\dfrac {\partial }{\partial x_{2}}\left( 3x_{1}+4x_{2}\right)&amp;=\dfrac {\partial }{\partial x_{2}}\left( 3x_{1}\right) +\dfrac {\partial }{\partial x_{2}}\left( 4x_{2}\right) \\
&amp;=3x_{1}\times \dfrac {\partial }{\partial x_{2}}\left( 1\right) +4\times \dfrac {\partial }{ax_{2}}\left( x_{2}\right) \\
&amp;=3x_{1} \times 0 + 4 \times 1 \\
&amp;= 4
\end{aligned}\end{split}\]</div>
<p>となり，下記の計算結果が得られます．</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
\dfrac {\partial }{\partial \boldsymbol{x}}\left( \boldsymbol{b}^{T}\boldsymbol{x}\right)
&amp;=\begin{bmatrix}
\dfrac {\partial }{\partial x_{1}} \left( 3x_{1}+4x_{2}\right)  \\
\dfrac {\partial }{\partial x_{2}} \left( 3x_{1}+4x_{2}\right)
\end{bmatrix} =\begin{bmatrix}
3  \\
4
\end{bmatrix} = \boldsymbol{b}
\end{aligned}\end{split}\]</div>
<p>ここで，ベクトルで微分した結果が最初の <span class="math notranslate nohighlight">\(\boldsymbol{b}\)</span>
と同じになっていることがわかります．これはたまたまではなく，一般的に成り立ちますが，この結果は最後に公式としてまとめましょう．</p>
<p>もう一問，以下の例題を考えましょう．</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
\boldsymbol{x}&amp;=\begin{bmatrix}
x_{1} \\
x_{2}
\end{bmatrix}\\
\dfrac {\partial }{\partial \boldsymbol{x}}\left( 1\right) &amp;=\begin{bmatrix}
\dfrac {\partial }{\partial x_{1}}\left( 1\right)  \\
\dfrac {\partial }{\partial x_{2}}\left( 1\right)
\end{bmatrix}
=\begin{bmatrix}
0 \\
0
\end{bmatrix}=\boldsymbol{0}\end{aligned}\end{split}\]</div>
<p>もちろん，偏微分を行う対象の変数が含まれていない場合は 0
となります．要素が 0
のみで構成されたベクトルを<strong>零（ゼロ）ベクトル</strong>と言います．</p>
<p>これらを踏まえて，公式としてまとめておきましょう．</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
&amp;\left( 1\right) \ \dfrac {\partial}{\partial \boldsymbol{x}}\left( c\right) = \boldsymbol{0}\\
&amp;\left( 2\right) \ \dfrac {\partial }{\partial \boldsymbol{x}}\left( \boldsymbol{b}^{T}\boldsymbol{x}\right) = \boldsymbol{b}\\
&amp;\left( 3\right) \ \dfrac {\partial }{\partial \boldsymbol{x}}\left( \boldsymbol{x}^{T}\boldsymbol{A}\boldsymbol{x}\right) =\left( \boldsymbol{A}+\boldsymbol{A}^{T}\right) \boldsymbol{x}\end{aligned}\end{split}\]</div>
<p>(1)と(2) に関してはすでに計算したものであり，(3)
に関しては導出が少し複雑なので省略しますが，数値を代入して確認してみてください．こちらの3つの公式は機械学習を学んでいく上で非常に重要な公式となりますので，必ず覚えておきましょう．</p>
<p>こういった行列などにおける公式は他にもたくさんあり，論文などを読む際にはどういった公式があるのかを知っておくことも重要です．（例えば，<a class="reference external" href="https://www.math.uwaterloo.ca/~hwolkowi/matrixcookbook.pdf">The
Matrix
Cookbook</a>
が無料で公開されているので，参考にしてみてください．）</p>
</div>
</div>
<div class="section" id="統計">
<span id="id52"></span><h2>1.5. 統計<a class="headerlink" href="#統計" title="このヘッドラインへのパーマリンク">¶</a></h2>
<div class="section" id="確率や統計は何に使えるのか">
<span id="id54"></span><h3>1.5.1. 確率や統計は何に使えるのか<a class="headerlink" href="#確率や統計は何に使えるのか" title="このヘッドラインへのパーマリンク">¶</a></h3>
<p>機械学習といえば確率や統計といったイメージで勉強する人も多いと思いますが，簡単なアルゴリズムであれば，微分と線形代数を理解しておくだけで説明することができ，確率や統計が出てくることはありません．それでは，確率，統計では何を行うことができるのでしょうか．</p>
<p>それは，<strong>データの分布の情報を定量評価できる</strong>ことと，<strong>データの分布を定式化できる</strong>ことです．一見，同じように見えるかも知れませんが，目的がそれぞれ異なります．前者では，データの平均などといった情報を知ることで，アルゴリズム以前の<strong>データ前処理</strong>として使うことができます．後者では，分布の情報を定式化して<strong>機械学習のモデル</strong>に使用していきます．要するに使い道が前処理なのか，モデル化なのか，という違いです．前者の場合，学ぶべき数学が少なくて済むことに対し，後者の場合，<strong>ベイズ統計</strong>と呼ばれる生成モデルを取り扱うための数学が必要となり，多くの前提知識を必要とします．確率統計とひとまとめで呼ばれがちですが，前者が統計で，後者は確率として区別しています．</p>
<p>ここでは，まずデータの前処理のための統計を学んでいきましょう．この統計を学ぶことによって，次の2つの問題に対して解決策を提示できるようになります．各入力変数の値が0～100であったり，0～1であったり，スケールがばらばらであり，アルゴリズム内部でデータを扱う際にそのスケールの差による悪影響を受ける場合があります．このスケールを揃える方法を考えます．また，データの<strong>欠損値</strong>は簡単に見つけることができるため取り除くのは難しくありませんが，データの<strong>外れ値</strong>は「どのようなデータが外れているのか」といった定義が必要になります．この<strong>スケーリング</strong>と<strong>外れ値除去</strong>は，データの前処理として実務ではほぼ必ず行うものであり，重要なパートといえます．</p>
</div>
<div class="section" id="統計量">
<span id="id56"></span><h3>1.5.2. 統計量<a class="headerlink" href="#統計量" title="このヘッドラインへのパーマリンク">¶</a></h3>
<p>ここでは，よく使う統計量である平均と分散について紹介します．</p>
<p>まずはじめに紹介するのは，最も有名な統計量である<strong>平均</strong>です．たとえば，300円,
400円, 500円の平均は，</p>
<div class="math notranslate nohighlight">
\[\dfrac{300 + 400 + 500}{3} = 400\]</div>
<p>となり，すべてを足し合わせて対象の数で割ります．これを定式化すると，</p>
<div class="math notranslate nohighlight">
\[\begin{aligned}\overline {x}=\dfrac {x_{1}+x_{2}+\ldots +x_{N}}{N}
=\dfrac {1}{N}\sum ^{N}_{n=1}x_{n}\end{aligned}\]</div>
<p>のようになります．<span class="math notranslate nohighlight">\(n\)</span>
は<strong>サンプルの数</strong>を表すときの文字として使用します．平均は，
<span class="math notranslate nohighlight">\(\bar{x}\)</span> や <span class="math notranslate nohighlight">\(\mu\)</span>
といった記号で表わされるのが一般的です．データの分布においては，その重心に相当する値となります．</p>
<p>次に，<strong>分散</strong>を紹介します．分散の定義は</p>
<div class="math notranslate nohighlight">
\[\begin{aligned}\sigma ^{2}=\dfrac {1}{N}\sum ^{N}_{n=1}\left( x_{n}-\overline {x}\right) ^{2}\end{aligned}\]</div>
<p>です．各サンプルの平均 <span class="math notranslate nohighlight">\(\bar{x}\)</span> からの差分 <span class="math notranslate nohighlight">\(x- \bar{x}\)</span>
を計算し，それが二乗誤差の場合と同様，正と負の値を持ってしまうため，二乗してすべてを正にしてから<strong>総和</strong>を取って，平均の値を計算しています．つまり，平均からどの程度離れているか（の二乗）の平均値といえます．分散にはもう一つ定義があり，</p>
<div class="math notranslate nohighlight">
\[\begin{aligned}
\sigma ^{2}=\dfrac {1}{N-1}\sum ^{N}_{n=1}\left( x_{n}-\overline {x}\right) ^{2}
\end{aligned}\]</div>
<p>と表す場合もありあります．前者は<strong>母分散</strong>といい，後者は<strong>不偏分散</strong>といいます．これらの式の導出は他書に譲るとして，ここではその使い分けについて説明します．</p>
<p><img alt="image24" src="https://github.com/japan-medical-ai/medical-ai-course-materials/raw/master/notebooks/images/1/12.png" /></p>
<p>データ解析を行う際に，<strong>母集団</strong>に対する解析か<strong>標本集団</strong>に対する解析かを意識します．母集団とは解析を行いたい想定の範囲に対して，すべてのデータが揃っている場合であり，標本集団はそのうちの一部を抽出する場合です．例えば，全国の小学生の身長と体重を集計する場合に，全国の小学生を一人の抜け漏れもなく集められれば母集団であり，各都道府県で100人ずつ抜き出して集計する場合は標本集団です．母集団のデータを集めることは現実的に難しいことが多く，標本集団のデータから母集団の分布を推定することが一般的です．そうなると，基本的には標本集団向けである不偏分散を使用することになります．</p>
<p>さて，分散についての定義がわかったところで，これは何に使えるのでしょうか．分散はデータのばらつきを定量評価することができます．実験をしたときに，このばらつきが多ければ，各実験で再現性を確保できていないことを見つけることができるように，何度か試行して平均に集まっていることが望ましい状況において，ざっくりと感覚で議論するのではなく，定量評価できることはとても助かります．また，0～1のスケールのデータでは，分散は小さな値になり，0～1000のスケールのデータでは，分散は大きな値になります．もちろん，そのデータのばらつき具合にもよりますが，分散を使えば<strong>スケールの違い</strong>も評価することができます．そのため，この情報はスケーリングに使えそうであることがわかります．</p>
<p>最後に<strong>標準偏差</strong>です．分散では各サンプルの平均からの差の二乗の合計のため，単位は元の単位の二乗となっています．例えば元の単位がkgであれば，分散はkg*kgというスケールになります．これでは，分散が大きいかどうかを議論する場合に混乱してしまいます．そこで，元のスケールで議論するため，</p>
<div class="math notranslate nohighlight">
\[\sigma = \sqrt{\sigma^{2}}\]</div>
<p>のような分散の平方根を用いてばらつきをみます．これを標準偏差と呼びます．</p>
<p>それでは，定義と使い道が見えてきたところで，練習問題で具体的な計算手順の確認を行いましょう．以下の①と②のデータに対して，平均，分散，標準偏差を求めてください．ただし，今回は母分散を使用することとします．</p>
<p><img alt="image25" src="https://github.com/japan-medical-ai/medical-ai-course-materials/raw/master/notebooks/images/1/13.png" /></p>
<p>①の解答は以下の通りです．</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
\bar{x}&amp;=\dfrac {1}{5}\left( -2-1+0+1+2\right) =0\\
\sigma ^{2}&amp;=\dfrac {1}{5}\left\{ \left( -2-0\right) ^{2}+\left( -1-0\right) ^{2}+(0-0)^{2}+(1-0)^{2}+(2-0)^{2}\right\} \\
&amp;=\dfrac {1}{5}\times 10=2\\
\sigma &amp;=\sqrt {2}
\end{aligned}\end{split}\]</div>
<p>また，②の解答は以下の通りです．</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
\overline {x}&amp;=\dfrac {1}{5}\left( -4-2+0+2+4\right) =0\\
\sigma ^{2}&amp;=\dfrac {1}{5}\left\{ \left( -4-0\right) ^{2}+\left( -2-0\right) ^{2}+\left( 0-0\right) ^{2}+\left( 2-0\right) ^{2}+\left( 4-0\right) ^{2}\right\} \\
&amp;=\dfrac {1}{5}\times 40=8\\
\sigma &amp;=\sqrt {8}=2\sqrt {2}
\end{aligned}\end{split}\]</div>
<p>これより，②のケースの方が分散が大きく，データのばらつきが大きいことがわかります．</p>
</div>
<div class="section" id="正規分布">
<span id="id58"></span><h3>1.5.3. 正規分布<a class="headerlink" href="#正規分布" title="このヘッドラインへのパーマリンク">¶</a></h3>
<p>確率では何度も登場する<strong>正規分布</strong>です．<strong>ガウス分布</strong>とも呼ばれています．</p>
<p><img alt="image26" src="https://github.com/japan-medical-ai/medical-ai-course-materials/raw/master/notebooks/images/1/14.png" /></p>
<p>では，なぜこの正規分布がよく登場するのでしょうか．その理由として，以下のような物理的・数学的背景があります．</p>
<ul class="simple">
<li>物理現象でこの分布に従うことがよくある</li>
<li>数式が扱いやすい</li>
</ul>
<p>独立で多数の因子の和として表される確率変数は中心極限定理より正規分布に従うことが知られており，物理現象でこのような確率変数は多く扱われます．（一方で正規分布ではないような分布に対し正規分布にあてはめて考えてしまい誤った結論を導く場合も多々あります．）正規分布の数式が扱いやすいのは，正規分布は指数型分布族とよばれる形をしており，効率的な計算（尤度や事後確率分布など）ができるためです．</p>
<p>正規分布では平均 <span class="math notranslate nohighlight">\(\mu\)</span> と標準偏差 <span class="math notranslate nohighlight">\(\sigma\)</span>
に対して，何%がその分布に入っているかといった議論を良く行います．例えば，<span class="math notranslate nohighlight">\(\mu \pm 3\sigma\)</span>
の範囲内に，データの全体の99.7%が入るため，この <span class="math notranslate nohighlight">\(\mu \pm 3 \sigma\)</span>
に入らない領域を外れ値として定義するといった使い方をします．</p>
</div>
<div class="section" id="スケーリング">
<span id="id60"></span><h3>1.5.4. スケーリング<a class="headerlink" href="#スケーリング" title="このヘッドラインへのパーマリンク">¶</a></h3>
<p>スケーリングはどのアルゴリズムでも前処理として重要になってきますが，ここでは簡単に２つの事例を紹介します．</p>
<p>まず１つ目が距離の問題です．スケールが異なる変数 <span class="math notranslate nohighlight">\(x_{1}\)</span> と
<span class="math notranslate nohighlight">\(x_{2}\)</span>
があった場合に，下記の図のような状況になります．ここで，縦軸と横軸のスケールが大きく異なりますが，わざと同じようなスケールに見えるようにプロットしています．</p>
<p><img alt="image27" src="https://github.com/japan-medical-ai/medical-ai-course-materials/raw/master/notebooks/images/1/15.png" /></p>
<p>この２点間の距離 <span class="math notranslate nohighlight">\(d\)</span> を求めると，</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
d&amp;=\sqrt {\left( 100-1000\right) ^{2}+\left( 0.1-1\right) ^{2}}\\
&amp;= \sqrt {900^{2}+0.9^{2}}\\
&amp;= \sqrt {810000+0.81} \\
&amp;= \sqrt {810000.81}
\end{aligned}\end{split}\]</div>
<p>のようになります．ここで着目したい点として，<span class="math notranslate nohighlight">\(x_{1}\)</span> と
<span class="math notranslate nohighlight">\(x_{2}\)</span>のどちらが距離 <span class="math notranslate nohighlight">\(d\)</span>
に対して影響を与えているかですが，明らかに <span class="math notranslate nohighlight">\(x_{1}\)</span>
です．<span class="math notranslate nohighlight">\(x_{2}\)</span>
に関しては，スケールが小さいがゆえにほとんど影響を与えていません．これでは
<span class="math notranslate nohighlight">\(x_{2}\)</span>
がデータの意味として重要な場合においても考慮できません．こうした問題を解決する方法の一つが，ここで紹介する<strong>スケーリング</strong>です．代表的なスケーリングの方法としては２つあります．</p>
<p>１つ目が，サンプル集合を<strong>最小値0</strong>，<strong>最大値1</strong>にスケーリングする方法です．これを<strong>Min-Max
スケーリング</strong>と呼びます．この方法は単純で，各変数ごとに最小値
<span class="math notranslate nohighlight">\(x_{\min}\)</span> と最大値 <span class="math notranslate nohighlight">\(x_{\max}\)</span>
を求めておき，すべてのデータに対して，</p>
<div class="math notranslate nohighlight">
\[\widetilde{x} = \dfrac{x - x_{\min}}{x_{\max} - x_{\min}}\]</div>
<p>の計算を行います．Min-Maxスケーリングには計算が単純というメリットがある反面，下図の例ように<span class="math notranslate nohighlight">\(x_1\)</span>で外れ値を持つデータ点が存在するような場合，<span class="math notranslate nohighlight">\(x_{\max}\)</span>
が外れ値であるこの一点に大きく引っ張られてしまうという弱点があります．</p>
<p><img alt="image28" src="https://github.com/japan-medical-ai/medical-ai-course-materials/raw/master/notebooks/images/1/16.png" /></p>
<p>もう１つのスケーリングの方法として，<strong>平均0</strong>，<strong>標準偏差1</strong>
にスケーリングする方法があります．分散含め，標準偏差ではデータのばらつきを定量評価することができ，</p>
<div class="math notranslate nohighlight">
\[\widetilde{x}  = \dfrac{x - \bar{x}}{\sigma}\]</div>
<p>のように，標準偏差で割ることで，スケールを統一することができます．分散を計算した例題の①に対して，適用してみると，</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
x_{1}&amp;=\dfrac {-2-0}{\sqrt {2}}=-\dfrac {2}{\sqrt {2}}\\
x_{2}&amp;=\dfrac {-1-0}{\sqrt {2}}=-\dfrac {1}{\sqrt {2}}\\
x_{3}&amp;=\dfrac {0-0}{\sqrt {2}}=0\\
x_{4}&amp;=\dfrac {1-0}{\sqrt {2}}=\dfrac {1}{\sqrt {2}}\\
x_{5}&amp;=\dfrac {2-0}{\sqrt {2}}=\dfrac {2}{\sqrt {2}}
\end{aligned}\end{split}\]</div>
<p>のように，データが変換されます．この時の平均と標準偏差を求めてみると，</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
\overline {x}&amp;=\dfrac {1}{5}\left( -\dfrac {2}{\sqrt {2}}-\dfrac {1}{\sqrt {2}}+0+\dfrac {1}{\sqrt {2}}+\dfrac {2}{\sqrt {2}}\right) =0\\
\sigma ^{2}&amp;=\dfrac {1}{5}\left\{ \left( -\dfrac {2}{\sqrt {2}}-0\right) ^{2}+\left( -\dfrac {1}{\sqrt {2}}-0\right) ^{2}+\left( 0-0\right) ^{2}
 +\left( \dfrac {1}{\sqrt {2}}-0\right) ^{2}+\left( \dfrac {2}{\sqrt {2}}-0\right) ^{2}\right\} =1\\
\sigma &amp;=\sqrt {\sigma ^{2}}=1
\end{aligned}\end{split}\]</div>
<p>のように，平均0，標準偏差1にスケーリングできていることがわかります．この方法であれば，統計量を使用するため全体の傾向で議論することができ，１点だけの外れ値のようなケースには強い（これを<strong>ロバスト</strong>と表現する）と言えます．</p>
</div>
<div class="section" id="外れ値除去">
<span id="id62"></span><h3>1.5.5. 外れ値除去<a class="headerlink" href="#外れ値除去" title="このヘッドラインへのパーマリンク">¶</a></h3>
<p>以下のように時間によって変動するようなデータを扱うとしましょう．例えば，横軸が時刻，縦軸がCPUの負荷率(%)と考えるとわかりやすいと思います．</p>
<p><img alt="image29" src="https://github.com/japan-medical-ai/medical-ai-course-materials/raw/master/notebooks/images/1/17.png" /></p>
<p>このデータに対して，CPUの負荷率の異常（外れ値）を検出したい場合，どのようにこの外れ値を定義して検出すれば良いでしょうか．その答えは，値の<strong>頻度</strong>に着目することです．</p>
<p><img alt="image30" src="https://github.com/japan-medical-ai/medical-ai-course-materials/raw/master/notebooks/images/1/18.png" /></p>
<p>上図のように，平均に対して線を引き，それぞれの値において頻度を算出してヒストグラムを描いてみると正規分布が現れます．物理現象として正規分布に従うものが多いと説明しましたが，このように中心付近の値の頻度は多く，離れるほど頻度が少なくなっていく現象では正規分布をあてはめることができます．そして，外れ値を定義するために，データの平均
<span class="math notranslate nohighlight">\(\mu\)</span> と標準偏差 <span class="math notranslate nohighlight">\(\sigma\)</span>
を計算し，<span class="math notranslate nohighlight">\(\mu \pm 3\sigma\)</span>の値に線を引けば，外れ値除去を行うことができます．これを<strong>3σ法</strong>と呼び，理論がシンプルかつ，プログラムの実装的にも平均と標準偏差だけで行えて簡単です．外れ値の回数が多い場合などは平均や標準偏差がその外れ値に引っ張られ，3σ法ではうまく対処できない場合があり，そのような場合には中央値をベースとした<strong>Hampel判別法</strong>を用います．</p>
<p>この他，データを大きい順に並べてそれらの上位10%，下位10%を取り除くといったことも行われます．</p>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="Introduction_to_ML_libs.html" class="btn btn-neutral float-right" title="2. 機械学習ライブラリの基礎" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="../index.html" class="btn btn-neutral" title="メディカルAIコース オンライン講義資料" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2018, Preferred Networks &amp; キカガク

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../_static/jquery.js"></script>
        <script type="text/javascript" src="../_static/underscore.js"></script>
        <script type="text/javascript" src="../_static/doctools.js"></script>
        <script type="text/javascript" src="../_static/translations.js"></script>
        <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    

  

  <script type="text/javascript" src="../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>